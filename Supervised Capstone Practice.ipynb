{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro to the Data\n",
    "Here I will dive into the data, taking a preliminary look to identify what kind of data we have and what data is missing. I will also explain what each feature means, the basics of how the data was collected, and what methodologies were used to collect it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559, 41)\n",
      "  yearrt      med   maxeso  gender intake_who  age chemo  ott chemo3g gtv1  \\\n",
      "0   2010  17.0346  44.8989       0          2   67     1   21       2        \n",
      "1   2014                         0          1   69         36                \n",
      "2   2010                         1          1   82         24                \n",
      "3   2013  17.2298  48.9217       1          1   77     1   36       2        \n",
      "4   2013                         1          2   83         28                \n",
      "\n",
      "  tumorload toxeso toxesohigh2 pretoxeso dose per fraction fractions  \\\n",
      "0   52.5055      2           0         2                               \n",
      "1                2           0         2               1.5        30   \n",
      "2                1           0         0                               \n",
      "3   42.2745      1           0         1                 2        22   \n",
      "4                0           0         0               1.8        40   \n",
      "\n",
      "  total dose second dose per fracion second fractions second total dose  \\\n",
      "0                                                                         \n",
      "1         45                       2               11                22   \n",
      "2                                                                         \n",
      "3         33                                                              \n",
      "4         72                                                              \n",
      "\n",
      "     BED Modality PacksPerDay SmokingStatus  IsSCLC T_stage N_stage M_stage  \\\n",
      "0               0                                 0       0       2       0   \n",
      "1  78.15        2                         1       0       3       2       0   \n",
      "2               1                         1       0       1       3       0   \n",
      "3   52.8        2                         1       0       1       3       0   \n",
      "4  84.96        2                         1       0       1       2       0   \n",
      "\n",
      "  PA Locatie FEV  CumultativeTotalTumorDose meanlungdose  lungv20  CumOTT  \\\n",
      "0  0       1  97                      45.00      15.4178  33.8485      21   \n",
      "1  1       0  61                      67.00                            36   \n",
      "2  1       0                          52.25                            24   \n",
      "3  1       0  91                      69.00      25.0428  11.9888      36   \n",
      "4  1       2                          72.00                            28   \n",
      "\n",
      "  OverallBaselineDysp  OverallPostRTDyspFullScore  DyspGT2 DeltaDyspGe1  \\\n",
      "0                   0                           0        0            0   \n",
      "1                   1                           1        0            0   \n",
      "2                   0                           1        0            1   \n",
      "3                   1                           1        0            0   \n",
      "4                   2                           2        0            0   \n",
      "\n",
      "  TreatmentType  TwoYearSurvival  \n",
      "0                              0  \n",
      "1             2                0  \n",
      "2                              0  \n",
      "3             2                0  \n",
      "4             2                0  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('cancer_data.csv')\n",
    "print(df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, all missing values are recorded as a space so I will convert them to NaN then take a look at how many entries there are for each feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 559 entries, 0 to 558\n",
      "Data columns (total 41 columns):\n",
      "yearrt                        553 non-null object\n",
      "med                           352 non-null object\n",
      "maxeso                        352 non-null object\n",
      "gender                        559 non-null int64\n",
      "intake_who                    541 non-null object\n",
      "age                           559 non-null int64\n",
      "chemo                         451 non-null object\n",
      "ott                           559 non-null int64\n",
      "chemo3g                       451 non-null object\n",
      "gtv1                          3 non-null object\n",
      "tumorload                     331 non-null object\n",
      "toxeso                        547 non-null object\n",
      "toxesohigh2                   547 non-null object\n",
      "pretoxeso                     551 non-null object\n",
      "dose per fraction             233 non-null object\n",
      "fractions                     233 non-null object\n",
      "total dose                    233 non-null object\n",
      "second dose per fracion       72 non-null object\n",
      "second fractions              74 non-null object\n",
      "second total dose             74 non-null object\n",
      "BED                           233 non-null object\n",
      "Modality                      547 non-null object\n",
      "PacksPerDay                   63 non-null object\n",
      "SmokingStatus                 464 non-null object\n",
      "IsSCLC                        559 non-null int64\n",
      "T_stage                       524 non-null object\n",
      "N_stage                       532 non-null object\n",
      "M_stage                       505 non-null object\n",
      "PA                            512 non-null object\n",
      "Locatie                       498 non-null object\n",
      "FEV                           430 non-null object\n",
      "CumultativeTotalTumorDose     559 non-null float64\n",
      "meanlungdose                  337 non-null object\n",
      "lungv20                       357 non-null object\n",
      "CumOTT                        559 non-null int64\n",
      "OverallBaselineDysp           497 non-null object\n",
      "OverallPostRTDyspFullScore    559 non-null int64\n",
      "DyspGT2                       559 non-null int64\n",
      "DeltaDyspGe1                  497 non-null object\n",
      "TreatmentType                 209 non-null object\n",
      "TwoYearSurvival               559 non-null int64\n",
      "dtypes: float64(1), int64(8), object(32)\n",
      "memory usage: 179.1+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "df = df.replace(r'\\s+', np.nan, regex=True)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most features have at least 450 of a total possible 559 observations, which should be sufficient. Categories with over 50% missing values will be eliminated, as they will not provide enough information for us to make a reliable model. One category, GTV1, has only 3 entries. This is not nearly enough information to have an impact on our model. Four other categories have under 100 observations: second dose per fraction, second fractions, second total dose, and packs per day. The first 3 of those are all correlated to eachother, so it is unlikely that all 3 of these are necessary for the final model anyways. Packs per day is directly related to smoking status, so this may not be a crucial feature either.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(559, 31)\n"
     ]
    }
   ],
   "source": [
    "df = df.loc[:, pd.notnull(df).sum()>len(df)*.5]\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are left with only 31 features, which significantly reduces our feature space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    339\n",
      "1    220\n",
      "Name: TwoYearSurvival, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df['TwoYearSurvival'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Two Year Survival, our outcome of interest, there are 339 instances of die and 220 for live. This is fairly even and should not cause significant class imbalance in our predictive models.<br><br>\n",
    "\n",
    "Currently, 0 represents death and 1 represents life. We will find later that death is actually the outcome of interest that we are trying to optimize for, so I will switch these values now. From this point forward, 0 represents life and 1 represents death."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['TwoYearSurvival'].replace([0],['temp'],inplace=True)\n",
    "df['TwoYearSurvival'].replace([1],[0],inplace=True)\n",
    "df['TwoYearSurvival'].replace(['temp'],[1],inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, to look at each individual feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yearrt\n",
      "Minimum: 2007.0\n",
      "Maximum: 2014.0\n",
      "\n",
      "med\n",
      "Minimum: 2.6862\n",
      "Maximum: 49.0148\n",
      "\n",
      "maxeso\n",
      "Minimum: 7.0901\n",
      "Maximum: 79.2183\n",
      "\n",
      "gender\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "\n",
      "intake_who\n",
      "Minimum: 0.0\n",
      "Maximum: 4.0\n",
      "\n",
      "age\n",
      "Minimum: 33\n",
      "Maximum: 90\n",
      "\n",
      "chemo\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "\n",
      "ott\n",
      "Minimum: 1\n",
      "Maximum: 96\n",
      "\n",
      "chemo3g\n",
      "Minimum: 0.0\n",
      "Maximum: 2.0\n",
      "\n",
      "tumorload\n",
      "Minimum: 0.9813\n",
      "Maximum: 1075.4356\n",
      "\n",
      "toxeso\n",
      "Minimum: 0.0\n",
      "Maximum: 4.0\n",
      "\n",
      "toxesohigh2\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "\n",
      "pretoxeso\n",
      "Minimum: 0.0\n",
      "Maximum: 3.0\n",
      "\n",
      "Modality\n",
      "Minimum: 0.0\n",
      "Maximum: 2.0\n",
      "\n",
      "SmokingStatus\n",
      "Minimum: 0.0\n",
      "Maximum: 2.0\n",
      "\n",
      "IsSCLC\n",
      "Minimum: 0\n",
      "Maximum: 0\n",
      "\n",
      "T_stage\n",
      "Minimum: 0.0\n",
      "Maximum: 3.0\n",
      "\n",
      "N_stage\n",
      "Minimum: 0.0\n",
      "Maximum: 3.0\n",
      "\n",
      "M_stage\n",
      "Minimum: 0.0\n",
      "Maximum: 0.0\n",
      "\n",
      "PA\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "\n",
      "Locatie\n",
      "Minimum: 0.0\n",
      "Maximum: 3.0\n",
      "\n",
      "FEV\n",
      "Minimum: 25.0\n",
      "Maximum: 138.0\n",
      "\n",
      "CumultativeTotalTumorDose\n",
      "Minimum: 1.5\n",
      "Maximum: 129.6\n",
      "\n",
      "meanlungdose\n",
      "Minimum: 1.5949\n",
      "Maximum: 34.6335\n",
      "\n",
      "lungv20\n",
      "Minimum: 0.0\n",
      "Maximum: 50.9581\n",
      "\n",
      "CumOTT\n",
      "Minimum: 1\n",
      "Maximum: 96\n",
      "\n",
      "OverallBaselineDysp\n",
      "Minimum: 0.0\n",
      "Maximum: 3.0\n",
      "\n",
      "OverallPostRTDyspFullScore\n",
      "Minimum: 0\n",
      "Maximum: 5\n",
      "\n",
      "DyspGT2\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "\n",
      "DeltaDyspGe1\n",
      "Minimum: 0.0\n",
      "Maximum: 1.0\n",
      "\n",
      "TwoYearSurvival\n",
      "Minimum: 0\n",
      "Maximum: 1\n",
      "\n",
      "   yearrt      med   maxeso  gender  intake_who  age  chemo  ott  chemo3g  \\\n",
      "0  2010.0  17.0346  44.8989       0         2.0   67    1.0   21      2.0   \n",
      "1  2014.0      NaN      NaN       0         1.0   69    NaN   36      NaN   \n",
      "2  2010.0      NaN      NaN       1         1.0   82    NaN   24      NaN   \n",
      "3  2013.0  17.2298  48.9217       1         1.0   77    1.0   36      2.0   \n",
      "4  2013.0      NaN      NaN       1         2.0   83    NaN   28      NaN   \n",
      "\n",
      "   tumorload  toxeso  toxesohigh2  pretoxeso  Modality  SmokingStatus  IsSCLC  \\\n",
      "0    52.5055     2.0          0.0        2.0       0.0            NaN       0   \n",
      "1        NaN     2.0          0.0        2.0       2.0            1.0       0   \n",
      "2        NaN     1.0          0.0        0.0       1.0            1.0       0   \n",
      "3    42.2745     1.0          0.0        1.0       2.0            1.0       0   \n",
      "4        NaN     0.0          0.0        0.0       2.0            1.0       0   \n",
      "\n",
      "   T_stage  N_stage  M_stage   PA  Locatie   FEV  CumultativeTotalTumorDose  \\\n",
      "0      0.0      2.0      0.0  0.0      1.0  97.0                      45.00   \n",
      "1      3.0      2.0      0.0  1.0      0.0  61.0                      67.00   \n",
      "2      1.0      3.0      0.0  1.0      0.0   NaN                      52.25   \n",
      "3      1.0      3.0      0.0  1.0      0.0  91.0                      69.00   \n",
      "4      1.0      2.0      0.0  1.0      2.0   NaN                      72.00   \n",
      "\n",
      "   meanlungdose  lungv20  CumOTT  OverallBaselineDysp  \\\n",
      "0       15.4178  33.8485      21                  0.0   \n",
      "1           NaN      NaN      36                  1.0   \n",
      "2           NaN      NaN      24                  0.0   \n",
      "3       25.0428  11.9888      36                  1.0   \n",
      "4           NaN      NaN      28                  2.0   \n",
      "\n",
      "   OverallPostRTDyspFullScore  DyspGT2  DeltaDyspGe1  TwoYearSurvival  \n",
      "0                           0        0           0.0                1  \n",
      "1                           1        0           0.0                1  \n",
      "2                           1        0           1.0                1  \n",
      "3                           1        0           0.0                1  \n",
      "4                           2        0           0.0                1  \n"
     ]
    }
   ],
   "source": [
    "df = df.apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "for column in df.columns.values:\n",
    "    print(column)\n",
    "    print(f'Minimum: {df[column].min()}')\n",
    "    print(f'Maximum: {df[column].max()}\\n')\n",
    "    \n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Yearrt: the year that the patient received radiation therapy. 2007-2014. <br>\n",
    "\n",
    "Med: Mean Esophageal Dose. 2.6862-49.0148 Gy. <br>\n",
    "\n",
    "Maxeso: maximum dose received by any point of the esophagus. 7.0901-79.2183 Gy.<br>\n",
    "\n",
    "Gender: gender of the patient. 0/1.<br>\n",
    "\n",
    "Intake_who: ??? 0,1,2,3,4.<br>\n",
    "\n",
    "Age: age of the patient. 33-90 years.<br>\n",
    "\n",
    "Chemo: whether or not the patient received chemotherapy. 0/1. <br>\n",
    "\n",
    "OTT: Overall Treatment Time. 1-96 months.<br>\n",
    "\n",
    "Chemo3g: Timing of chemotherapy with radiation. 0 = only radiotherapy. 1 = sequential chemoradiation. 2 = concurrent chemoradiation. <br>\n",
    "\n",
    "GTV1: Initial gross tumor volume. Defined as the enhancing lesion and surrounding edema as visualized in diagnostic CT Scan. 4.92-61.94 cc (cubic centimeters).<br>\n",
    "\n",
    "Tumorload: Refers to the number of cancer cells, the size of a tumor, or the amount of cancer in the body. Also called tumor burden. Can be measured with ELISA or beta-gal immunoassay. 0.9813-1075.4356.<br>\n",
    "\n",
    "Toxeso: Esophageal toxicity resulting from radiation. 0, 1, 2, 3, 4. Mostly dependent on maxeso and schedule of radiation therapy. Can negatively impact long term survival. Less common when given separately from chemotherapy. Level 3/4 is considered severe.<br>\n",
    "\n",
    "Toxesohigh2: Whether esophageal toxicity score was above 2. 0/1. <br>\n",
    "\n",
    "Pretoxeso: Esophageal toxicity before radiotherapy. 0, 1, 2, 3.<br>\n",
    "\n",
    "Dose per fraction: Amount of Gy per radiation course. Standard of care is 2 Gy/fraction, 5 fractions/week for total 60 Gy. 1.5-7.5.<br>\n",
    "\n",
    "Fractions: Number of total radiation treatments over the treatment period. 4-44.<br>\n",
    "Total Dose: Total amount of Gy for entire treatment course. 7.2-129.6.<br>\n",
    "\n",
    "Second Dose per Fraction: In some cases, two fractions per day are used near the end of a course of treatment (hyperfractionation). Used on tumors that regenerate more quickly when they are smaller. Only 72 patients received this. 1.5-10.<br>\n",
    "\n",
    "Second Fractions: The number of fractions in the treatment regimen that were given as the second fraction of the day? First fraction destroys cells in mitosis. Second fractions destroys cells entering mitosis. 1-30.<br>\n",
    "\n",
    "Second Total Dose: Seems like this might be the total amount of Gy given in all second doses. 2-45.<br>\n",
    "\n",
    "BED: Biologically Effective Dose, dependent on linear quadratic cell survival. 8.496-315.<br>\n",
    "\n",
    "Modality: Type of treatment. 0 = 3D CRT (3D conformal radiotherapy). 1 = VMAT/IMRT (Volumetric Modulated Arc Therapy/Intensity Modulated Radiation Therapy). <br>\n",
    "\n",
    "PacksPerDay: Number of cigarette packs smoked per day, as estimated by the patient. 0-2.<br>\n",
    "\n",
    "SmokingStatus: Not a smoker, occasional smoker, regular smoker. 0,1,2.<br>\n",
    "\n",
    "IsSCLC: This study is on Non-small cell lung cancer, so I find it unusual that they included a category on whether the patient has small cell lung cancer. All entries are 0.<br>\n",
    "\n",
    "T Stage: TNM system describes characteristics of NSCLC after treatment. T is for tumor size. T0=no sign of cancer. T1=tumor is contained within lung. T2=tumor is 3-5 cm or reaches into bronchus or visceral pleura. T3=tumor is 5-7 cm or reaches into chest wall, phrenic nerve, or pericardium. T4=over 7 cm or reaches into second lung, diaphragm, other surrounding areas.<br>\n",
    "\n",
    "N Stage: N is for Node, and whether cancer has spread to lymph nodes. N0=lymph node is non-cancerous. N1=cancer cells in area where lungs join lymph nodes. N2=cancer in lymph nodes within affected chest area. N3=cancer in lymph nodes outside affected chest area.<br>\n",
    "\n",
    "M Stage: M is for metastasis, when the cancer spreads to another part of the body. M0=cancer has not spread outside initial area. M1=cancer has spread. All 0 in this cohort.<br>\n",
    "\n",
    "PA: ??? Binary.<br>\n",
    "\n",
    "Locatie: Location of tumor. 0,1,2,3.<br>\n",
    "\n",
    "FEV: Forced Expiratory Volume. The maximum volume of air breathed out in 1 second. This is impaired when pulmonary function is reduced due to disease burden. 25-138.<br>\n",
    "\n",
    "CumulativeTotalTumorDose: 1.5-129.6. There is another category called Total Dose that ranges from 7.2-129.6. That category only has 233 observations, and this cateogry has 559 so I will keep this one.<br>\n",
    "\n",
    "Mean Lung Dose: The mean amount of radiation delivered to the lung for all doses/fractions. 1.5949-34.6335 Gy. 15-20 Gy is average.<br>\n",
    "\n",
    "Lungv20: Percentage of lung volume receiving radiation doses of 20 Gy or more. If too high, patient experiences pneumonitis. Under 33% is considered safe, under 22% is considered very little risk. 0-50.9581.<br>\n",
    "\n",
    "CumOTT: Cumulative Overall Treatment Time. 1-96 months. This confirms to me that some features are redundant due to multiple sources of data being combined. This feature is unnecessary. <br>\n",
    "\n",
    "OverallBaselineDysp: Dyspnea is difficult or labored breathing. Dypsnea score befoe treatment. ? 0-3 out of possible 5.<br>\n",
    "\n",
    "OverallPostRTDyspFullScore: Dypsnea after treatment. 0,1,2,3,4,5.<br>\n",
    "\n",
    "DyspGT2: Whether or not the dyspnea score is greater than 2. Binary. <br>\n",
    "\n",
    "DeltaDyspGel: This is most likely the change in dyspnea score from before and after treatment. <br>\n",
    "\n",
    "TreatmentType: ??? Only 2 in this cohort.<br>\n",
    "\n",
    "TwoYearSurvival: Whether or not the patient survived 2 years after starting radiation therapy treatment. 0 is now survive, 1 is die."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intro\n",
    "\n",
    "This data comes from a 2017 study of historical patient data from 2 cohorts of of non-small cell lung cancer patients treated with (chemo)radiotherapy. This includes 559 patients at the Maastro clinic in the Netherlands, and 139 at the University of Manchester, UK. However, only the data fram the first cohort at Maastro clinic has been made publicly available. The original authors, Arthur Jochems et. al, used this data to develop a predictive model for patient survival using a Bayesian network. Tney validated it using testing data from a 3rd cohort from University of Michigan.<br>\n",
    "\n",
    "Recent research has illuminated several features that have an effect on patient prognosis. These include performance status, weight loss, presece of comorbidity, chemotherapy in combination with radiation, dose of radiation, size of tumor, features derived from tumor imaging data, and the radiomics approach. Despite these numerous factors, the TNM system of classification is widely regarded as the most valuable feature predictor for patient survival. The TNM system describes the size of the tumor, the severity of lymphatic involvement, and whether the cancer has metastasized to other parts of the body beyond the initial site of malignancy. Typically, TNM is evaluated by the doctor using a defined set of guidelines *following surgical tumor resection*. In this study, TNM was evaluated by the doctor at the end of each patient's non-invasive CRT or RT treatment regimen. Because the TNM system for NSCLC was designed with surgery in mind, the observations derived from a non-invasive treatment modality may not have the same predictive power. In fact, studies have indicated that the TNM system performs poorly for patients receiving CRT or RT.\n",
    "\n",
    "Amongst the 41 features in this study, select few features have a complete or near complete representation of the entire cohort. Thorough data is provided for the year of treatment, age, gender, overall treatment time, whether the patient received chemotherapy as well as radiation, esophageal toxicity and pretoxicity, modality, smoking status, TNM classification measures, PA, locatie, cumulative tumor dose, level of dyspnea before and after treatment, dyspGT2, deltadyspgel, and two year survival. While the amount of missing data for other categories may prove to be a obstacle for evaluating this dataset, we should note that we have a significant amount of data available for our two most relevant features: TNM classification and the outcome, two year survival.\n",
    "\n",
    "\n",
    "The data was collected as part of an IRB-approved and registered clinical trial. Patients with inoperable NSCLC were treated between 2007 to 2014. The patients received different schedules of dosing for their radiation, and some were treated with chemotherapy at different points in their treatment. 189 patients were treated using sequential CRT, completing a chemotherapy schedule before starting radiation at a cumulative dose of 54.0 to 79.2 Gy (fractions of 1.8 Gy, twice daily, until the mean lung dose or maximum dose to the spinal cord was reache)d. 283 patients were treated using concurrent CRT, receiving chemotherapy and radiation at the same time at a cumulative dose of 45 Gy (fractions of 1.5 Gy, twice daily). This treatment was followed by an individualized dose ranging from 8 to 24 Gy (fractions of 2.0 Gy, once daily, until the normal tissue dose constraints were reached). The remaining patients received an individualized regimen, some receiving conformal RT with and without chemotherapy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thesis\n",
    "\n",
    "Given that the TNM classification is the gold standard in survival risk stratification, I hypothesize that these will be the strongest indicator of patient survival, even though they weren't designed for inoperable patients. Instinctively, I would also hypothesize that smoking status has an effect on survival, because smoking will directly interfere with the treatment regimen and aggravate the cancer.<br>\n",
    "\n",
    "Initial gross tumor volume (GTV1) and tumor load also look like they will reveal a significant relationship with the outcome. They are both directly related to the Tumor part of TNM classification, which I hypothesize will be the strongest set of indicators. All 3 of these features are derived from tumor size, so they may not individually provide enough unique information and may actually end up complicating the model.<br>\n",
    "\n",
    "I don't expect any information related to dosing quantity or schedule to have much effect on patient survival because every patient has such vastly different needs, background, and reactions to medication.<br>\n",
    "\n",
    "Forced Expiratory Volume (FEV) is a valuable indicator for impaired pulmonary function and thus disease burden. However, I don't expect this feature to have much significance for the outcome because each patient has a different starting lung capacity. If this feature were change in forced expiratory volume over time, that would be a much more useful feature.<br>\n",
    "\n",
    "Add bulletpoints summary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Analysis\n",
    "\n",
    "Be sure to explain the intuition behind why you're looking into a particular part of the data, or trying to use certain types of models for the survival prediction. e.g. there are a lot of features, many of which might not be useful, so I'll initially use Lasso regression to train a basic model and drop unneeded features at the same time. And have some (very) basic discussion on the results.\n",
    "\n",
    "In this section I will start looking at correlations, visualizations of the data, and run a few machine learning classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/h/08QWnyyhb8wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ce7d3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEFCAYAAAAsU2YoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhrckFfR/s3Ezi1M6dMoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e9fd630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAER9JREFUeJzt3X2QXXV9x/H3JpuQxi5xWy46zDDijMO3yozQRpEHk+xY\nFIIPcah9mA6lyEixE0t0mOHJoFOLBWYALTKKRmPQ1v4hD63QSaFFGqO2g9I4NQN+GahOO8VxVtzA\nMpGHkO0f52y9jclmc/Zk99xf3q+ZzJxz7u45n72b+7m//d17zh2amppCklSGRQsdQJLUHktdkgpi\nqUtSQSx1SSqIpS5JBbHUJakglrokFcRSl6SCDC90AKkNETEGXAc8CZwE7AY+ClwKBHAncBnwCeA0\nYAQYAt4H/CvwT8DDmXl5RJwFbAFWAhPADcAaYDGwA7g0M5+JiD8F3g+8ADwHXJKZj0TEScCtwK8D\nU8BNmfmlw3wXSIAjdZXljcC1mfkbwE+Aq4C3A78FrAdOB44DTs/M1wG3A1dm5l7gfOCCiFgHfBH4\nw8z8CXAlsAdYmZknUz1pXB8Ri4FPAudk5huBzwFvjohh4GvApzLz9cBa4C8j4vT5uQt0pLPUVZIf\nZuaOevkJ4MHMfCEzfwo8AzwNbAQuiYgbgfcAvwqQmT8GLgbuBj6Xmd+o9/MOYB2wIyK+B7wbeF1m\nvgR8Ffh2RNxa7/sLwInAssy8q97vk1R/JZxzeH90qWKpqyTP77P+4j7rvw38Q73898BtVFMw006i\nGuGf2rdtMbAhM0/JzFPq294DkJnnA+8EHgeuAO5i/4+pRcCSQ/1hpCYsdR1J3gnck5mfAb5DNepe\nDBARpwIbgDcAL4+IDfX33Ad8ICKWRsQiYBNwXUQcExH/DTyVmZ+k+gvgZCCBFyLivHq/xwG/QzVn\nLx12lrqOJB8E1kTEf1C9OPoE8OqIWAH8LfBnmfk/wIXARyLiN4G/AH5E9QLpI1Qj+8vqKZ1rgQci\n4mHgeuB9mfki1ZPFhvo4/wx8LDMfnL8fU0eyIS+9K0nlcKQuSQWx1CWpIJa6JBXEUpekgizoZQLG\nxyfn9VXa0dHlTEzsns9DNmLOdpmzfYOStdScvd7I0IFuO6JG6sPDixc6wqyYs13mbN+gZD0Scx5R\npS5JpbPUJakglrokFcRSl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQVZ0MsESF110fVfX7Bjb77y\nLQt2bA0+R+qSVBBLXZIKYqlLUkFmNaceEW8CbsjMsYg4BfgU8BLwPHBBZv4kIi4GLgH2ANdm5r2H\nK7Qkaf8OOlKPiMuBzwPL6k1/RfWp62PAXcAVEfFK4FLgTOBs4LqIOOqwJJYkHdBsRupPAOcBX67X\n/yAzf9z3/c8BpwLfyszngecj4nHg9cB3Ztrx6Ojyeb/eca83Mq/Ha8qc7RqUnDA4Wc3ZrrZyHrTU\nM/POiDihb/3HABFxBvABYDXV6Pzpvm+bBFYcbN/z/Ykkvd4I4+OT83rMJszZrkHJOW0Qsg7KfVpq\nzpmeABq9UBoRvw/cBrw9M8eBZ4D+o4wAu5rsW5LU3CGffBQR51O9IDqWmT+rNz8EfDwilgFHAa8F\ndraWUpI0K4dU6hGxGLgF+C/grogA2JaZH42IW4DtVKP/D2fmc22HlSTNbFalnpk/Ak6rV3/tAF+z\nCdjUTixJUhOefCRJBbHUJakglrokFcRSl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6\nJBXEUpekgljqklQQS12SCmKpS1JBLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtS\nQSx1SSqIpS5JBRmezRdFxJuAGzJzLCJeA2wBpoCdwPrM3BsRFwOXAHuAazPz3sOUWZJ0AAcdqUfE\n5cDngWX1ppuBjZm5ChgC1kXEK4FLgTOBs4HrIuKowxNZknQgs5l+eQI4r299JbCtXt4KnAWcCnwr\nM5/PzKeBx4HXtxlUknRwB51+ycw7I+KEvk1DmTlVL08CK4Cjgaf7vmZ6+4xGR5czPLx49mlb0OuN\nzOvxmjJnuwYlJwxOVnO2q62cs5pT38fevuURYBfwTL287/YZTUzsbnD45nq9EcbHJ+f1mE2Ys12D\nknPaIGQdlPu01JwzPQE0effLjogYq5fXAtuBh4BVEbEsIlYAr6V6EVWSNI+ajNQvAzZFxFLgUeCO\nzHwpIm6hKvhFwIcz87kWc0qSZmFWpZ6ZPwJOq5cfA9bs52s2AZvaDCdJOjSefCRJBbHUJakglrok\nFcRSl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6JBXEUpekgljqklQQS12SCmKpS1JB\nLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtSQSx1SSqIpS5JBbHUJakgw02+KSKW\nALcDJwAvARcDe4AtwBSwE1ifmXtbSSlJmpWmI/VzgeHMPAP4GPBx4GZgY2auAoaAde1ElCTNVqOR\nOvAYMBwRi4CjgReB04Bt9e1bgbcBd8+0k9HR5QwPL24YoZleb2Rej9eUOds1KDlhcLKas11t5Wxa\n6s9STb38ADgGeAewOjOn6tsngRUH28nExO6Gh2+m1xthfHxyXo/ZhDnbNSg5pw1C1kG5T0vNOdMT\nQNPplw8B92XmicDJVPPrS/tuHwF2Ndy3JKmhpqU+ATxdL/8MWALsiIixettaYPvcokmSDlXT6ZdP\nAJsjYjvVCP1q4LvApohYCjwK3NFOREnSbDUq9cx8Fvi9/dy0Zm5xJElz4clHklQQS12SCmKpS1JB\nLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtSQSx1SSqIpS5JBbHUJakglrokFcRS\nl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6JBXEUpekgljqklSQ4abfGBFXAe8ClgKf\nBrYBW4ApYCewPjP3tpBRkjRLjUbqETEGnAGcCawBjgduBjZm5ipgCFjXUkZJ0iw1nX45G/g+cDdw\nD3AvsJJqtA6wFThrzukkSYek6fTLMcCrgHcArwa+BizKzKn69klgxcF2Mjq6nOHhxQ0jNNPrjczr\n8ZoyZ7sGJScMTlZztqutnE1L/SngB5n5ApAR8RzVFMy0EWDXwXYyMbG74eGb6fVGGB+fnNdjNmHO\ndg1KzmmDkHVQ7tNSc870BNB0+uWbwDkRMRQRxwEvAx6o59oB1gLbG+5bktRQo5F6Zt4bEauBh6ie\nGNYDPwQ2RcRS4FHgjtZSSpJmpfFbGjPz8v1sXjOHLJKkOfLkI0kqiKUuSQWx1CWpIJa6JBXEUpek\ngljqklQQS12SCmKpS1JBLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtSQRp/SIYk\nteWi67++IMfdfOVbFuS4h5MjdUkqiKUuSQWx1CWpIJa6JBXEUpekgljqklQQS12SCmKpS1JB5nTy\nUUQcCzwMvBXYA2wBpoCdwPrM3DvXgJKk2Ws8Uo+IJcBngZ/Xm24GNmbmKmAIWDf3eJKkQzGX6Zcb\ngduAJ+v1lcC2enkrcNYc9i1JaqDR9EtEXAiMZ+Z9EXFVvXkoM6fq5UlgxcH2Mzq6nOHhxU0iNNbr\njczr8ZoyZ7sGJScMTtZByTmTLv0MbWVpOqd+ETAVEWcBpwBfAo7tu30E2HWwnUxM7G54+GZ6vRHG\nxyfn9ZhNmLNdg5Jz2iBkHbT79EC68jMc6v050xNAo+mXzFydmWsycwz4HnABsDUixuovWQtsb7Jv\nSVJzbV569zJgU0QsBR4F7mhx35KkWZhzqdej9Wlr5ro/SVJzfkiGJGDhPqhC7fKMUkkqiKUuSQWx\n1CWpIJa6JBXEUpekgljqklQQS12SCuL71NVpvndaOjSO1CWpIJa6JBXEUpekgjinPkAWcn5585Vv\nWbBjS5o9R+qSVBBLXZIK4vSLpCNWiVOajtQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtSQSx1SSqI\npS5JBbHUJakglrokFaTRZQIiYgmwGTgBOAq4FngE2AJMATuB9Zm5t5WUkqRZaTpSPx94KjNXAecA\ntwI3AxvrbUPAunYiSpJmq+kFvb4K3FEvDwF7gJXAtnrbVuBtwN0z7WR0dDnDw4sbRmim1xuZ1+M1\n1bWcB8rTtZwl8HNZjwz7Pnbaeiw1KvXMfBYgIkaoyn0jcGNmTtVfMgmsONh+JiZ2Nzl8Y73eCOPj\nk/N6zCa6mHN/ebqYUxoU/Y+dQ30szfQE0PiF0og4HngQ+HJmfgXonz8fAXY13bckqZlGpR4RrwDu\nB67IzM315h0RMVYvrwW2zz2eJOlQNJ1TvxoYBa6JiGvqbRuAWyJiKfAov5hzlyTNk6Zz6huoSnxf\na+YWR13li3fSYPDkI0kqiKUuSQWx1CWpIJa6JBXEUpekgljqklQQS12SCmKpS1JBLHVJKoilLkkF\nsdQlqSBNL+h1RPM6KJK6ypG6JBXEUpekgljqklQQS12SCjKwL5T6YqUk/TJH6pJUEEtdkgpiqUtS\nQSx1SSqIpS5JBbHUJakglrokFcRSl6SCtHryUUQsAj4NnAw8D7wvMx9v8xiSpANre6T+bmBZZp4O\nXAnc1PL+JUkzaLvU3wz8I0Bm/hvwhpb3L0maQdvXfjkaeLpv/aWIGM7MPfv74l5vZKjpge65aV3T\nb5Wkzun1RlrZT9sj9WeA/mSLDlTokqT2tV3q3wLOBYiI04Dvt7x/SdIM2p5+uRt4a0R8GxgC3tvy\n/iVJMxiamppa6AySpJZ48pEkFcRSl6SCWOqSVJCB/YzS2YiINwE3ZOZYRLwG2AJMATuB9Zm5d4Hz\nLQE2AycARwHXAo/QsZwAEbEY2AQEVbb3A8/RwawAEXEs8DDwVmAPHcwZEf9O9TZggB8CH6ebOa8C\n3gUspboMyDa6mfNC4MJ6dRlwCtUJkZ+kQ1nrx/3tVI/7l4CLafH/aLEj9Yi4HPg81S8X4GZgY2au\nonpnThfOXjofeKrOdA5wK93MCfBOgMw8E9hIVUCdzFo/aD4L/Lze1LmcEbEMGMrMsfrfe+lmzjHg\nDOBMYA1wPB3MCZCZW6bvT6on9EuBj9C9rOcCw5l5BvAxWn4sFVvqwBPAeX3rK6lGGABbgbPmPdEv\n+ypwTb08RPVs3cWcZObfAX9Sr74K2EVHswI3ArcBT9brXcx5MrA8Iu6PiK/X53V0MefZVOeb3A3c\nA9xLN3P+n4h4A3BSZn6ObmZ9DBiuL4B4NPAiLeYsttQz806qO2vaUGZOv39zElgx/6n+v8x8NjMn\nI2IEuINqBNy5nNMyc09E3A58CvgbOpi1/hN8PDPv69vcuZzAbqonn7OpprI6eX8Cx1Bdw+l3+UXO\nRR3M2e9q4M/r5S7ep89STb38gGpK8xZazFlsqe9H//zUCNVIc8FFxPHAg8CXM/MrdDTntMz8Y+BE\nqv+Mv9J3U1eyXkR1Aty/UM2pfgk4tu/2ruR8DPjrzJzKzMeAp4BX9N3elZxPAfdl5guZmVSvo/QX\nTldyAhARLwciMx+sN3Xx8fQhqvv0RKq/2G6ner1i2pxyHkmlvqOeHwRYC2xfwCwARMQrgPuBKzJz\nc725czkBIuKP6hfMoBpl7gW+27Wsmbk6M9fU86rfAy4AtnYtJ9WTz00AEXEc1Z/h93cw5zeBcyJi\nqM75MuCBDuacthp4oG+9i4+nCX5x4cOfAUtoMWfR737Zx2XApohYCjxKNd2x0K4GRoFrImJ6bn0D\ncEvHcgLcBXwxIr5B9Z/wg1T5unaf7k8Xf/dfALZExDep3vFwEfBTOpYzM++NiNXAQ1SDwPVU79Tp\nVM4+Afxn33oXf/efADZHxHaqEfrVwHdpKaeXCZCkghxJ0y+SVDxLXZIKYqlLUkEsdUkqiKUuSQWx\n1CWpIJa6JBXkfwHkvb/8U9mM5gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eb6f080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cab31d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nvx9bUWdbYCHoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eaf41d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmmXflAYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ecf6160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEOBJREFUeJzt3X+Q3HV9x/HnJUc4Mxzp0a6iU0faUd/STkNtLKBpSiqK\nUrWxWDtTq1NlGkKLJbSZKjWhdDQt4gDWaLV6FGmdYeoIprWZItCpxYBVEEFNZd4aWqbOOLQnvSSn\nMSE/rn98vxl34t3uZrN7y332+Zhh+P7+vt+zl9d+7vvd/d7I7OwskqQyLBl0AZKk3jHUJakghrok\nFcRQl6SCGOqSVBBDXZIKYqhrKETE2ojYNeg6pH4z1CWpICN++UgliohLgU3AEeC7wMeB9wBfBF4E\njAHrM3NnRCwDrgcuAJYCDwNXZua+iHgcuA14DfDjwLXAamAVcAj4tcz8TkT8LPCheptZ4MbM/LuF\n6Vb6IUfqKk5EnEMV0q/OzJXAZ4DNwE8C78/Mnwc+CvxZvcvVwGFgVWaeA3wHeG/TIcfq5ZuAjwEf\nqOe/Dbw1Ikbrc3ywPt/FwF9ExEv726n0owx1lehC4K7M/DZAZv4lcDnwWGZ+qd7mEeCZ9fRrgXXA\nwxHxCPB64GeajndH/f/HgCcy86tN82cAL6QK/k/X5/tOvc+r+9Cb1NLooAuQ+uAw1SUQACLiGVSX\nXA41bTMLjNTTS4GNmXlnvf1pVJdnjjnYNN18jGPmGhwtAU454cqlk+RIXSX6HPCKiHh2Pb8BeF+L\n7e8C3h4RyyJiCTAJXHcC50vgqYi4BCAingO8AbjnhCuXTpKhruJk5teBPwY+GxFfpboMcnmLXd4D\nPE51g/QbVCP4TSdwvkNUl2w2RsTXgH8B3p2Zn+uqAekk+OkXSSqII3VJKoihLkkFMdQlqSCGuiQV\nZKCfU5+amun6Lu3ExHKmp/f3spynPXseDvY8HE6m50ZjfGS+dYt2pD46unTQJSw4ex4O9jwc+tXz\nog11SdKPMtQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBfHP2UkaWpe+918Hdu5/\nunFdX47rSF2SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqI\noS5JBTHUJakghrokFcRQl6SCGOqSVJC2fyQjIpYCk0AAs8DlwAHg1np+F3BFZh6NiPXABuAwsDUz\nd/SpbknSHDoZqb8OIDNXA1uAPwduArZk5hpgBFgXEWcCVwKrgVcB10XEqX2pWpI0p7ahnpn/AFxW\nzz4P2AOsAu6tl90JvAI4F7g/Mw9m5l5gN7Cy5xVLkubV0d8ozczDEfG3wK8DvwG8MjNn69UzwArg\ndGBv027Hls9rYmI5o6NLT7joYxqN8a73XazseTjY83DoR88d/+HpzPydiHgn8CXgGU2rxqlG7/vq\n6eOXz2t6en/nlR6n0Rhnamqm6/0XI3seDvY8PLrtudWbQdvLLxHxloj4k3p2P3AU+HJErK2XXQzs\nBB4A1kTEWESsAM6muokqSVognYzUPw18PCI+D5wCXAU8CkxGxLJ6+vbMPBIR26gCfgmwOTMP9Klu\nSdIc2oZ6Zn4f+M05Vl0wx7aTVB9/lCQNgF8+kqSCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWp\nIIa6JBXEUJekghjqklQQQ12SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpi\nqEtSQQx1SSqIoS5JBTHUJakgo61WRsQpwC3AWcCpwFbg28AO4Fv1Zh/JzE9GxHpgA3AY2JqZO/pV\ntCRpbi1DHXgz8GRmviUizgAeAd4N3JSZNx7bKCLOBK4EXgKMAfdFxD2ZebBPdUuS5tAu1D8F3F5P\nj1CNwlcBERHrqEbrVwHnAvfXIX4wInYDK4EH+1K1JGlOLUM9M78HEBHjVOG+heoyzM2Z+VBEbAau\npRrB723adQZY0e7kExPLGR1d2mXp0GiMd73vYmXPw8Geh0M/em43UicingtsBz6cmbdFxI9l5p56\n9Xbgg8DngebqxoE9tDE9vf/EK641GuNMTc10vf9iZM/DwZ6HR7c9t3ozaPnpl4h4FnA38M7MvKVe\nfFdEnFtPXwg8BDwArImIsYhYAZwN7OqqWklS19qN1N8FTADXRMQ19bI/At4fEYeAJ4DLMnNfRGwD\ndlK9UWzOzAP9KlqSNLd219Q3AhvnWLV6jm0ngcke1SVJ6oJfPpKkghjqklQQQ12SCmKoS1JBDHVJ\nKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFcRQl6SC\nGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIKOtVkbEKcAtwFnAqcBW4BvArcAssAu4IjOPRsR6\nYANwGNiamTv6V7YkaS7tRupvBp7MzDXAq4EPATcBW+plI8C6iDgTuBJYDbwKuC4iTu1f2ZKkubQc\nqQOfAm6vp0eoRuGrgHvrZXcCFwFHgPsz8yBwMCJ2AyuBB3tesSRpXi1DPTO/BxAR41ThvgW4ITNn\n601mgBXA6cDepl2PLW9pYmI5o6NLuyi70miMd73vYmXPw8Geh0M/em43UicingtsBz6cmbdFxPua\nVo8De4B99fTxy1uant5/YtU2aTTGmZqa6Xr/xcieh4M9D49ue271ZtDymnpEPAu4G3hnZt5SL344\nItbW0xcDO4EHgDURMRYRK4CzqW6iSpIWULuR+ruACeCaiLimXrYR2BYRy4BHgdsz80hEbKMK+CXA\n5sw80K+iJUlza3dNfSNViB/vgjm2nQQme1SXJKkLfvlIkgpiqEtSQQx1SSqIoS5JBTHUJakghrok\nFcRQl6SCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6JBXEUJekghjqklQQQ12SCmKoS1JB\nDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUkNFONoqI84DrM3NtRLwY2AF8q179kcz8ZESsBzYA\nh4GtmbmjLxVLkubVNtQj4h3AW4Dv14tWATdl5o1N25wJXAm8BBgD7ouIezLzYO9LliTNp5OR+mPA\nJcAn6vlVQETEOqrR+lXAucD9dYgfjIjdwErgwVYHnphYzujo0m5rp9EY73rfxcqeh4M9D4d+9Nw2\n1DPzjog4q2nRA8DNmflQRGwGrgUeAfY2bTMDrGh37Onp/SdWbZNGY5ypqZmu91+M7Hk42PPw6Lbn\nVm8G3dwo3Z6ZDx2bBl4M7AOazzIO7Oni2JKkk9BNqN8VEefW0xcCD1GN3tdExFhErADOBnb1qEZJ\nUoc6+vTLcX4P+GBEHAKeAC7LzH0RsQ3YSfVGsTkzD/SwTklSBzoK9cx8HDi/nv4KsHqObSaByV4W\nJ0k6MX75SJIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6JBXEUJekghjqklQQQ12SCmKoS1JBDHVJKoih\nLkkFMdQlqSCGuiQVpJvnqT8tvG7TPw7s3Ldc/fKBnVuSWnGkLkkFMdQlqSCGuiQVxFCXpIIY6pJU\nEENdkgpiqEtSQQx1SSpIR18+iojzgOszc21EPB+4FZgFdgFXZObRiFgPbAAOA1szc0efapYkzaPt\nSD0i3gHcDIzVi24CtmTmGmAEWBcRZwJXAquBVwHXRcSp/SlZkjSfTkbqjwGXAJ+o51cB99bTdwIX\nAUeA+zPzIHAwInYDK4EHWx14YmI5o6NLu6l7oBqN8aE896DY83Cw595oG+qZeUdEnNW0aCQzZ+vp\nGWAFcDqwt2mbY8tbmp7e33mlTyNTUzMDOW+jMT6wcw+KPQ+HYewZus+SVm8G3dwoPdo0PQ7sAfbV\n08cvlyQtoG5C/eGIWFtPXwzsBB4A1kTEWESsAM6muokqSVpA3Tx6dxMwGRHLgEeB2zPzSERsowr4\nJcDmzDzQwzolSR3oKNQz83Hg/Hr6m8AFc2wzCUz2sjhJ0onxy0eSVBBDXZIKYqhLUkEMdUkqiKEu\nSQUx1CWpIIa6JBXEUJekghjqklQQQ12SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJU\nEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFWS02x0j4ivAvnr2v4A/B24FZoFdwBWZefRkC5Qk\nda6rUI+IMWAkM9c2LfsMsCUz/y0i/hpYB2zvSZWSpI50O1I/B1geEXfXx3gXsAq4t15/J3ARhrok\nLahuQ30/cANwM/ACqhAfyczZev0MsKLdQSYmljM6urTLEgan0RgfynMPij0PB3vujW5D/ZvA7jrE\nvxkRT1KN1I8ZB/a0O8j09P4uTz9YU1MzAzlvozE+sHMPij0Ph2HsGbrPklZvBt1++uVS4EaAiHgO\ncDpwd0SsrddfDOzs8tiSpC51O1L/G+DWiLiP6tMulwLfBSYjYhnwKHB7b0qUJHWqq1DPzKeAN82x\n6oKTK0eSdDL88pEkFcRQl6SCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6JBXEUJekghjq\nklQQQ12SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5J\nBRnt5cEiYgnwYeAc4CDwu5m5u5fnkCTNr9cj9dcDY5n5UuBq4MYeH1+S1EKvQ/2XgM8CZOYXgZf0\n+PiSpBZGZmdne3awiLgZuCMz76zn/xv46cw83LOTSJLm1euR+j5gvPn4BrokLZxeh/r9wK8CRMT5\nwNd7fHxJUgs9/fQLsB14ZUR8ARgB3tbj40uSWujpNXVJ0mD55SNJKoihLkkFMdQlqSC9vlHac+0e\nPRARrwP+FDgM3JKZkwMptIc66Pm3gKuoev468PuZeXQQtfZCp4+XiIiPAf+XmVcvcIk918Fr/IvA\nTVQfOHgCeHNmHhhErb3SQc+/DWwCjlD9W/7IQArtg4g4D7g+M9cet7zn+bUYRurzPnogIk4B3g9c\nBFwAXBYRzxpIlb3VqudnAFuBX8nM1cAK4LUDqbJ32j5eIiI2AD+30IX1UavXeASYBN6Wmce+pf28\ngVTZW+1e5xuAVwCrgU0RMbHA9fVFRLwDuBkYO255X/JrMYR6q0cPnA3szszpzHwKuA/45YUvseda\n9XwQeFlm7q/nR4FFPYKjzeMlIuJlwHnARxe+tL5p1fMLgSeBP4yIe4EzMjMXvsSea/cYka9RDVLG\nqH5DKeWjeY8Bl8yxvC/5tRhC/XRgb9P8kYgYnWfdDNUPxWI3b8+ZeTQz/wcgIv4AOA24Z+FL7Kl5\n+42IZwPXAm8fRGF91Orn+ieAlwEfohq5XhgRL1/g+vqhVc8Au4CHgP8AdmTmnoUsrl8y8w7g0Byr\n+pJfiyHUWz164Ph140AJPwgtH7cQEUsi4gbglcAbMnOxj2ha9ftGqpD7Z6pf2d8UEW9d2PL6olXP\nT1KN4B7NzENUo9sSHo43b88RsRJ4DfBTwFnAMyPijQte4cLqS34thlBv9eiBR4EXRMQZEbGM6leX\nf1/4Enuu3eMWPkr1K+rrmy7DLGbz9puZ2zJzVX2D6b3AbZl56yCK7LFWr/F/AqdFxPPr+TVUo9fF\nrlXPe4EfAD/IzCPA/wJFXFNvoS/59bT/RmnTHfOV/PDRA78AnJaZH2u6e7yE6u7xXw2s2B5p1TPw\n5fq/nfzwmuMHMnP7AErtiXavcdN2bwVeVNinX+b7uX451ZvYCPCFzNw4sGJ7pIOeLwcuBZ6iug69\nvr7WvOhFxFnA32fm+RHxJvqYX0/7UJckdW4xXH6RJHXIUJekghjqklQQQ12SCmKoS1JBDHVJKoih\nLkkF+X9R983hjQlBoQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11efe9438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEFCAYAAAACFke6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f141c50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nKoilLkkFsdQlqSD/B1inlSHeewkzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f2470b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11dc01860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nW+XnyApmAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f47e7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSYUYdUkqxKhLUiFGXZIK+T9ppKtf6WKHKQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f554e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noS5JBTHUJakg/wNF1SefIvBEigAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f441748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ec5e390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAFERJREFUeJzt3X2UXHV9x/H3koXE6BIXzwraekpt9VtahWIQsJGaooKo\nNJZy2lMPtEoFVCqgVlAIWtsgaiEKPhtMU60oBURpLAIVRUArCNgapV+I1VPbqmfh5GExTTDJ9o97\n106X3XnKzs744/36hzv3aT774+Yzv727Mzs0OTmJJKkMe/U7gCRp7ljqklQQS12SCmKpS1JBLHVJ\nKoilLkkFGe53AD26RcSRwEXAE6gmGT8A/jwzvz0H514HbMjMi6et/0tgY2Z+vMvz7g1cCLwImASG\ngE8DF2XmZES8BDgiM9/a4jxt7Sd1wlJX30TEQmA9cExm3l2vOwm4PiJ+OTN39eJ556BEzwaeCjwr\nM3dGxBLgZuAB4KPAs4H92jhPu/tJbbPU1U+LgccDj2tY90lgK/D8iHg78N/AbwDbgLcBZwIBXJOZ\nrweIiNPq9buAHwN/lpn3NT5RRKwGDgFWAO+nnsFHxHbgncALgScDl2bmeyNiAfDXwO8CW4CvA7+e\nmcuBJwF7AwuBnZm5JSJOBvaKiCOAVwMLImIL8A7gQ8DTqQp8Anh5/XU37nc/cGJmvrTO+4qpxxHx\nXGA1sIDqO4OLMvOa7oZcpfOeuvomMzcB5wBfiIh/j4hPAK8E/gl4mGomuyozf42qrN8CvAR4FnBG\nRDw5Io6uz/E7mXkIcAXw2YgYqp9mKCI+ABwIvDgzH5oWYyHwQGYuA04E3hkRi4BXAUuBZwDPAX6l\n4ZjVwC8AD0TElyPiQmBhZm7IzK8DHwauzMzzgeOAzZl5ZGY+HbiT6kVn+n7NvB1YnZlLgVOAo1sO\nrh61LHX1VWauBvanmmn/EDgXuAdYAnwvM++pd/0u8KXMfDgzH6Caze9HdV/7yswcr8+3jqpwD6yP\newPVjPhtmbljlhifq/97N1XJPxZ4MfDxzNyemQ8DH2nI/J+ZeRhV6V9F9Z3D1yLitTN8fVcD6yLi\ndRFxKbCc//+dSTv+HvhARHyyfs7zOjxejyKWuvomIpZFxJsycyIz12fmOVS3WnZT3d6YXsI/neE0\nM13DQ/XxALdQ3QNfV/+Acyb/A5CZUx+ENATsrP875Wf39yPi3RHx9Mz8TmZ+IDNPpJrZP6LUI+I1\nwMeobh9dAXxq2nmnTE5bv8/UQmZ+BHgmcBNwLPCv9X186REsdfXTOLCyvmc85UlUM+UntHmOG4A/\njIgxgIh4JfAgsLHe/g2qe+ibgb/oINvngZMiYmFEDAOvoCpegCcCfxURi+vnHKKard9db9/J/72o\nHAusy8yPAQkcT3VvfPp+48AzImJR/XzHTwWJiK8Ch9bfhZxGdT9+tIOvRY8i/qBUfZOZ90XEy4B3\nRMQvAtupfih5Wr3czjluioj3ADdHxF5U5fjSzNwdEVP7TEbEKcA3I+LzbcZbR1XU9wAPAd+jmm1D\nNSO/kGrGvIPq39HNwBn19i8Cn4mIh4GLgY/WLza7gLuoZt3T93s91XcV/0Z1G+pLwMH1fucAl0bE\nKqrvYt6emd9v8+vQo8yQH70rPVJEHAM8MTP/rn58KbA9M8/tbzKpOWfq0sy+DbwpIt5E9e/kX4DX\n9DeS1JozdUkqiD8olaSCWOqSVJC+3lMfH5/o+t7P6OhiNm3a1nrHeWauzpirc4OazVyd2ZNcY2Mj\nM73XAfg5nqkPDy9ovVMfmKsz5urcoGYzV2d6levnttQlSY9kqUtSQSx1SSqIpS5JBbHUJakglrok\nFcRSl6SCWOqSVBBLXZIK4kfvSjM4/o2fa71Tj6x9s39XWt1zpi5JBbHUJakglrokFcRSl6SCWOqS\nVBBLXZIKYqlLUkEsdUkqSMs3H0XEAmANEMAk8GpgO7CufrwBOCMzd0fEqcDpwE5gVWau71FuSdIM\n2pmpHw+QmcuAlcCFwGpgZWYeBQwBKyLiAOBMYBlwLHBRRCzsSWpJ0oxalnpmfhY4rX74S8BmYClw\nS73ueuAFwOHA7Zm5IzO3ABuBg+c8sSRpVm199ktm7oyIvwV+DzgReGFmTtabJ4AlwL7AlobDptbP\nanR08R79Re2xsZGuj+0lc3VmUHP1SzvjMahjZq7O9CJX2x/olZl/EhHnAl8HHtOwaYRq9r61Xp6+\nflabNm1rP+k0Y2MjjI9PdH18r5irM4Oaq59ajcegjpm5OrMnuZq9GLS8/RIRJ0fEW+qH24DdwDci\nYnm97jjgVuAO4KiIWBQRS4CDqH6IKkmaJ+3M1D8D/E1EfAXYGzgbuBdYExH71MtXZ+auiLiMquD3\nAs7PzO09yi1JmkHLUs/MnwB/MMOm582w7xqqX3+UJPWBbz6SpIJY6pJUEEtdkgpiqUtSQSx1SSqI\npS5JBbHUJakglrokFcRSl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6JBXEUpekgljq\nklQQS12SCmKpS1JBLHVJKoilLkkFsdQlqSCWuiQVxFKXpIIMN9sYEXsDa4EDgYXAKuAHwHrg/nq3\nD2XmlRFxKnA6sBNYlZnrexVakjSzpqUOnAQ8mJknR8R+wDeBvwRWZ+YlUztFxAHAmcBhwCLgtoi4\nKTN39Ci3JGkGrUr9KuDqenmIaha+FIiIWEE1Wz8bOBy4vS7xHRGxETgYuLMnqSVJM2pa6pn5EEBE\njFCV+0qq2zCXZ+ZdEXE+8DaqGfyWhkMngCWtnnx0dDHDwwu6jA5jYyNdH9tL5urMoObql3bGY1DH\nzFyd6UWuVjN1IuIpwLXABzPzioh4fGZurjdfC7wP+ArQmG4E2EwLmzZt6zxxbWxshPHxia6P7xVz\ndWZQc/VTq/EY1DEzV2f2JFezF4Omv/0SEfsDNwLnZubaevUNEXF4vfx84C7gDuCoiFgUEUuAg4AN\nXaWVJHWt1Uz9PGAUuCAiLqjXvQF4T0T8FPgRcFpmbo2Iy4BbqV4ozs/M7b0KLUmaWat76mcBZ82w\nadkM+64B1sxRLklSF3zzkSQVxFKXpIJY6pJUEEtdkgpiqUtSQSx1SSqIpS5JBbHUJakglrokFcRS\nl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6JBXEUpekgljqklQQS12SCmKpS1JBLHVJ\nKoilLkkFsdQlqSDDzTZGxN7AWuBAYCGwCvgOsA6YBDYAZ2Tm7og4FTgd2Amsysz1vYstSZpJq5n6\nScCDmXkU8CLg/cBqYGW9bghYEREHAGcCy4BjgYsiYmHvYkuSZtJ0pg5cBVxdLw9RzcKXArfU664H\njgF2Abdn5g5gR0RsBA4G7pzzxJKkWTUt9cx8CCAiRqjKfSVwcWZO1rtMAEuAfYEtDYdOrW9qdHQx\nw8MLuohdGRsb6frYXjJXZwY1V7+0Mx6DOmbm6kwvcrWaqRMRTwGuBT6YmVdExLsbNo8Am4Gt9fL0\n9U1t2rSts7QNxsZGGB+f6Pr4XjFXZwY1Vz+1Go9BHTNzdWZPcjV7MWh6Tz0i9gduBM7NzLX16nsi\nYnm9fBxwK3AHcFRELIqIJcBBVD9ElSTNo1Yz9fOAUeCCiLigXncWcFlE7APcC1ydmbsi4jKqgt8L\nOD8zt/cqtCRpZq3uqZ9FVeLTPW+GfdcAa+YolySpC775SJIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6\nJBXEUpekgljqklQQS12SCmKpS1JBLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtS\nQSx1SSqIpS5JBbHUJakglrokFcRSl6SCWOqSVBBLXZIKMtzOThFxBPCuzFweEYcC64H7680fyswr\nI+JU4HRgJ7AqM9f3JLEkaVYtSz0izgFOBn5Sr1oKrM7MSxr2OQA4EzgMWATcFhE3ZeaOuY8sSZpN\nOzP17wInAJ+oHy8FIiJWUM3WzwYOB26vS3xHRGwEDgbubHbi0dHFDA8v6DY7Y2MjXR/bS+bqzKDm\n6pd2xmNQx8xcnelFrpalnpnXRMSBDavuAC7PzLsi4nzgbcA3gS0N+0wAS1qde9OmbZ2lbTA2NsL4\n+ETXx/eKuTozqLn6qdV4DOqYmasze5Kr2YtBNz8ovTYz75paBg4FtgKNzzICbO7i3JKkPdBNqd8Q\nEYfXy88H7qKavR8VEYsiYglwELBhjjJKktrU1m+/TPMa4H0R8VPgR8Bpmbk1Ii4DbqV6oTg/M7fP\nYU5JUhvaKvXM/D5wZL18N7Bshn3WAGvmMpwkqTO++UiSCmKpS1JBLHVJKoilLkkFsdQlqSCWuiQV\nxFKXpIJ08+YjSSrCKe+8uW/P/Q+XrOjJeZ2pS1JBLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJU\nEEtdkgpiqUtSQSx1SSqIpS5JBbHUJakglrokFcRSl6SCWOqSVBBLXZIK0tYfyYiII4B3ZebyiPhV\nYB0wCWwAzsjM3RFxKnA6sBNYlZnre5RZkjSLljP1iDgHuBxYVK9aDazMzKOAIWBFRBwAnAksA44F\nLoqIhb2JLEmaTTu3X74LnNDweClwS718PfAC4HDg9szckZlbgI3AwXMZVJLUWsvbL5l5TUQc2LBq\nKDMn6+UJYAmwL7ClYZ+p9U2Nji5meHhB+2mnGRsb6frYXjJXZwY1V7+0Mx6DOmbm6kwvcnXzh6d3\nNyyPAJuBrfXy9PVNbdq0rYunr4yNjTA+PtH18b1irs4Maq5+ajUegzpm5upct7mavRh089sv90TE\n8nr5OOBW4A7gqIhYFBFLgIOofogqSZpH3czU3wisiYh9gHuBqzNzV0RcRlXwewHnZ+b2OcwpSWpD\nW6Wemd8HjqyX7wOeN8M+a4A1cxlOktQZ33wkSQWx1CWpIJa6JBXEUpekgljqklQQS12SCmKpS1JB\nLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgpiqUtSQSx1SSqIpS5JBbHUJakglrokFcRS\nl6SCWOqSVBBLXZIKYqlLUkEsdUkqiKUuSQUZ7vbAiLgb2Fo//B5wIbAOmAQ2AGdk5u49DShJal9X\npR4Ri4ChzFzesO46YGVmfjkiPgysAK6dk5SSpLZ0O1M/BFgcETfW5zgPWArcUm+/HjiGFqU+OrqY\n4eEFXUaAsbGRro/tJXN1ZlBz9Us74zGoY2auzvQiV7elvg24GLgceBpViQ9l5mS9fQJY0uokmzZt\n6/Lpq8EYH5/o+vheMVdnBjVXP7Uaj0EdM3N1rttczV4Mui31+4CNdYnfFxEPUs3Up4wAm7s8tySp\nS93+9sspwCUAEfFkYF/gxohYXm8/Drh1j9NJkjrS7Uz9Y8C6iLiN6rddTgEeANZExD7AvcDVcxNR\nktSurko9Mx8GXj7DpuftWRxJ0p7wzUeSVBBLXZIKYqlLUkEsdUkqiKUuSQWx1CWpIJa6JBXEUpek\ngljqklQQS12SCmKpS1JBLHVJKoilLkkFsdQlqSCWuiQVxFKXpIJY6pJUEEtdkgrS7d8o7bvj3/i5\nvj332jcf3bfnlqRmnKlLUkEsdUkqiKUuSQWx1CWpIJa6JBVkTn/7JSL2Aj4IHALsAF6VmRvn8jkk\nSbOb65n6y4BFmfkc4M3AJXN8fklSE3Nd6s8FvgCQmf8MHDbH55ckNTE0OTk5ZyeLiMuBazLz+vrx\nfwBPzcydc/YkkqRZzfVMfSsw0nh+C12S5s9cl/rtwIsBIuJI4FtzfH5JUhNz/dkv1wIvjIivAkPA\nK+f4/JKkJub0nrokqb9885EkFcRSl6SCWOqSVJCB/CMZrT5uICKOB94K7ATWZuaa+fiIgjZy/RFw\ndp3rW8BrM3N3RNxN9eueAN/LzDn9AXIbuV4PvAoYr1edDtzf7Jhe54qIA4BPN+z+m8CbM/PDvR6v\nhnxHAO/KzOXT1vfl+mojV1+urzZy9eX6aparn9dXROwNrAUOBBYCqzLzuobtPb2+BrLUafi4gfpX\nIy8BVsDPBuw9wLOBnwC3R8R1wLLZjpmnXI8BVgHPzMxtEfEp4KURcSMwNP0fwnzlqi0F/jgz75pa\nEREntDimp7ky80fA8jrLc4ALgTURsYjejxcRcQ5wMtU11Li+n9dXs1z9vL5mzVXr1/U1a64+X18n\nAQ9m5skRsR/wTeC6OkvPr69Bvf3S7OMGDgI2ZuamzHwYuA347RbHzEeuHcBvZea2+vEwsJ3qlXdx\nRNwYETfX/8PmMxdU/+jeEhG3RcRb2jxmPnIREUPA+4DXZOYu5me8AL4LnDDD+n5eX81y9fP6apYL\n+nd9tcrVr+vrKuCCenmIakY+pefX16CW+r7AlobHuyJieJZtE8CSFsf0PFdm7s7MHwNExOuAxwE3\nAduAi4FjgVcDn5zPXLVP1899NPDciHhpG8fMRy6A44FvZ2bWj+djvMjMa4CfzrCpn9fXrLn6fH01\nGy/o3/XVKhf04frKzIcycyIiRoCrgZUNm3t+fQ3q7ZdmHzcwfdsIsLnFMfORa+oe8ruBpwO/n5mT\nEXEf1SvzJHBfRDwIPAn4wXzkqmcq783MLfXjzwOHtvpaep2rwUnApQ2P52O8munn9dVUH6+vZpn6\neX21oy/XV0Q8herNmB/MzCsaNvX8+hrUmXqzjxu4F3haROwXEftQfevytRbHzEcugI8Ai4CXNXyb\nfAr1RxBHxJOpXpF/OI+59gU2RMTj6n+ARwN3tfG19DrXlMOArzY8no/xaqaf11cr/bq+munn9dWO\neb++ImJ/4Ebg3MxcO21zz6+vQZ2pP+LjBiLi5cDjMvOjEfEG4AaqF6W1mflfETEfH1Eway7gG8Cf\nArcCN0cEVDOEjwHrIuI2YBI4pQczllbjdR7wJar7sl/MzH+sZ319G6861xiwtZ41TZmP8XqEAbm+\nZs1Ff6+vWXP1+fpqlatf19d5wChwQURM3VtfAzx2Pq4vPyZAkgoyqLdfJEldsNQlqSCWuiQVxFKX\npIJY6pJUEEtdkgpiqUtSQf4Xq8Ou/tOBiMAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f441400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f250898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAEx9JREFUeJzt3XuQZGV5x/HvMAOsi8M6VEaplJdNIjyFJgJZwkUubkEC\n8ZZNqKS0DHghAloQQFREYEOZwhKCoLCJJCxZERIiEVxDUIQEEGEtAiwQXUI9CkqZpNQayAADKysL\nmz/6TNKuM909Z3qmp9/5fqoozq3ffp9+a3/9zunTpwe2bduGJKkMO/S6A5Kk7jHUJakghrokFcRQ\nl6SCGOqSVBBDXZIKMtTrDkizFRGXAodVq68DfgD8tFo/KDN/OuUDp25rGbA+Mw/vbi+l+WGoq+9l\n5imTyxHxGPDHmXlfzeZGgP270C2pJwx1LUoRsTtwFfBL1aavZuZq4PPASyLiQWAF8B7gRGAnYDfg\n/My8LCIGgQuB3wOeAv4NeF1mrqxm+5cAvwHsCNwKfDQzt85bgVq0PKeuxep44PuZ+ZvAocAeVRi/\nD/hpZu4DvKQ67i2ZuS/wDuAvqse/n0bo/zpwEPBrTW1/BtiYmSuAfWm8cZw+9yVJztS1eH0d+FpE\nvBr4V+DMzHwqIkYmD8jMZyLibcBbI2IPYB/gpdXutwBXZeZzABHxN8DkaaC3AftHxJ9U6y+Z+3Kk\nBmfqWpQy817gV4DLgeXAPRHxxuZjIuKVwIPAa4C7gHOadm8FBprWX2haHgT+KDP3qWb8BwAnd7sG\naSqGuhaliDgfWJ2ZXwFOBR4C9qQR1oMRMQDsB4wB52XmzTRm4FTn078KHBMRO0fEEPBeYPLueDcD\nH4qIgYjYGbgBQ13zxFDXYvVZYJ+I2ATcR+MyyH8AfgTcDzwM3Av8F5AR8QDwahoh/1rgShofjj4A\nfAv4GbC5avsUYBfgO8C3q/9PnouX5tSAt96VZi4ijgRenpl/V61fAjyXmR/rbc+02PlBqYoVEXcC\nw9PsPjQzJ2bR/EPARyPiozT+Hf078MFZtCd1hTN1SSqI59QlqSCGuiQVpKfn1MfGJmqf+xkZWcr4\n+Ob2B/YBa1l4SqkDrGWhmk0to6PDA9Pt69uZ+tDQYK+70DXWsvCUUgdYy0I1V7X0bahLkn6RoS5J\nBTHUJakghrokFaTl1S8RsSOwjsZd7HYGzgP+g8Z9L7YBm4CTMvPFiDiexo8JbKVxA6Qb567bkqSp\ntJupHwM8kZmHAr8L/CVwMXBOtW0AWFX9iswpwMHAUcCnqrvTSZLmUbvr1L8EXFctD9CYha8A7qi2\n3QQcSeNe0hsycwuwJSIeAd5A4y53kqR50jLUM/MZgIgYphHu5wCfzszJLw1NAMuAXWn8TiPbbW9p\nZGTprK7VHB2d7l5N/cdaFp5S6gBrWajmopa23yiNiFcB64HPZeY1EdF8X+hh4EngaX7+bniT21ua\nzTfDRkeHGRubzU32Fg5rWXhKqQOsZaGaTS2t3gzafVD6CuAW4OTMvLXa/EBErMzMbwBvBm4H7gE+\nGRFLaHyguheND1ElacE67vzbevbc/3zRqjlpt91M/SxgBFgdEaurbacCl0bETjR+Hea6zHwhIi4F\n7qTx4evZkz/IK0maP+3OqZ9KI8S396Ypjl0LrO1SvyRJNfjlI0kqiKEuSQUx1CWpIIa6JBXEUJek\nghjqklQQQ12SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqI\noS5JBWn3G6UARMQBwAWZuTIivgjsXu1aDtydme+MiEuAQ4DJn8delZlPdbvDkqTptQ31iDgDOBZ4\nFiAz31ltHwFuBz5UHboCOCozH5+brkqS2unk9MujwNFTbP8EsCYzfxQROwB7AJdHxIaIOK6bnZQk\ndabtTD0zr4+I5c3bIuLlwBH8/yx9F2ANcDEwCNweEfdl5rdbtT0yspShocE6/QZgdHS49mMXGmtZ\neEqpA6xloZqLWjo6pz6FPwSuycwXqvXNwCWZuRkgIm4D9gZahvr4+OaaT994McbGJtof2AesZeEp\npQ6wloWsbi2t3gzqXv3y28BNTet7AhsiYjAidqTxgen9NduWJNVUN9QD+P7kSmY+DFwN3A3cAVyV\nmQ/NvnuSpJno6PRLZj4GHNi0/vopjrkQuLBrPZMkzZhfPpKkghjqklQQQ12SCmKoS1JBDHVJKoih\nLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFcRQl6SC1P3h\naS0yx51/W0+ed92Zh/fkeaV+1VGoR8QBwAWZuTIi9gVuBL5X7b4sM6+NiOOBE4GtwHmZeeOc9FiS\nNK22oR4RZwDHAs9Wm1YAF2fmRU3H7A6cAuwHLAHuioh/ycwt3e+yJGk6nczUHwWOBq6u1lcAERGr\naMzWTwP2BzZUIb4lIh4B3gDc2/0uS5Km0zbUM/P6iFjetOke4IrM3BgRZwPnAg8CTzUdMwEsa9f2\nyMhShoYGZ9bjJqOjw7Ufu9CUVEs39fJ1KWlMrGVhmota6nxQuj4zn5xcBtYA3wSaezcMPLn9A7c3\nPr65xtM3jI4OMzY2UfvxC0lJtXRbr16XksbEWhauurW0ejOoc0njzRGxf7V8BLCRxuz90IhYEhHL\ngL2ATTXaliTNQp2Z+geBNRHxPPBj4ITMfDoiLgXupPFGcXZmPtfFfkqSOtBRqGfmY8CB1fL9wMFT\nHLMWWNvNzkmSZsZvlEpSQQx1SSqIoS5JBTHUJakghrokFcRQl6SCGOqSVBBDXZIKYqhLUkEMdUkq\niKEuSQUx1CWpIIa6JBXEUJekghjqklQQQ12SCmKoS1JBDHVJKkhHP2cXEQcAF2TmyojYB1gDvABs\nAd6dmT+JiEuAQ4DJn8delZlPzUWnJUlTaxvqEXEGcCzwbLXpEuBPM/PBiDgR+BhwOrACOCozH5+r\nzkqSWuvk9MujwNFN6+/MzAer5SHguYjYAdgDuDwiNkTEcV3upySpA21n6pl5fUQsb1r/EUBEvBE4\nGTgM2IXGKZmLgUHg9oi4LzO/3artkZGlDA0N1u786Ohw7ccuNCXV0k29fF1KGhNrWZjmopaOzqlv\nLyLeAZwNvDUzxyJiELgkMzdX+28D9gZahvr4+OY6Tw80XoyxsYn2B/aBkmrptl69LiWNibUsXHVr\nafVmMONQj4hjgBOBlZn5P9XmPYFrI2JfGqd0DgG+MPOuSpJmY0ahXs3ILwV+CHw5IgDuyMxzI+Jq\n4G7geeCqzHyo252VJLXWUahn5mPAgdXqbtMccyFwYXe6JUmqwy8fSVJBDHVJKoihLkkFMdQlqSCG\nuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFcRQl6SCGOqSVBBDXZIKYqhL\nUkEMdUkqiKEuSQXp6DdKI+IA4ILMXBkRrwWuBLYBm4CTMvPFiDgeOBHYCpyXmTfOUZ8lSdNoO1OP\niDOAK4Al1aaLgXMy81BgAFgVEbsDpwAHA0cBn4qIneemy5Kk6XQyU38UOBq4ulpfAdxRLd8EHAm8\nAGzIzC3Aloh4BHgDcG+rhkdGljI0NFin3wCMjg7XfuxCU1It3dTL16WkMbGWhWkuamkb6pl5fUQs\nb9o0kJnbquUJYBmwK/BU0zGT21saH9/ceU+3Mzo6zNjYRO3HLyQl1dJtvXpdShoTa1m46tbS6s2g\nzgelLzYtDwNPAk9Xy9tvlyTNozqh/kBErKyW3wzcCdwDHBoRSyJiGbAXjQ9RJUnzqKOrX7bzYWBt\nROwEPAxcl5kvRMSlNAJ+B+DszHyui/2UJHWgo1DPzMeAA6vl7wJvmuKYtcDabnZOkjQzfvlIkgpi\nqEtSQQx1SSqIoS5JBTHUJakghrokFaTOdeqS5tBx59/Wk+ddd+bhPXledZczdUkqiKEuSQUx1CWp\nIIa6JBXEUJekgvTt1S9v//A/9ey5vUpA0kLlTF2SCmKoS1JBDHVJKoihLkkFMdQlqSC1rn6JiPcC\n761WlwD7AAcBNwLfq7ZflpnXzrJ/kqQZqBXqmXklcCVARPwVsA5YAVycmRd1q3OSpJmZ1XXqEbEf\n8PrMPCkiLmtsilU0ZuunZeZEq8ePjCxlaGhwNl3oidHR4b5oswS9fF0W25j0S7390s9OzEUts/3y\n0VnAJ6rle4ArMnNjRJwNnAt8pNWDx8c3z/Lpe2NsrOV71YyNjg53vc1S9Op1WYxj0g/1ljYudWtp\n9WZQ+4PSiHgZEJl5e7VpfWZunFwG9q3btiSpntlc/XIYcGvT+s0RsX+1fASw8RcfIkmaS7M5/RLA\n95vWPwisiYjngR8DJ8ymY5Kkmasd6pl54Xbr9wMHz7pHkqTa/PKRJBXEUJekghjqklQQQ12SCmKo\nS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtSQQx1SSqIoS5JBTHUJakghrok\nFcRQl6SC1P45u4i4H3i6Wv0B8EngSmAbsAk4KTNfnG0HJUmdqxXqEbEEGMjMlU3bbgDOycxvRMRf\nA6uA9V3ppSSpI3Vn6nsDSyPilqqNs4AVwB3V/puAIzHUJWle1Q31zcCngSuAPWiE+EBmbqv2TwDL\n2jUyMrKUoaHBml3ondHR4b5oswS9fF0W25j0S7390s9OzEUtdUP9u8AjVYh/NyKeoDFTnzQMPNmu\nkfHxzTWfvrfGxia62t7o6HDX2yxFr16XxTgm/VBvaeNSt5ZWbwZ1r345DrgIICJ+GdgVuCUiVlb7\n3wzcWbNtSVJNdWfqfwtcGRF30bja5TjgcWBtROwEPAxc150uSpI6VSvUM/NnwLum2PWm2XVHkjQb\nfvlIkgpiqEtSQQx1SSqIoS5JBTHUJakghrokFcRQl6SCGOqSVBBDXZIKYqhLUkEMdUkqiKEuSQUx\n1CWpIIa6JBXEUJekghjqklQQQ12SCmKoS1JBav2cXUTsCKwDlgM7A+cB/wncCHyvOuyyzLy2C32U\nJHWo7g9PHwM8kZnHRsRuwIPAnwMXZ+ZFXeudJGlG6ob6l4DrquUBYCuwAoiIWEVjtn5aZk7MvouS\npE7VCvXMfAYgIoZphPs5NE7DXJGZGyPibOBc4COt2hkZWcrQ0GCdLvTU6OhwX7RZgl6+LottTPql\n3n7pZyfmopa6M3Ui4lXAeuBzmXlNRLwsM5+sdq8H1rRrY3x8c92n76mxse7+ATI6Otz1NkvRq9dl\nMY5JP9Rb2rjUraXVm0Gtq18i4hXALcDHMnNdtfnmiNi/Wj4C2FinbUlSfXVn6mcBI8DqiFhdbTsd\n+ExEPA/8GDihC/2TJM1A3XPqpwKnTrHr4Nl1R5I0G375SJIKYqhLUkEMdUkqiKEuSQUx1CWpIIa6\nJBXEUJekghjqklQQQ12SCmKoS1JBDHVJKoihLkkFMdQlqSCGuiQVxFCXpIIY6pJUEENdkgpiqEtS\nQer+RumUImIH4HPA3sAW4P2Z+Ug3n0OSNL1uz9R/H1iSmQcBZwIXdbl9SVIL3Q71Q4CvA2Tm3cB+\nXW5fktTCwLZt27rWWERcAVyfmTdV6z8EfjUzt3btSSRJ0+r2TP1pYLi5fQNdkuZPt0N9A/AWgIg4\nEPhOl9uXJLXQ1atfgPXA70TEt4AB4H1dbl+S1EJXz6lLknrLLx9JUkEMdUkqiKEuSQXp9gelXdfu\n1gMR8Xbgz4CtwLrMXNuTjrbRQR0fAt4PjFWbTszMnPeOzkBEHABckJkrt9veF2PSrEUtfTEuEbEj\nsA5YDuwMnJeZNzTt75sx6aCWvhgTgIgYBNYCAWwDPpCZm5r2d31cFnyo03TrgeoyyYuAVfB/g/8Z\n4LeAZ4ENEXFDZv6kZ72d3rR1VFYA787MjT3p3QxFxBnAsTRe9+bt/TQmwPS1VPplXI4BnsjMYyNi\nN+BB4AboyzGZtpZKv4wJwNsBMvPgiFgJfJI5zq9+OP3S6tYDewGPZOZ4Zv4MuAs4bP672JF2t1BY\nAXw8Iu6KiI/Pd+dqeBQ4eort/TQmk6arBfpnXL4ErK6WB2jM/Cb125i0qgX6Z0zIzK8AJ1SrrwGe\nbNo9J+PSD6G+K/BU0/oLETE0zb4JYNl8dWyGWtUB8EXgA8DhwCER8bb57NxMZeb1wPNT7OqnMQFa\n1gJ9Mi6Z+UxmTkTEMHAdcE7T7r4akza1QJ+MyaTM3BoRXwDWAH/ftGtOxqUfQr3VrQe23zfMz78T\nLiTT1hERA8BnM/Px6h37q8C+PehjN/TTmLTUb+MSEa8Cbgeuzsxrmnb13ZhMV0u/jcmkzHwPsCew\nNiJ2qTbPybj0wzn1DTTOS/3jFLceeBjYozrv9gyNP10+Pf9d7EirOnYFNkXEXjTOrR1O44OiftRP\nY9JO34xLRLwCuAU4OTNv3W53X41Jm1r6ZkwAIuJY4JWZ+SlgM/Bi9R/M0bj0Q6j/wq0HIuJdwEsz\n8/KIOB24mcZfHesy87972NdW2tVxFo2ZyRbg1sz8Wg/7OmN9OiZT6tNxOQsYAVZHxOT56LXALn04\nJu1q6ZcxAfgy8PmI+CawI3Aa8AcRMWf/VrxNgCQVpB/OqUuSOmSoS1JBDHVJKoihLkkFMdQlqSCG\nuiQVxFCXpIL8LyA99oIJZplgAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f4142b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niKEuSQUx1CWpIIa6JBXEUJekgvwfSEaZmahza2kAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eb9fa20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\noS5JhRjqklTI/wLvRHV2t76x4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eb9f8d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11f01c208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZIKYqhLUkH+D3AyTG2K2rveAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eaf2b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEFCAYAAAAsU2YoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11ed01e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSQX5/wGFO72EE/vpAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e8ce828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nXZIKYqlLUkEsdUkqiKUuSQWx1CWpIP8H5bGwFHZ0eyYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e805ba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW8AAAEFCAYAAAAsU2YoAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3pJUoP8Fpl5zgs94p2gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e652860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXsAAAEFCAYAAAACFke6AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAMNekgr4P9A2TA9UjceUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e8b83c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eb0e630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/hfNMkGGe+riMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11efb3780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11eba8518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXUAAAEFCAYAAAAc33cJAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqSCGuiQV5H8At4WSFffK1sgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11cad6048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "input = df.drop(['TwoYearSurvival'], axis=1)\n",
    "\n",
    "for column in input:\n",
    "    plt.hist(input[column].dropna())\n",
    "    plt.title(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are more patients in the more recent years of the study. These patients may end up living longer since they are being treated with more state of the art technology. While this may skew the data towards survival, technology is always improving, and we would likely see survival improve with time in most medical data sets. In this study, since all patients are undergoing the standard NSCLC protocol, we may not see that year of treatment has any effect on survival.<br>\n",
    "\n",
    "There is a relatively normal age distribution, with the majority of patients ranging from 65-75. More people received chemotherapy than did not receive chemotherapy. Although the overall treatment time ranges from 1-96 months, there is only one observation at 96 months; the rest of the patients fall under 50 months, which is about 4 years.<br>\n",
    "\n",
    "GTV1 might have been a good feature if it had more than 3 datapoints. The tumorload has a near exponential decrease, which means that most patients have a relatively low tumor load.<br>\n",
    "\n",
    "The toxeso histogram shows that zero esophageal toxicity is most common, with high numbers of patients at levels 1 and 2 as well. Few patients have severe toxicity at 3, and only 1 patients has level 4.<br>\n",
    "\n",
    "The dose per fraction also maxes out at the beginning. From a medical perspective, the lower the dose the better, only the minimum biological effective dose should be used to help prevent side effects and complications. The same trend is seen in second dose per fraction. The number of total fractions given is more varied; it peaks, drops, and rises again. The same trned is seen in total dose.<br>\n",
    "\n",
    "For people who smoke, the common quantity to consume is 1 pack per day. The next most common quantity is 1/2 pack per day, and shortly behind that is 0 packs (non-smokers).<br>\n",
    "\n",
    "There is a healthy distribution of values for both T and N classifications, which will help to build a reliable model. There is, however, only 1 value for the M classification, so this feature will likely not make the cut in the final model.<br>\n",
    "\n",
    "FEV has a near perfect normal distribution, which may make it a good feature to include.\n",
    "\n",
    "Cumulative total tumor dose has a much more normal distribution than total tumor dose, which makes sense because it has over double the number of observations. The normal distribution might make this another good feature to include.<br>\n",
    "\n",
    "Lungv20 has a normal distribution as well. This makes intuitive sense because this metric should be targeted to deliver as much medicine to the lungs as possible, but if too much is given the patient will develop pneumonitis. The distribution should therefore be centered around the middle.<br>\n",
    "\n",
    "More patients tended not to have dyspnea at baseline, with the majority of values falling at 0 or 1. The patients that did have dyspnea likely started with a stronger disease burden, which may correlate to their survival. <br>\n",
    "\n",
    "The variables with normal distributions are age, FEV, Cumulative Total Tumor Dose, and lungv20. We will keep these in mind when moving forward."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yearrt                        0.198887\n",
      "med                           0.124601\n",
      "maxeso                        0.104804\n",
      "gender                        0.066701\n",
      "intake_who                    0.102559\n",
      "age                           0.067338\n",
      "chemo                        -0.053787\n",
      "ott                          -0.180136\n",
      "chemo3g                      -0.044269\n",
      "gtv1                               NaN\n",
      "tumorload                     0.177023\n",
      "toxeso                        0.093582\n",
      "toxesohigh2                   0.073368\n",
      "pretoxeso                    -0.032043\n",
      "dose per fraction            -0.050494\n",
      "fractions                    -0.091325\n",
      "total dose                   -0.034500\n",
      "second dose per fracion       0.022480\n",
      "second fractions             -0.047052\n",
      "second total dose            -0.098626\n",
      "BED                          -0.049029\n",
      "Modality                      0.062833\n",
      "PacksPerDay                   0.119660\n",
      "SmokingStatus                -0.037060\n",
      "IsSCLC                             NaN\n",
      "T_stage                      -0.009541\n",
      "N_stage                       0.137334\n",
      "M_stage                            NaN\n",
      "PA                            0.024870\n",
      "Locatie                      -0.039418\n",
      "FEV                          -0.106958\n",
      "CumultativeTotalTumorDose    -0.147027\n",
      "meanlungdose                  0.097729\n",
      "lungv20                       0.196407\n",
      "CumOTT                       -0.179871\n",
      "OverallBaselineDysp           0.036435\n",
      "OverallPostRTDyspFullScore    0.127668\n",
      "DyspGT2                       0.098367\n",
      "DeltaDyspGe1                  0.067666\n",
      "TreatmentType                      NaN\n",
      "TwoYearSurvival               1.000000\n",
      "Name: TwoYearSurvival, dtype: float64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearrt</th>\n",
       "      <th>med</th>\n",
       "      <th>maxeso</th>\n",
       "      <th>gender</th>\n",
       "      <th>intake_who</th>\n",
       "      <th>age</th>\n",
       "      <th>chemo</th>\n",
       "      <th>ott</th>\n",
       "      <th>chemo3g</th>\n",
       "      <th>gtv1</th>\n",
       "      <th>tumorload</th>\n",
       "      <th>toxeso</th>\n",
       "      <th>toxesohigh2</th>\n",
       "      <th>pretoxeso</th>\n",
       "      <th>dose per fraction</th>\n",
       "      <th>fractions</th>\n",
       "      <th>total dose</th>\n",
       "      <th>second dose per fracion</th>\n",
       "      <th>second fractions</th>\n",
       "      <th>second total dose</th>\n",
       "      <th>BED</th>\n",
       "      <th>Modality</th>\n",
       "      <th>PacksPerDay</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>IsSCLC</th>\n",
       "      <th>T_stage</th>\n",
       "      <th>N_stage</th>\n",
       "      <th>M_stage</th>\n",
       "      <th>PA</th>\n",
       "      <th>Locatie</th>\n",
       "      <th>FEV</th>\n",
       "      <th>CumultativeTotalTumorDose</th>\n",
       "      <th>meanlungdose</th>\n",
       "      <th>lungv20</th>\n",
       "      <th>CumOTT</th>\n",
       "      <th>OverallBaselineDysp</th>\n",
       "      <th>OverallPostRTDyspFullScore</th>\n",
       "      <th>DyspGT2</th>\n",
       "      <th>DeltaDyspGe1</th>\n",
       "      <th>TreatmentType</th>\n",
       "      <th>TwoYearSurvival</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>yearrt</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.035484</td>\n",
       "      <td>0.170502</td>\n",
       "      <td>0.022171</td>\n",
       "      <td>0.101750</td>\n",
       "      <td>0.092262</td>\n",
       "      <td>-0.132144</td>\n",
       "      <td>-0.074144</td>\n",
       "      <td>-0.124391</td>\n",
       "      <td>0.817770</td>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.019743</td>\n",
       "      <td>-0.011638</td>\n",
       "      <td>-0.028859</td>\n",
       "      <td>-0.199189</td>\n",
       "      <td>0.065645</td>\n",
       "      <td>-0.026370</td>\n",
       "      <td>-0.274645</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.088090</td>\n",
       "      <td>-0.033742</td>\n",
       "      <td>0.785852</td>\n",
       "      <td>0.370652</td>\n",
       "      <td>-0.032330</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021221</td>\n",
       "      <td>0.009848</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024006</td>\n",
       "      <td>-0.038233</td>\n",
       "      <td>-0.099301</td>\n",
       "      <td>0.024296</td>\n",
       "      <td>-0.093961</td>\n",
       "      <td>-0.078641</td>\n",
       "      <td>-0.073638</td>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.083471</td>\n",
       "      <td>-0.000678</td>\n",
       "      <td>-0.061878</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.198887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>med</th>\n",
       "      <td>0.035484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.685031</td>\n",
       "      <td>-0.013612</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0.103075</td>\n",
       "      <td>-0.323796</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.343370</td>\n",
       "      <td>0.276970</td>\n",
       "      <td>0.176292</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>0.128879</td>\n",
       "      <td>-0.278657</td>\n",
       "      <td>-0.167061</td>\n",
       "      <td>0.365426</td>\n",
       "      <td>-0.409917</td>\n",
       "      <td>-0.442843</td>\n",
       "      <td>-0.014945</td>\n",
       "      <td>-0.037155</td>\n",
       "      <td>-0.011438</td>\n",
       "      <td>-0.032434</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.095781</td>\n",
       "      <td>0.322424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.031029</td>\n",
       "      <td>-0.117122</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>-0.282365</td>\n",
       "      <td>0.452758</td>\n",
       "      <td>0.541446</td>\n",
       "      <td>-0.323505</td>\n",
       "      <td>0.110745</td>\n",
       "      <td>0.043273</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>-0.090430</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.124601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maxeso</th>\n",
       "      <td>0.170502</td>\n",
       "      <td>0.685031</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.064168</td>\n",
       "      <td>0.155735</td>\n",
       "      <td>0.150098</td>\n",
       "      <td>-0.060674</td>\n",
       "      <td>-0.259238</td>\n",
       "      <td>-0.205260</td>\n",
       "      <td>0.995527</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>-0.060629</td>\n",
       "      <td>-0.210410</td>\n",
       "      <td>0.297460</td>\n",
       "      <td>-0.128770</td>\n",
       "      <td>0.114528</td>\n",
       "      <td>0.330205</td>\n",
       "      <td>-0.170795</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>0.232297</td>\n",
       "      <td>0.118773</td>\n",
       "      <td>0.339117</td>\n",
       "      <td>0.041726</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.088251</td>\n",
       "      <td>0.063772</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>-0.108905</td>\n",
       "      <td>-0.080982</td>\n",
       "      <td>-0.029768</td>\n",
       "      <td>0.256328</td>\n",
       "      <td>0.452165</td>\n",
       "      <td>-0.258884</td>\n",
       "      <td>0.160408</td>\n",
       "      <td>0.032826</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.163323</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.104804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gender</th>\n",
       "      <td>0.022171</td>\n",
       "      <td>-0.013612</td>\n",
       "      <td>0.064168</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.052541</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>-0.056850</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>-0.076631</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.145503</td>\n",
       "      <td>-0.109016</td>\n",
       "      <td>-0.079475</td>\n",
       "      <td>-0.105280</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>-0.161737</td>\n",
       "      <td>0.128467</td>\n",
       "      <td>0.095235</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.042404</td>\n",
       "      <td>0.204991</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>-0.038292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075692</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>-0.148245</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>-0.059605</td>\n",
       "      <td>-0.004486</td>\n",
       "      <td>-0.035608</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>-0.016519</td>\n",
       "      <td>0.062249</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.066701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>intake_who</th>\n",
       "      <td>0.101750</td>\n",
       "      <td>0.127662</td>\n",
       "      <td>0.155735</td>\n",
       "      <td>0.052541</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.160668</td>\n",
       "      <td>-0.204388</td>\n",
       "      <td>-0.052391</td>\n",
       "      <td>-0.233440</td>\n",
       "      <td>0.420437</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>0.037378</td>\n",
       "      <td>-0.040470</td>\n",
       "      <td>0.108461</td>\n",
       "      <td>-0.032267</td>\n",
       "      <td>0.061639</td>\n",
       "      <td>0.257016</td>\n",
       "      <td>-0.181464</td>\n",
       "      <td>-0.107216</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058642</td>\n",
       "      <td>-0.133962</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.080843</td>\n",
       "      <td>-0.165784</td>\n",
       "      <td>-0.098427</td>\n",
       "      <td>-0.082891</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>-0.052659</td>\n",
       "      <td>0.435516</td>\n",
       "      <td>0.336889</td>\n",
       "      <td>0.232220</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.102559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>0.092262</td>\n",
       "      <td>0.041787</td>\n",
       "      <td>0.150098</td>\n",
       "      <td>0.215333</td>\n",
       "      <td>0.160668</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.380028</td>\n",
       "      <td>-0.176119</td>\n",
       "      <td>-0.434831</td>\n",
       "      <td>-0.384586</td>\n",
       "      <td>-0.132469</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>-0.160623</td>\n",
       "      <td>-0.238382</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>0.040062</td>\n",
       "      <td>0.118013</td>\n",
       "      <td>0.213730</td>\n",
       "      <td>-0.131216</td>\n",
       "      <td>-0.109096</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>0.091707</td>\n",
       "      <td>-0.369649</td>\n",
       "      <td>-0.201562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.079190</td>\n",
       "      <td>-0.243414</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.109747</td>\n",
       "      <td>-0.065149</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>-0.019162</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>0.183543</td>\n",
       "      <td>-0.176510</td>\n",
       "      <td>0.158830</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemo</th>\n",
       "      <td>-0.132144</td>\n",
       "      <td>0.103075</td>\n",
       "      <td>-0.060674</td>\n",
       "      <td>-0.056850</td>\n",
       "      <td>-0.204388</td>\n",
       "      <td>-0.380028</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.212733</td>\n",
       "      <td>0.932458</td>\n",
       "      <td>0.907322</td>\n",
       "      <td>0.108469</td>\n",
       "      <td>0.311989</td>\n",
       "      <td>0.216224</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>-0.252915</td>\n",
       "      <td>-0.153679</td>\n",
       "      <td>-0.382522</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.351451</td>\n",
       "      <td>-0.147750</td>\n",
       "      <td>0.151648</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.309738</td>\n",
       "      <td>0.469623</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.051460</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.271034</td>\n",
       "      <td>-0.103707</td>\n",
       "      <td>0.166079</td>\n",
       "      <td>-0.045534</td>\n",
       "      <td>0.213209</td>\n",
       "      <td>-0.302601</td>\n",
       "      <td>-0.229349</td>\n",
       "      <td>-0.119252</td>\n",
       "      <td>0.075513</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.053787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ott</th>\n",
       "      <td>-0.074144</td>\n",
       "      <td>-0.323796</td>\n",
       "      <td>-0.259238</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>-0.052391</td>\n",
       "      <td>-0.176119</td>\n",
       "      <td>0.212733</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.266783</td>\n",
       "      <td>-0.695739</td>\n",
       "      <td>-0.133776</td>\n",
       "      <td>0.193045</td>\n",
       "      <td>0.086609</td>\n",
       "      <td>0.169078</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>0.191954</td>\n",
       "      <td>-0.374661</td>\n",
       "      <td>0.172864</td>\n",
       "      <td>0.268432</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>-0.074765</td>\n",
       "      <td>0.201871</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126577</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.084749</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>-0.314085</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>-0.106849</td>\n",
       "      <td>-0.095122</td>\n",
       "      <td>-0.046729</td>\n",
       "      <td>0.043190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.180136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chemo3g</th>\n",
       "      <td>-0.124391</td>\n",
       "      <td>0.015743</td>\n",
       "      <td>-0.205260</td>\n",
       "      <td>-0.076631</td>\n",
       "      <td>-0.233440</td>\n",
       "      <td>-0.434831</td>\n",
       "      <td>0.932458</td>\n",
       "      <td>0.266783</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.907322</td>\n",
       "      <td>0.143610</td>\n",
       "      <td>0.339678</td>\n",
       "      <td>0.252552</td>\n",
       "      <td>0.361789</td>\n",
       "      <td>-0.304678</td>\n",
       "      <td>-0.220716</td>\n",
       "      <td>-0.483641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.427028</td>\n",
       "      <td>-0.152546</td>\n",
       "      <td>0.148943</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.252156</td>\n",
       "      <td>0.463517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.066528</td>\n",
       "      <td>0.076412</td>\n",
       "      <td>0.285565</td>\n",
       "      <td>-0.136605</td>\n",
       "      <td>0.163836</td>\n",
       "      <td>-0.138129</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>-0.333993</td>\n",
       "      <td>-0.239390</td>\n",
       "      <td>-0.134257</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044269</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gtv1</th>\n",
       "      <td>0.817770</td>\n",
       "      <td>0.996419</td>\n",
       "      <td>0.995527</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.420437</td>\n",
       "      <td>-0.384586</td>\n",
       "      <td>0.907322</td>\n",
       "      <td>-0.695739</td>\n",
       "      <td>0.907322</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.817770</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.907322</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.994959</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.999307</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.744798</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tumorload</th>\n",
       "      <td>0.001419</td>\n",
       "      <td>0.343370</td>\n",
       "      <td>0.080694</td>\n",
       "      <td>0.145503</td>\n",
       "      <td>0.060034</td>\n",
       "      <td>-0.132469</td>\n",
       "      <td>0.108469</td>\n",
       "      <td>-0.133776</td>\n",
       "      <td>0.143610</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.062906</td>\n",
       "      <td>0.082007</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>-0.050977</td>\n",
       "      <td>-0.189986</td>\n",
       "      <td>-0.246227</td>\n",
       "      <td>-0.102610</td>\n",
       "      <td>-0.187413</td>\n",
       "      <td>-0.322491</td>\n",
       "      <td>-0.086650</td>\n",
       "      <td>-0.005453</td>\n",
       "      <td>0.130804</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.359041</td>\n",
       "      <td>0.118654</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.100813</td>\n",
       "      <td>0.075595</td>\n",
       "      <td>-0.265619</td>\n",
       "      <td>0.173426</td>\n",
       "      <td>0.120387</td>\n",
       "      <td>-0.133568</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>-0.026728</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxeso</th>\n",
       "      <td>0.019743</td>\n",
       "      <td>0.276970</td>\n",
       "      <td>0.041139</td>\n",
       "      <td>-0.109016</td>\n",
       "      <td>0.017873</td>\n",
       "      <td>-0.196950</td>\n",
       "      <td>0.311989</td>\n",
       "      <td>0.193045</td>\n",
       "      <td>0.339678</td>\n",
       "      <td>0.817770</td>\n",
       "      <td>0.062906</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689074</td>\n",
       "      <td>0.547655</td>\n",
       "      <td>-0.152203</td>\n",
       "      <td>-0.036039</td>\n",
       "      <td>-0.212466</td>\n",
       "      <td>0.143601</td>\n",
       "      <td>-0.179079</td>\n",
       "      <td>-0.145759</td>\n",
       "      <td>-0.178598</td>\n",
       "      <td>-0.038318</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050498</td>\n",
       "      <td>0.332101</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>-0.057487</td>\n",
       "      <td>0.066401</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.128101</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>0.193106</td>\n",
       "      <td>-0.096965</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>-0.027473</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.093582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>toxesohigh2</th>\n",
       "      <td>-0.011638</td>\n",
       "      <td>0.176292</td>\n",
       "      <td>-0.060629</td>\n",
       "      <td>-0.079475</td>\n",
       "      <td>0.037378</td>\n",
       "      <td>-0.160623</td>\n",
       "      <td>0.216224</td>\n",
       "      <td>0.086609</td>\n",
       "      <td>0.252552</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.082007</td>\n",
       "      <td>0.689074</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.471345</td>\n",
       "      <td>-0.174210</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>-0.140665</td>\n",
       "      <td>0.130618</td>\n",
       "      <td>-0.072486</td>\n",
       "      <td>-0.040059</td>\n",
       "      <td>-0.138096</td>\n",
       "      <td>-0.035275</td>\n",
       "      <td>-0.112897</td>\n",
       "      <td>-0.026687</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.205676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>-0.022085</td>\n",
       "      <td>0.055168</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>0.142954</td>\n",
       "      <td>-0.009286</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>-0.041804</td>\n",
       "      <td>0.058098</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>0.062647</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pretoxeso</th>\n",
       "      <td>-0.028859</td>\n",
       "      <td>0.010657</td>\n",
       "      <td>-0.210410</td>\n",
       "      <td>-0.105280</td>\n",
       "      <td>-0.040470</td>\n",
       "      <td>-0.238382</td>\n",
       "      <td>0.297100</td>\n",
       "      <td>0.169078</td>\n",
       "      <td>0.361789</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.060811</td>\n",
       "      <td>0.547655</td>\n",
       "      <td>0.471345</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.092540</td>\n",
       "      <td>-0.078108</td>\n",
       "      <td>-0.287549</td>\n",
       "      <td>0.332972</td>\n",
       "      <td>-0.221932</td>\n",
       "      <td>-0.200561</td>\n",
       "      <td>-0.158301</td>\n",
       "      <td>-0.016978</td>\n",
       "      <td>0.067265</td>\n",
       "      <td>-0.059723</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.064306</td>\n",
       "      <td>0.210275</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.059345</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>-0.010079</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>-0.151055</td>\n",
       "      <td>0.169078</td>\n",
       "      <td>-0.126220</td>\n",
       "      <td>-0.054245</td>\n",
       "      <td>-0.057827</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dose per fraction</th>\n",
       "      <td>-0.199189</td>\n",
       "      <td>0.128879</td>\n",
       "      <td>0.297460</td>\n",
       "      <td>0.017366</td>\n",
       "      <td>0.108461</td>\n",
       "      <td>0.080575</td>\n",
       "      <td>-0.252915</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>-0.304678</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050977</td>\n",
       "      <td>-0.152203</td>\n",
       "      <td>-0.174210</td>\n",
       "      <td>-0.092540</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.376706</td>\n",
       "      <td>0.366112</td>\n",
       "      <td>0.525856</td>\n",
       "      <td>-0.199954</td>\n",
       "      <td>-0.082981</td>\n",
       "      <td>0.578708</td>\n",
       "      <td>-0.004604</td>\n",
       "      <td>-0.031372</td>\n",
       "      <td>-0.103177</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.023393</td>\n",
       "      <td>-0.168780</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050780</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.096442</td>\n",
       "      <td>0.081345</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>-0.010107</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>-0.036952</td>\n",
       "      <td>-0.008059</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050494</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fractions</th>\n",
       "      <td>0.065645</td>\n",
       "      <td>-0.278657</td>\n",
       "      <td>-0.128770</td>\n",
       "      <td>0.081317</td>\n",
       "      <td>-0.032267</td>\n",
       "      <td>0.040062</td>\n",
       "      <td>-0.153679</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>-0.220716</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.189986</td>\n",
       "      <td>-0.036039</td>\n",
       "      <td>0.019748</td>\n",
       "      <td>-0.078108</td>\n",
       "      <td>-0.376706</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.599352</td>\n",
       "      <td>-0.525856</td>\n",
       "      <td>0.199954</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>0.431702</td>\n",
       "      <td>-0.049823</td>\n",
       "      <td>0.121239</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.056282</td>\n",
       "      <td>-0.151861</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.064155</td>\n",
       "      <td>0.034974</td>\n",
       "      <td>-0.012090</td>\n",
       "      <td>0.427112</td>\n",
       "      <td>-0.262449</td>\n",
       "      <td>-0.223045</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.059023</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.091325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>total dose</th>\n",
       "      <td>-0.026370</td>\n",
       "      <td>-0.167061</td>\n",
       "      <td>0.114528</td>\n",
       "      <td>0.098310</td>\n",
       "      <td>0.061639</td>\n",
       "      <td>0.118013</td>\n",
       "      <td>-0.382522</td>\n",
       "      <td>0.191954</td>\n",
       "      <td>-0.483641</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.246227</td>\n",
       "      <td>-0.212466</td>\n",
       "      <td>-0.140665</td>\n",
       "      <td>-0.287549</td>\n",
       "      <td>0.366112</td>\n",
       "      <td>0.599352</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.796819</td>\n",
       "      <td>-0.072995</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>-0.015436</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.105878</td>\n",
       "      <td>-0.281215</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.003494</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.696988</td>\n",
       "      <td>-0.219716</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.191954</td>\n",
       "      <td>0.068380</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second dose per fracion</th>\n",
       "      <td>-0.274645</td>\n",
       "      <td>0.365426</td>\n",
       "      <td>0.330205</td>\n",
       "      <td>-0.161737</td>\n",
       "      <td>0.257016</td>\n",
       "      <td>0.213730</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.374661</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.102610</td>\n",
       "      <td>0.143601</td>\n",
       "      <td>0.130618</td>\n",
       "      <td>0.332972</td>\n",
       "      <td>0.525856</td>\n",
       "      <td>-0.525856</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.431155</td>\n",
       "      <td>-0.299436</td>\n",
       "      <td>0.359231</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>-0.196502</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.117753</td>\n",
       "      <td>0.026737</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021543</td>\n",
       "      <td>0.074769</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>0.160675</td>\n",
       "      <td>0.207630</td>\n",
       "      <td>-0.374661</td>\n",
       "      <td>0.095823</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>-0.048498</td>\n",
       "      <td>-0.026668</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.022480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second fractions</th>\n",
       "      <td>-0.001297</td>\n",
       "      <td>-0.409917</td>\n",
       "      <td>-0.170795</td>\n",
       "      <td>0.128467</td>\n",
       "      <td>-0.181464</td>\n",
       "      <td>-0.131216</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.172864</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.187413</td>\n",
       "      <td>-0.179079</td>\n",
       "      <td>-0.072486</td>\n",
       "      <td>-0.221932</td>\n",
       "      <td>-0.199954</td>\n",
       "      <td>0.199954</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.431155</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.963265</td>\n",
       "      <td>-0.129765</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>0.240002</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032202</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.200180</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>-0.070514</td>\n",
       "      <td>0.080343</td>\n",
       "      <td>-0.193699</td>\n",
       "      <td>-0.518723</td>\n",
       "      <td>0.172864</td>\n",
       "      <td>0.060088</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>-0.015920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.047052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>second total dose</th>\n",
       "      <td>-0.088090</td>\n",
       "      <td>-0.442843</td>\n",
       "      <td>-0.100960</td>\n",
       "      <td>0.095235</td>\n",
       "      <td>-0.107216</td>\n",
       "      <td>-0.109096</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.268432</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.322491</td>\n",
       "      <td>-0.145759</td>\n",
       "      <td>-0.040059</td>\n",
       "      <td>-0.200561</td>\n",
       "      <td>-0.082981</td>\n",
       "      <td>0.082981</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.299436</td>\n",
       "      <td>0.963265</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.041938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.271384</td>\n",
       "      <td>0.201853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.097328</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.253932</td>\n",
       "      <td>0.020347</td>\n",
       "      <td>-0.046832</td>\n",
       "      <td>0.289739</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>-0.520877</td>\n",
       "      <td>0.268432</td>\n",
       "      <td>0.071221</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.044419</td>\n",
       "      <td>-0.012150</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.098626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BED</th>\n",
       "      <td>-0.033742</td>\n",
       "      <td>-0.014945</td>\n",
       "      <td>0.232297</td>\n",
       "      <td>0.089293</td>\n",
       "      <td>0.021255</td>\n",
       "      <td>0.083876</td>\n",
       "      <td>-0.351451</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>-0.427028</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.086650</td>\n",
       "      <td>-0.178598</td>\n",
       "      <td>-0.138096</td>\n",
       "      <td>-0.158301</td>\n",
       "      <td>0.578708</td>\n",
       "      <td>0.431702</td>\n",
       "      <td>0.796819</td>\n",
       "      <td>0.359231</td>\n",
       "      <td>-0.129765</td>\n",
       "      <td>-0.041938</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.033807</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>-0.044050</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.050392</td>\n",
       "      <td>-0.257850</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>-0.024357</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>0.587917</td>\n",
       "      <td>-0.067666</td>\n",
       "      <td>-0.129587</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>-0.017351</td>\n",
       "      <td>0.040853</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.049029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modality</th>\n",
       "      <td>0.785852</td>\n",
       "      <td>-0.037155</td>\n",
       "      <td>0.118773</td>\n",
       "      <td>0.042404</td>\n",
       "      <td>0.019391</td>\n",
       "      <td>0.091707</td>\n",
       "      <td>-0.147750</td>\n",
       "      <td>-0.074765</td>\n",
       "      <td>-0.152546</td>\n",
       "      <td>-0.907322</td>\n",
       "      <td>-0.005453</td>\n",
       "      <td>-0.038318</td>\n",
       "      <td>-0.035275</td>\n",
       "      <td>-0.016978</td>\n",
       "      <td>-0.004604</td>\n",
       "      <td>-0.049823</td>\n",
       "      <td>-0.072995</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.033807</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.388707</td>\n",
       "      <td>-0.069068</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026810</td>\n",
       "      <td>-0.033832</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.024562</td>\n",
       "      <td>0.076521</td>\n",
       "      <td>-0.087149</td>\n",
       "      <td>-0.127979</td>\n",
       "      <td>-0.074642</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.071616</td>\n",
       "      <td>-0.022424</td>\n",
       "      <td>-0.046445</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.062833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PacksPerDay</th>\n",
       "      <td>0.370652</td>\n",
       "      <td>-0.011438</td>\n",
       "      <td>0.339117</td>\n",
       "      <td>0.204991</td>\n",
       "      <td>0.021186</td>\n",
       "      <td>-0.369649</td>\n",
       "      <td>0.151648</td>\n",
       "      <td>0.201871</td>\n",
       "      <td>0.148943</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.130804</td>\n",
       "      <td>0.030309</td>\n",
       "      <td>-0.112897</td>\n",
       "      <td>0.067265</td>\n",
       "      <td>-0.031372</td>\n",
       "      <td>0.121239</td>\n",
       "      <td>0.077746</td>\n",
       "      <td>0.010494</td>\n",
       "      <td>-0.249777</td>\n",
       "      <td>-0.271384</td>\n",
       "      <td>0.013358</td>\n",
       "      <td>0.388707</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.408958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.241545</td>\n",
       "      <td>0.239546</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.032235</td>\n",
       "      <td>-0.082960</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.112930</td>\n",
       "      <td>-0.019987</td>\n",
       "      <td>0.201871</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>0.130907</td>\n",
       "      <td>0.100587</td>\n",
       "      <td>-0.007705</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.119660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmokingStatus</th>\n",
       "      <td>-0.032330</td>\n",
       "      <td>-0.032434</td>\n",
       "      <td>0.041726</td>\n",
       "      <td>0.014501</td>\n",
       "      <td>0.004963</td>\n",
       "      <td>-0.201562</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.021100</td>\n",
       "      <td>0.017383</td>\n",
       "      <td>-0.026687</td>\n",
       "      <td>-0.059723</td>\n",
       "      <td>-0.103177</td>\n",
       "      <td>0.027233</td>\n",
       "      <td>-0.015436</td>\n",
       "      <td>-0.196502</td>\n",
       "      <td>0.240002</td>\n",
       "      <td>0.201853</td>\n",
       "      <td>-0.044050</td>\n",
       "      <td>-0.069068</td>\n",
       "      <td>0.408958</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>-0.037825</td>\n",
       "      <td>-0.073774</td>\n",
       "      <td>0.038605</td>\n",
       "      <td>-0.079628</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>-0.026956</td>\n",
       "      <td>-0.048821</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>-0.037518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.037060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>IsSCLC</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>T_stage</th>\n",
       "      <td>-0.021221</td>\n",
       "      <td>0.095781</td>\n",
       "      <td>0.088251</td>\n",
       "      <td>0.063357</td>\n",
       "      <td>-0.058642</td>\n",
       "      <td>-0.079190</td>\n",
       "      <td>0.309738</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>0.252156</td>\n",
       "      <td>0.994959</td>\n",
       "      <td>0.359041</td>\n",
       "      <td>0.050498</td>\n",
       "      <td>0.021973</td>\n",
       "      <td>0.064306</td>\n",
       "      <td>-0.023393</td>\n",
       "      <td>-0.056282</td>\n",
       "      <td>-0.105878</td>\n",
       "      <td>-0.117753</td>\n",
       "      <td>-0.032202</td>\n",
       "      <td>-0.097328</td>\n",
       "      <td>-0.050392</td>\n",
       "      <td>-0.026810</td>\n",
       "      <td>0.241545</td>\n",
       "      <td>0.002271</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038302</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>0.188236</td>\n",
       "      <td>0.072450</td>\n",
       "      <td>-0.060214</td>\n",
       "      <td>0.040501</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-0.085191</td>\n",
       "      <td>-0.101269</td>\n",
       "      <td>-0.044456</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_stage</th>\n",
       "      <td>0.009848</td>\n",
       "      <td>0.322424</td>\n",
       "      <td>0.063772</td>\n",
       "      <td>-0.038292</td>\n",
       "      <td>-0.133962</td>\n",
       "      <td>-0.243414</td>\n",
       "      <td>0.469623</td>\n",
       "      <td>-0.002630</td>\n",
       "      <td>0.463517</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118654</td>\n",
       "      <td>0.332101</td>\n",
       "      <td>0.205676</td>\n",
       "      <td>0.210275</td>\n",
       "      <td>-0.168780</td>\n",
       "      <td>-0.151861</td>\n",
       "      <td>-0.281215</td>\n",
       "      <td>0.026737</td>\n",
       "      <td>0.004876</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>-0.257850</td>\n",
       "      <td>-0.033832</td>\n",
       "      <td>0.239546</td>\n",
       "      <td>-0.000335</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.038302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.013137</td>\n",
       "      <td>0.014754</td>\n",
       "      <td>0.208070</td>\n",
       "      <td>-0.186541</td>\n",
       "      <td>0.288704</td>\n",
       "      <td>0.244433</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>-0.143632</td>\n",
       "      <td>-0.135270</td>\n",
       "      <td>-0.155977</td>\n",
       "      <td>-0.025439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.137334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>M_stage</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PA</th>\n",
       "      <td>0.024006</td>\n",
       "      <td>-0.031029</td>\n",
       "      <td>0.010165</td>\n",
       "      <td>0.075692</td>\n",
       "      <td>0.012925</td>\n",
       "      <td>0.109747</td>\n",
       "      <td>-0.051460</td>\n",
       "      <td>0.126577</td>\n",
       "      <td>-0.066528</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.058530</td>\n",
       "      <td>0.027007</td>\n",
       "      <td>0.045733</td>\n",
       "      <td>-0.059345</td>\n",
       "      <td>0.050780</td>\n",
       "      <td>-0.064155</td>\n",
       "      <td>-0.016378</td>\n",
       "      <td>-0.021543</td>\n",
       "      <td>0.200180</td>\n",
       "      <td>0.253932</td>\n",
       "      <td>0.009317</td>\n",
       "      <td>0.029621</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.001732</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000462</td>\n",
       "      <td>-0.013137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.059095</td>\n",
       "      <td>-0.043210</td>\n",
       "      <td>0.153027</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>-0.011514</td>\n",
       "      <td>0.126559</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>0.073753</td>\n",
       "      <td>0.021377</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Locatie</th>\n",
       "      <td>-0.038233</td>\n",
       "      <td>-0.117122</td>\n",
       "      <td>-0.108905</td>\n",
       "      <td>0.042166</td>\n",
       "      <td>0.080843</td>\n",
       "      <td>-0.065149</td>\n",
       "      <td>0.071722</td>\n",
       "      <td>0.079917</td>\n",
       "      <td>0.076412</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.100813</td>\n",
       "      <td>-0.057487</td>\n",
       "      <td>-0.022085</td>\n",
       "      <td>0.049608</td>\n",
       "      <td>-0.000774</td>\n",
       "      <td>0.034974</td>\n",
       "      <td>-0.003494</td>\n",
       "      <td>0.074769</td>\n",
       "      <td>0.044444</td>\n",
       "      <td>0.020347</td>\n",
       "      <td>-0.024357</td>\n",
       "      <td>-0.035609</td>\n",
       "      <td>-0.032235</td>\n",
       "      <td>-0.037825</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.188236</td>\n",
       "      <td>0.014754</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.059095</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>-0.128097</td>\n",
       "      <td>-0.146837</td>\n",
       "      <td>0.079759</td>\n",
       "      <td>-0.048253</td>\n",
       "      <td>-0.059175</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.039418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FEV</th>\n",
       "      <td>-0.099301</td>\n",
       "      <td>0.027104</td>\n",
       "      <td>-0.080982</td>\n",
       "      <td>-0.148245</td>\n",
       "      <td>-0.165784</td>\n",
       "      <td>-0.003546</td>\n",
       "      <td>0.271034</td>\n",
       "      <td>0.084749</td>\n",
       "      <td>0.285565</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.075595</td>\n",
       "      <td>0.066401</td>\n",
       "      <td>0.055168</td>\n",
       "      <td>0.066374</td>\n",
       "      <td>0.023314</td>\n",
       "      <td>-0.012090</td>\n",
       "      <td>0.019684</td>\n",
       "      <td>0.009552</td>\n",
       "      <td>-0.070514</td>\n",
       "      <td>-0.046832</td>\n",
       "      <td>0.031338</td>\n",
       "      <td>-0.024562</td>\n",
       "      <td>-0.082960</td>\n",
       "      <td>-0.073774</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.072450</td>\n",
       "      <td>0.208070</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.043210</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.040035</td>\n",
       "      <td>0.143628</td>\n",
       "      <td>0.102651</td>\n",
       "      <td>0.084749</td>\n",
       "      <td>-0.339637</td>\n",
       "      <td>-0.248436</td>\n",
       "      <td>-0.071121</td>\n",
       "      <td>0.048454</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.106958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumultativeTotalTumorDose</th>\n",
       "      <td>0.024296</td>\n",
       "      <td>-0.282365</td>\n",
       "      <td>-0.029768</td>\n",
       "      <td>-0.009368</td>\n",
       "      <td>-0.098427</td>\n",
       "      <td>-0.019162</td>\n",
       "      <td>-0.103707</td>\n",
       "      <td>0.613298</td>\n",
       "      <td>-0.136605</td>\n",
       "      <td>-0.999307</td>\n",
       "      <td>-0.265619</td>\n",
       "      <td>0.014101</td>\n",
       "      <td>0.007435</td>\n",
       "      <td>-0.010079</td>\n",
       "      <td>0.326087</td>\n",
       "      <td>0.427112</td>\n",
       "      <td>0.696988</td>\n",
       "      <td>0.042710</td>\n",
       "      <td>0.080343</td>\n",
       "      <td>0.289739</td>\n",
       "      <td>0.587917</td>\n",
       "      <td>0.076521</td>\n",
       "      <td>0.089941</td>\n",
       "      <td>0.038605</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.060214</td>\n",
       "      <td>-0.186541</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.153027</td>\n",
       "      <td>0.005628</td>\n",
       "      <td>-0.040035</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.009455</td>\n",
       "      <td>-0.173725</td>\n",
       "      <td>0.613251</td>\n",
       "      <td>-0.029617</td>\n",
       "      <td>-0.058246</td>\n",
       "      <td>-0.062178</td>\n",
       "      <td>0.041829</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.147027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>meanlungdose</th>\n",
       "      <td>-0.093961</td>\n",
       "      <td>0.452758</td>\n",
       "      <td>0.256328</td>\n",
       "      <td>-0.059605</td>\n",
       "      <td>-0.082891</td>\n",
       "      <td>-0.012839</td>\n",
       "      <td>0.166079</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>0.163836</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.173426</td>\n",
       "      <td>0.128101</td>\n",
       "      <td>0.142954</td>\n",
       "      <td>0.035395</td>\n",
       "      <td>0.096442</td>\n",
       "      <td>-0.262449</td>\n",
       "      <td>-0.219716</td>\n",
       "      <td>0.160675</td>\n",
       "      <td>-0.193699</td>\n",
       "      <td>-0.172379</td>\n",
       "      <td>-0.067666</td>\n",
       "      <td>-0.087149</td>\n",
       "      <td>0.112930</td>\n",
       "      <td>-0.079628</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.040501</td>\n",
       "      <td>0.288704</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.048402</td>\n",
       "      <td>-0.128097</td>\n",
       "      <td>0.143628</td>\n",
       "      <td>-0.009455</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.588647</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>-0.006812</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.097729</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lungv20</th>\n",
       "      <td>-0.078641</td>\n",
       "      <td>0.541446</td>\n",
       "      <td>0.452165</td>\n",
       "      <td>-0.004486</td>\n",
       "      <td>-0.000247</td>\n",
       "      <td>0.183543</td>\n",
       "      <td>-0.045534</td>\n",
       "      <td>-0.314085</td>\n",
       "      <td>-0.138129</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.120387</td>\n",
       "      <td>0.021831</td>\n",
       "      <td>-0.009286</td>\n",
       "      <td>-0.151055</td>\n",
       "      <td>0.081345</td>\n",
       "      <td>-0.223045</td>\n",
       "      <td>0.023769</td>\n",
       "      <td>0.207630</td>\n",
       "      <td>-0.518723</td>\n",
       "      <td>-0.520877</td>\n",
       "      <td>-0.129587</td>\n",
       "      <td>-0.127979</td>\n",
       "      <td>-0.019987</td>\n",
       "      <td>-0.033291</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.034471</td>\n",
       "      <td>0.244433</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.011514</td>\n",
       "      <td>-0.146837</td>\n",
       "      <td>0.102651</td>\n",
       "      <td>-0.173725</td>\n",
       "      <td>0.588647</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.314085</td>\n",
       "      <td>0.110387</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>0.046527</td>\n",
       "      <td>-0.076196</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.196407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CumOTT</th>\n",
       "      <td>-0.073638</td>\n",
       "      <td>-0.323505</td>\n",
       "      <td>-0.258884</td>\n",
       "      <td>-0.035608</td>\n",
       "      <td>-0.052659</td>\n",
       "      <td>-0.176510</td>\n",
       "      <td>0.213209</td>\n",
       "      <td>0.999986</td>\n",
       "      <td>0.267231</td>\n",
       "      <td>-0.744798</td>\n",
       "      <td>-0.133568</td>\n",
       "      <td>0.193106</td>\n",
       "      <td>0.086709</td>\n",
       "      <td>0.169078</td>\n",
       "      <td>0.035295</td>\n",
       "      <td>0.207995</td>\n",
       "      <td>0.191954</td>\n",
       "      <td>-0.374661</td>\n",
       "      <td>0.172864</td>\n",
       "      <td>0.268432</td>\n",
       "      <td>0.151153</td>\n",
       "      <td>-0.074642</td>\n",
       "      <td>0.201871</td>\n",
       "      <td>0.060999</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.005002</td>\n",
       "      <td>-0.002299</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126559</td>\n",
       "      <td>0.079759</td>\n",
       "      <td>0.084749</td>\n",
       "      <td>0.613251</td>\n",
       "      <td>0.025968</td>\n",
       "      <td>-0.314085</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.106849</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>-0.046685</td>\n",
       "      <td>0.043190</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.179871</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallBaselineDysp</th>\n",
       "      <td>0.025096</td>\n",
       "      <td>0.110745</td>\n",
       "      <td>0.160408</td>\n",
       "      <td>-0.002582</td>\n",
       "      <td>0.435516</td>\n",
       "      <td>0.158830</td>\n",
       "      <td>-0.302601</td>\n",
       "      <td>-0.106849</td>\n",
       "      <td>-0.333993</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.041443</td>\n",
       "      <td>-0.096965</td>\n",
       "      <td>-0.041804</td>\n",
       "      <td>-0.126220</td>\n",
       "      <td>-0.010107</td>\n",
       "      <td>0.027011</td>\n",
       "      <td>0.068380</td>\n",
       "      <td>0.095823</td>\n",
       "      <td>0.060088</td>\n",
       "      <td>0.071221</td>\n",
       "      <td>0.013879</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.027688</td>\n",
       "      <td>-0.026956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.085191</td>\n",
       "      <td>-0.143632</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.007367</td>\n",
       "      <td>-0.048253</td>\n",
       "      <td>-0.339637</td>\n",
       "      <td>-0.029617</td>\n",
       "      <td>-0.005571</td>\n",
       "      <td>0.110387</td>\n",
       "      <td>-0.106849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.607698</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>-0.336464</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.036435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OverallPostRTDyspFullScore</th>\n",
       "      <td>0.083471</td>\n",
       "      <td>0.043273</td>\n",
       "      <td>0.032826</td>\n",
       "      <td>0.034739</td>\n",
       "      <td>0.336889</td>\n",
       "      <td>0.155274</td>\n",
       "      <td>-0.229349</td>\n",
       "      <td>-0.095122</td>\n",
       "      <td>-0.239390</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.059287</td>\n",
       "      <td>0.036825</td>\n",
       "      <td>0.058098</td>\n",
       "      <td>-0.054245</td>\n",
       "      <td>-0.013886</td>\n",
       "      <td>0.023499</td>\n",
       "      <td>0.008642</td>\n",
       "      <td>0.059423</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.039333</td>\n",
       "      <td>0.013348</td>\n",
       "      <td>0.071616</td>\n",
       "      <td>0.130907</td>\n",
       "      <td>-0.048821</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.101269</td>\n",
       "      <td>-0.135270</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.073753</td>\n",
       "      <td>-0.059175</td>\n",
       "      <td>-0.248436</td>\n",
       "      <td>-0.058246</td>\n",
       "      <td>-0.006812</td>\n",
       "      <td>0.018637</td>\n",
       "      <td>-0.094880</td>\n",
       "      <td>0.607698</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.611347</td>\n",
       "      <td>0.377371</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.127668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DyspGT2</th>\n",
       "      <td>-0.000678</td>\n",
       "      <td>0.016402</td>\n",
       "      <td>0.016594</td>\n",
       "      <td>-0.016519</td>\n",
       "      <td>0.232220</td>\n",
       "      <td>0.112600</td>\n",
       "      <td>-0.119252</td>\n",
       "      <td>-0.046729</td>\n",
       "      <td>-0.134257</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.016452</td>\n",
       "      <td>-0.027473</td>\n",
       "      <td>0.018407</td>\n",
       "      <td>-0.057827</td>\n",
       "      <td>-0.036952</td>\n",
       "      <td>0.025406</td>\n",
       "      <td>0.014174</td>\n",
       "      <td>-0.048498</td>\n",
       "      <td>0.035408</td>\n",
       "      <td>0.044419</td>\n",
       "      <td>-0.017351</td>\n",
       "      <td>-0.022424</td>\n",
       "      <td>0.100587</td>\n",
       "      <td>-0.051778</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.044456</td>\n",
       "      <td>-0.155977</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.021377</td>\n",
       "      <td>0.019870</td>\n",
       "      <td>-0.071121</td>\n",
       "      <td>-0.062178</td>\n",
       "      <td>0.037993</td>\n",
       "      <td>0.046527</td>\n",
       "      <td>-0.046685</td>\n",
       "      <td>0.323300</td>\n",
       "      <td>0.611347</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216909</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.098367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DeltaDyspGe1</th>\n",
       "      <td>-0.061878</td>\n",
       "      <td>-0.090430</td>\n",
       "      <td>-0.163323</td>\n",
       "      <td>0.062249</td>\n",
       "      <td>0.005699</td>\n",
       "      <td>-0.001902</td>\n",
       "      <td>0.075513</td>\n",
       "      <td>0.043190</td>\n",
       "      <td>0.072189</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.026728</td>\n",
       "      <td>0.062604</td>\n",
       "      <td>0.062647</td>\n",
       "      <td>0.012224</td>\n",
       "      <td>-0.008059</td>\n",
       "      <td>0.059023</td>\n",
       "      <td>-0.004475</td>\n",
       "      <td>-0.026668</td>\n",
       "      <td>-0.015920</td>\n",
       "      <td>-0.012150</td>\n",
       "      <td>0.040853</td>\n",
       "      <td>-0.046445</td>\n",
       "      <td>-0.007705</td>\n",
       "      <td>-0.037518</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.004086</td>\n",
       "      <td>-0.025439</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.043008</td>\n",
       "      <td>-0.031788</td>\n",
       "      <td>0.048454</td>\n",
       "      <td>0.041829</td>\n",
       "      <td>0.023137</td>\n",
       "      <td>-0.076196</td>\n",
       "      <td>0.043190</td>\n",
       "      <td>-0.336464</td>\n",
       "      <td>0.377371</td>\n",
       "      <td>0.216909</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.067666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TreatmentType</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TwoYearSurvival</th>\n",
       "      <td>0.198887</td>\n",
       "      <td>0.124601</td>\n",
       "      <td>0.104804</td>\n",
       "      <td>0.066701</td>\n",
       "      <td>0.102559</td>\n",
       "      <td>0.067338</td>\n",
       "      <td>-0.053787</td>\n",
       "      <td>-0.180136</td>\n",
       "      <td>-0.044269</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.177023</td>\n",
       "      <td>0.093582</td>\n",
       "      <td>0.073368</td>\n",
       "      <td>-0.032043</td>\n",
       "      <td>-0.050494</td>\n",
       "      <td>-0.091325</td>\n",
       "      <td>-0.034500</td>\n",
       "      <td>0.022480</td>\n",
       "      <td>-0.047052</td>\n",
       "      <td>-0.098626</td>\n",
       "      <td>-0.049029</td>\n",
       "      <td>0.062833</td>\n",
       "      <td>0.119660</td>\n",
       "      <td>-0.037060</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.009541</td>\n",
       "      <td>0.137334</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.024870</td>\n",
       "      <td>-0.039418</td>\n",
       "      <td>-0.106958</td>\n",
       "      <td>-0.147027</td>\n",
       "      <td>0.097729</td>\n",
       "      <td>0.196407</td>\n",
       "      <td>-0.179871</td>\n",
       "      <td>0.036435</td>\n",
       "      <td>0.127668</td>\n",
       "      <td>0.098367</td>\n",
       "      <td>0.067666</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              yearrt       med    maxeso    gender  \\\n",
       "yearrt                      1.000000  0.035484  0.170502  0.022171   \n",
       "med                         0.035484  1.000000  0.685031 -0.013612   \n",
       "maxeso                      0.170502  0.685031  1.000000  0.064168   \n",
       "gender                      0.022171 -0.013612  0.064168  1.000000   \n",
       "intake_who                  0.101750  0.127662  0.155735  0.052541   \n",
       "age                         0.092262  0.041787  0.150098  0.215333   \n",
       "chemo                      -0.132144  0.103075 -0.060674 -0.056850   \n",
       "ott                        -0.074144 -0.323796 -0.259238 -0.035446   \n",
       "chemo3g                    -0.124391  0.015743 -0.205260 -0.076631   \n",
       "gtv1                        0.817770  0.996419  0.995527       NaN   \n",
       "tumorload                   0.001419  0.343370  0.080694  0.145503   \n",
       "toxeso                      0.019743  0.276970  0.041139 -0.109016   \n",
       "toxesohigh2                -0.011638  0.176292 -0.060629 -0.079475   \n",
       "pretoxeso                  -0.028859  0.010657 -0.210410 -0.105280   \n",
       "dose per fraction          -0.199189  0.128879  0.297460  0.017366   \n",
       "fractions                   0.065645 -0.278657 -0.128770  0.081317   \n",
       "total dose                 -0.026370 -0.167061  0.114528  0.098310   \n",
       "second dose per fracion    -0.274645  0.365426  0.330205 -0.161737   \n",
       "second fractions           -0.001297 -0.409917 -0.170795  0.128467   \n",
       "second total dose          -0.088090 -0.442843 -0.100960  0.095235   \n",
       "BED                        -0.033742 -0.014945  0.232297  0.089293   \n",
       "Modality                    0.785852 -0.037155  0.118773  0.042404   \n",
       "PacksPerDay                 0.370652 -0.011438  0.339117  0.204991   \n",
       "SmokingStatus              -0.032330 -0.032434  0.041726  0.014501   \n",
       "IsSCLC                           NaN       NaN       NaN       NaN   \n",
       "T_stage                    -0.021221  0.095781  0.088251  0.063357   \n",
       "N_stage                     0.009848  0.322424  0.063772 -0.038292   \n",
       "M_stage                          NaN       NaN       NaN       NaN   \n",
       "PA                          0.024006 -0.031029  0.010165  0.075692   \n",
       "Locatie                    -0.038233 -0.117122 -0.108905  0.042166   \n",
       "FEV                        -0.099301  0.027104 -0.080982 -0.148245   \n",
       "CumultativeTotalTumorDose   0.024296 -0.282365 -0.029768 -0.009368   \n",
       "meanlungdose               -0.093961  0.452758  0.256328 -0.059605   \n",
       "lungv20                    -0.078641  0.541446  0.452165 -0.004486   \n",
       "CumOTT                     -0.073638 -0.323505 -0.258884 -0.035608   \n",
       "OverallBaselineDysp         0.025096  0.110745  0.160408 -0.002582   \n",
       "OverallPostRTDyspFullScore  0.083471  0.043273  0.032826  0.034739   \n",
       "DyspGT2                    -0.000678  0.016402  0.016594 -0.016519   \n",
       "DeltaDyspGe1               -0.061878 -0.090430 -0.163323  0.062249   \n",
       "TreatmentType                    NaN       NaN       NaN       NaN   \n",
       "TwoYearSurvival             0.198887  0.124601  0.104804  0.066701   \n",
       "\n",
       "                            intake_who       age     chemo       ott  \\\n",
       "yearrt                        0.101750  0.092262 -0.132144 -0.074144   \n",
       "med                           0.127662  0.041787  0.103075 -0.323796   \n",
       "maxeso                        0.155735  0.150098 -0.060674 -0.259238   \n",
       "gender                        0.052541  0.215333 -0.056850 -0.035446   \n",
       "intake_who                    1.000000  0.160668 -0.204388 -0.052391   \n",
       "age                           0.160668  1.000000 -0.380028 -0.176119   \n",
       "chemo                        -0.204388 -0.380028  1.000000  0.212733   \n",
       "ott                          -0.052391 -0.176119  0.212733  1.000000   \n",
       "chemo3g                      -0.233440 -0.434831  0.932458  0.266783   \n",
       "gtv1                          0.420437 -0.384586  0.907322 -0.695739   \n",
       "tumorload                     0.060034 -0.132469  0.108469 -0.133776   \n",
       "toxeso                        0.017873 -0.196950  0.311989  0.193045   \n",
       "toxesohigh2                   0.037378 -0.160623  0.216224  0.086609   \n",
       "pretoxeso                    -0.040470 -0.238382  0.297100  0.169078   \n",
       "dose per fraction             0.108461  0.080575 -0.252915  0.035295   \n",
       "fractions                    -0.032267  0.040062 -0.153679  0.207995   \n",
       "total dose                    0.061639  0.118013 -0.382522  0.191954   \n",
       "second dose per fracion       0.257016  0.213730       NaN -0.374661   \n",
       "second fractions             -0.181464 -0.131216       NaN  0.172864   \n",
       "second total dose            -0.107216 -0.109096       NaN  0.268432   \n",
       "BED                           0.021255  0.083876 -0.351451  0.151153   \n",
       "Modality                      0.019391  0.091707 -0.147750 -0.074765   \n",
       "PacksPerDay                   0.021186 -0.369649  0.151648  0.201871   \n",
       "SmokingStatus                 0.004963 -0.201562  0.000125  0.060999   \n",
       "IsSCLC                             NaN       NaN       NaN       NaN   \n",
       "T_stage                      -0.058642 -0.079190  0.309738  0.004838   \n",
       "N_stage                      -0.133962 -0.243414  0.469623 -0.002630   \n",
       "M_stage                            NaN       NaN       NaN       NaN   \n",
       "PA                            0.012925  0.109747 -0.051460  0.126577   \n",
       "Locatie                       0.080843 -0.065149  0.071722  0.079917   \n",
       "FEV                          -0.165784 -0.003546  0.271034  0.084749   \n",
       "CumultativeTotalTumorDose    -0.098427 -0.019162 -0.103707  0.613298   \n",
       "meanlungdose                 -0.082891 -0.012839  0.166079  0.025968   \n",
       "lungv20                      -0.000247  0.183543 -0.045534 -0.314085   \n",
       "CumOTT                       -0.052659 -0.176510  0.213209  0.999986   \n",
       "OverallBaselineDysp           0.435516  0.158830 -0.302601 -0.106849   \n",
       "OverallPostRTDyspFullScore    0.336889  0.155274 -0.229349 -0.095122   \n",
       "DyspGT2                       0.232220  0.112600 -0.119252 -0.046729   \n",
       "DeltaDyspGe1                  0.005699 -0.001902  0.075513  0.043190   \n",
       "TreatmentType                      NaN       NaN       NaN       NaN   \n",
       "TwoYearSurvival               0.102559  0.067338 -0.053787 -0.180136   \n",
       "\n",
       "                             chemo3g      gtv1  tumorload    toxeso  \\\n",
       "yearrt                     -0.124391  0.817770   0.001419  0.019743   \n",
       "med                         0.015743  0.996419   0.343370  0.276970   \n",
       "maxeso                     -0.205260  0.995527   0.080694  0.041139   \n",
       "gender                     -0.076631       NaN   0.145503 -0.109016   \n",
       "intake_who                 -0.233440  0.420437   0.060034  0.017873   \n",
       "age                        -0.434831 -0.384586  -0.132469 -0.196950   \n",
       "chemo                       0.932458  0.907322   0.108469  0.311989   \n",
       "ott                         0.266783 -0.695739  -0.133776  0.193045   \n",
       "chemo3g                     1.000000  0.907322   0.143610  0.339678   \n",
       "gtv1                        0.907322  1.000000   1.000000  0.817770   \n",
       "tumorload                   0.143610  1.000000   1.000000  0.062906   \n",
       "toxeso                      0.339678  0.817770   0.062906  1.000000   \n",
       "toxesohigh2                 0.252552       NaN   0.082007  0.689074   \n",
       "pretoxeso                   0.361789       NaN   0.060811  0.547655   \n",
       "dose per fraction          -0.304678       NaN  -0.050977 -0.152203   \n",
       "fractions                  -0.220716       NaN  -0.189986 -0.036039   \n",
       "total dose                 -0.483641       NaN  -0.246227 -0.212466   \n",
       "second dose per fracion          NaN       NaN  -0.102610  0.143601   \n",
       "second fractions                 NaN       NaN  -0.187413 -0.179079   \n",
       "second total dose                NaN       NaN  -0.322491 -0.145759   \n",
       "BED                        -0.427028       NaN  -0.086650 -0.178598   \n",
       "Modality                   -0.152546 -0.907322  -0.005453 -0.038318   \n",
       "PacksPerDay                 0.148943       NaN   0.130804  0.030309   \n",
       "SmokingStatus               0.000380       NaN  -0.021100  0.017383   \n",
       "IsSCLC                           NaN       NaN        NaN       NaN   \n",
       "T_stage                     0.252156  0.994959   0.359041  0.050498   \n",
       "N_stage                     0.463517       NaN   0.118654  0.332101   \n",
       "M_stage                          NaN       NaN        NaN       NaN   \n",
       "PA                         -0.066528       NaN  -0.058530  0.027007   \n",
       "Locatie                     0.076412       NaN   0.100813 -0.057487   \n",
       "FEV                         0.285565       NaN   0.075595  0.066401   \n",
       "CumultativeTotalTumorDose  -0.136605 -0.999307  -0.265619  0.014101   \n",
       "meanlungdose                0.163836       NaN   0.173426  0.128101   \n",
       "lungv20                    -0.138129       NaN   0.120387  0.021831   \n",
       "CumOTT                      0.267231 -0.744798  -0.133568  0.193106   \n",
       "OverallBaselineDysp        -0.333993       NaN   0.041443 -0.096965   \n",
       "OverallPostRTDyspFullScore -0.239390  0.089552   0.059287  0.036825   \n",
       "DyspGT2                    -0.134257       NaN   0.016452 -0.027473   \n",
       "DeltaDyspGe1                0.072189       NaN  -0.026728  0.062604   \n",
       "TreatmentType                    NaN       NaN        NaN       NaN   \n",
       "TwoYearSurvival            -0.044269       NaN   0.177023  0.093582   \n",
       "\n",
       "                            toxesohigh2  pretoxeso  dose per fraction  \\\n",
       "yearrt                        -0.011638  -0.028859          -0.199189   \n",
       "med                            0.176292   0.010657           0.128879   \n",
       "maxeso                        -0.060629  -0.210410           0.297460   \n",
       "gender                        -0.079475  -0.105280           0.017366   \n",
       "intake_who                     0.037378  -0.040470           0.108461   \n",
       "age                           -0.160623  -0.238382           0.080575   \n",
       "chemo                          0.216224   0.297100          -0.252915   \n",
       "ott                            0.086609   0.169078           0.035295   \n",
       "chemo3g                        0.252552   0.361789          -0.304678   \n",
       "gtv1                                NaN        NaN                NaN   \n",
       "tumorload                      0.082007   0.060811          -0.050977   \n",
       "toxeso                         0.689074   0.547655          -0.152203   \n",
       "toxesohigh2                    1.000000   0.471345          -0.174210   \n",
       "pretoxeso                      0.471345   1.000000          -0.092540   \n",
       "dose per fraction             -0.174210  -0.092540           1.000000   \n",
       "fractions                      0.019748  -0.078108          -0.376706   \n",
       "total dose                    -0.140665  -0.287549           0.366112   \n",
       "second dose per fracion        0.130618   0.332972           0.525856   \n",
       "second fractions              -0.072486  -0.221932          -0.199954   \n",
       "second total dose             -0.040059  -0.200561          -0.082981   \n",
       "BED                           -0.138096  -0.158301           0.578708   \n",
       "Modality                      -0.035275  -0.016978          -0.004604   \n",
       "PacksPerDay                   -0.112897   0.067265          -0.031372   \n",
       "SmokingStatus                 -0.026687  -0.059723          -0.103177   \n",
       "IsSCLC                              NaN        NaN                NaN   \n",
       "T_stage                        0.021973   0.064306          -0.023393   \n",
       "N_stage                        0.205676   0.210275          -0.168780   \n",
       "M_stage                             NaN        NaN                NaN   \n",
       "PA                             0.045733  -0.059345           0.050780   \n",
       "Locatie                       -0.022085   0.049608          -0.000774   \n",
       "FEV                            0.055168   0.066374           0.023314   \n",
       "CumultativeTotalTumorDose      0.007435  -0.010079           0.326087   \n",
       "meanlungdose                   0.142954   0.035395           0.096442   \n",
       "lungv20                       -0.009286  -0.151055           0.081345   \n",
       "CumOTT                         0.086709   0.169078           0.035295   \n",
       "OverallBaselineDysp           -0.041804  -0.126220          -0.010107   \n",
       "OverallPostRTDyspFullScore     0.058098  -0.054245          -0.013886   \n",
       "DyspGT2                        0.018407  -0.057827          -0.036952   \n",
       "DeltaDyspGe1                   0.062647   0.012224          -0.008059   \n",
       "TreatmentType                       NaN        NaN                NaN   \n",
       "TwoYearSurvival                0.073368  -0.032043          -0.050494   \n",
       "\n",
       "                            fractions  total dose  second dose per fracion  \\\n",
       "yearrt                       0.065645   -0.026370                -0.274645   \n",
       "med                         -0.278657   -0.167061                 0.365426   \n",
       "maxeso                      -0.128770    0.114528                 0.330205   \n",
       "gender                       0.081317    0.098310                -0.161737   \n",
       "intake_who                  -0.032267    0.061639                 0.257016   \n",
       "age                          0.040062    0.118013                 0.213730   \n",
       "chemo                       -0.153679   -0.382522                      NaN   \n",
       "ott                          0.207995    0.191954                -0.374661   \n",
       "chemo3g                     -0.220716   -0.483641                      NaN   \n",
       "gtv1                              NaN         NaN                      NaN   \n",
       "tumorload                   -0.189986   -0.246227                -0.102610   \n",
       "toxeso                      -0.036039   -0.212466                 0.143601   \n",
       "toxesohigh2                  0.019748   -0.140665                 0.130618   \n",
       "pretoxeso                   -0.078108   -0.287549                 0.332972   \n",
       "dose per fraction           -0.376706    0.366112                 0.525856   \n",
       "fractions                    1.000000    0.599352                -0.525856   \n",
       "total dose                   0.599352    1.000000                      NaN   \n",
       "second dose per fracion     -0.525856         NaN                 1.000000   \n",
       "second fractions             0.199954         NaN                -0.431155   \n",
       "second total dose            0.082981         NaN                -0.299436   \n",
       "BED                          0.431702    0.796819                 0.359231   \n",
       "Modality                    -0.049823   -0.072995                      NaN   \n",
       "PacksPerDay                  0.121239    0.077746                 0.010494   \n",
       "SmokingStatus                0.027233   -0.015436                -0.196502   \n",
       "IsSCLC                            NaN         NaN                      NaN   \n",
       "T_stage                     -0.056282   -0.105878                -0.117753   \n",
       "N_stage                     -0.151861   -0.281215                 0.026737   \n",
       "M_stage                           NaN         NaN                      NaN   \n",
       "PA                          -0.064155   -0.016378                -0.021543   \n",
       "Locatie                      0.034974   -0.003494                 0.074769   \n",
       "FEV                         -0.012090    0.019684                 0.009552   \n",
       "CumultativeTotalTumorDose    0.427112    0.696988                 0.042710   \n",
       "meanlungdose                -0.262449   -0.219716                 0.160675   \n",
       "lungv20                     -0.223045    0.023769                 0.207630   \n",
       "CumOTT                       0.207995    0.191954                -0.374661   \n",
       "OverallBaselineDysp          0.027011    0.068380                 0.095823   \n",
       "OverallPostRTDyspFullScore   0.023499    0.008642                 0.059423   \n",
       "DyspGT2                      0.025406    0.014174                -0.048498   \n",
       "DeltaDyspGe1                 0.059023   -0.004475                -0.026668   \n",
       "TreatmentType                     NaN         NaN                      NaN   \n",
       "TwoYearSurvival             -0.091325   -0.034500                 0.022480   \n",
       "\n",
       "                            second fractions  second total dose       BED  \\\n",
       "yearrt                             -0.001297          -0.088090 -0.033742   \n",
       "med                                -0.409917          -0.442843 -0.014945   \n",
       "maxeso                             -0.170795          -0.100960  0.232297   \n",
       "gender                              0.128467           0.095235  0.089293   \n",
       "intake_who                         -0.181464          -0.107216  0.021255   \n",
       "age                                -0.131216          -0.109096  0.083876   \n",
       "chemo                                    NaN                NaN -0.351451   \n",
       "ott                                 0.172864           0.268432  0.151153   \n",
       "chemo3g                                  NaN                NaN -0.427028   \n",
       "gtv1                                     NaN                NaN       NaN   \n",
       "tumorload                          -0.187413          -0.322491 -0.086650   \n",
       "toxeso                             -0.179079          -0.145759 -0.178598   \n",
       "toxesohigh2                        -0.072486          -0.040059 -0.138096   \n",
       "pretoxeso                          -0.221932          -0.200561 -0.158301   \n",
       "dose per fraction                  -0.199954          -0.082981  0.578708   \n",
       "fractions                           0.199954           0.082981  0.431702   \n",
       "total dose                               NaN                NaN  0.796819   \n",
       "second dose per fracion            -0.431155          -0.299436  0.359231   \n",
       "second fractions                    1.000000           0.963265 -0.129765   \n",
       "second total dose                   0.963265           1.000000 -0.041938   \n",
       "BED                                -0.129765          -0.041938  1.000000   \n",
       "Modality                                 NaN                NaN -0.033807   \n",
       "PacksPerDay                        -0.249777          -0.271384  0.013358   \n",
       "SmokingStatus                       0.240002           0.201853 -0.044050   \n",
       "IsSCLC                                   NaN                NaN       NaN   \n",
       "T_stage                            -0.032202          -0.097328 -0.050392   \n",
       "N_stage                             0.004876           0.003750 -0.257850   \n",
       "M_stage                                  NaN                NaN       NaN   \n",
       "PA                                  0.200180           0.253932  0.009317   \n",
       "Locatie                             0.044444           0.020347 -0.024357   \n",
       "FEV                                -0.070514          -0.046832  0.031338   \n",
       "CumultativeTotalTumorDose           0.080343           0.289739  0.587917   \n",
       "meanlungdose                       -0.193699          -0.172379 -0.067666   \n",
       "lungv20                            -0.518723          -0.520877 -0.129587   \n",
       "CumOTT                              0.172864           0.268432  0.151153   \n",
       "OverallBaselineDysp                 0.060088           0.071221  0.013879   \n",
       "OverallPostRTDyspFullScore          0.030720           0.039333  0.013348   \n",
       "DyspGT2                             0.035408           0.044419 -0.017351   \n",
       "DeltaDyspGe1                       -0.015920          -0.012150  0.040853   \n",
       "TreatmentType                            NaN                NaN       NaN   \n",
       "TwoYearSurvival                    -0.047052          -0.098626 -0.049029   \n",
       "\n",
       "                            Modality  PacksPerDay  SmokingStatus  IsSCLC  \\\n",
       "yearrt                      0.785852     0.370652      -0.032330     NaN   \n",
       "med                        -0.037155    -0.011438      -0.032434     NaN   \n",
       "maxeso                      0.118773     0.339117       0.041726     NaN   \n",
       "gender                      0.042404     0.204991       0.014501     NaN   \n",
       "intake_who                  0.019391     0.021186       0.004963     NaN   \n",
       "age                         0.091707    -0.369649      -0.201562     NaN   \n",
       "chemo                      -0.147750     0.151648       0.000125     NaN   \n",
       "ott                        -0.074765     0.201871       0.060999     NaN   \n",
       "chemo3g                    -0.152546     0.148943       0.000380     NaN   \n",
       "gtv1                       -0.907322          NaN            NaN     NaN   \n",
       "tumorload                  -0.005453     0.130804      -0.021100     NaN   \n",
       "toxeso                     -0.038318     0.030309       0.017383     NaN   \n",
       "toxesohigh2                -0.035275    -0.112897      -0.026687     NaN   \n",
       "pretoxeso                  -0.016978     0.067265      -0.059723     NaN   \n",
       "dose per fraction          -0.004604    -0.031372      -0.103177     NaN   \n",
       "fractions                  -0.049823     0.121239       0.027233     NaN   \n",
       "total dose                 -0.072995     0.077746      -0.015436     NaN   \n",
       "second dose per fracion          NaN     0.010494      -0.196502     NaN   \n",
       "second fractions                 NaN    -0.249777       0.240002     NaN   \n",
       "second total dose                NaN    -0.271384       0.201853     NaN   \n",
       "BED                        -0.033807     0.013358      -0.044050     NaN   \n",
       "Modality                    1.000000     0.388707      -0.069068     NaN   \n",
       "PacksPerDay                 0.388707     1.000000       0.408958     NaN   \n",
       "SmokingStatus              -0.069068     0.408958       1.000000     NaN   \n",
       "IsSCLC                           NaN          NaN            NaN     NaN   \n",
       "T_stage                    -0.026810     0.241545       0.002271     NaN   \n",
       "N_stage                    -0.033832     0.239546      -0.000335     NaN   \n",
       "M_stage                          NaN          NaN            NaN     NaN   \n",
       "PA                          0.029621          NaN       0.001732     NaN   \n",
       "Locatie                    -0.035609    -0.032235      -0.037825     NaN   \n",
       "FEV                        -0.024562    -0.082960      -0.073774     NaN   \n",
       "CumultativeTotalTumorDose   0.076521     0.089941       0.038605     NaN   \n",
       "meanlungdose               -0.087149     0.112930      -0.079628     NaN   \n",
       "lungv20                    -0.127979    -0.019987      -0.033291     NaN   \n",
       "CumOTT                     -0.074642     0.201871       0.060999     NaN   \n",
       "OverallBaselineDysp         0.005434     0.027688      -0.026956     NaN   \n",
       "OverallPostRTDyspFullScore  0.071616     0.130907      -0.048821     NaN   \n",
       "DyspGT2                    -0.022424     0.100587      -0.051778     NaN   \n",
       "DeltaDyspGe1               -0.046445    -0.007705      -0.037518     NaN   \n",
       "TreatmentType                    NaN          NaN            NaN     NaN   \n",
       "TwoYearSurvival             0.062833     0.119660      -0.037060     NaN   \n",
       "\n",
       "                             T_stage   N_stage  M_stage        PA   Locatie  \\\n",
       "yearrt                     -0.021221  0.009848      NaN  0.024006 -0.038233   \n",
       "med                         0.095781  0.322424      NaN -0.031029 -0.117122   \n",
       "maxeso                      0.088251  0.063772      NaN  0.010165 -0.108905   \n",
       "gender                      0.063357 -0.038292      NaN  0.075692  0.042166   \n",
       "intake_who                 -0.058642 -0.133962      NaN  0.012925  0.080843   \n",
       "age                        -0.079190 -0.243414      NaN  0.109747 -0.065149   \n",
       "chemo                       0.309738  0.469623      NaN -0.051460  0.071722   \n",
       "ott                         0.004838 -0.002630      NaN  0.126577  0.079917   \n",
       "chemo3g                     0.252156  0.463517      NaN -0.066528  0.076412   \n",
       "gtv1                        0.994959       NaN      NaN       NaN       NaN   \n",
       "tumorload                   0.359041  0.118654      NaN -0.058530  0.100813   \n",
       "toxeso                      0.050498  0.332101      NaN  0.027007 -0.057487   \n",
       "toxesohigh2                 0.021973  0.205676      NaN  0.045733 -0.022085   \n",
       "pretoxeso                   0.064306  0.210275      NaN -0.059345  0.049608   \n",
       "dose per fraction          -0.023393 -0.168780      NaN  0.050780 -0.000774   \n",
       "fractions                  -0.056282 -0.151861      NaN -0.064155  0.034974   \n",
       "total dose                 -0.105878 -0.281215      NaN -0.016378 -0.003494   \n",
       "second dose per fracion    -0.117753  0.026737      NaN -0.021543  0.074769   \n",
       "second fractions           -0.032202  0.004876      NaN  0.200180  0.044444   \n",
       "second total dose          -0.097328  0.003750      NaN  0.253932  0.020347   \n",
       "BED                        -0.050392 -0.257850      NaN  0.009317 -0.024357   \n",
       "Modality                   -0.026810 -0.033832      NaN  0.029621 -0.035609   \n",
       "PacksPerDay                 0.241545  0.239546      NaN       NaN -0.032235   \n",
       "SmokingStatus               0.002271 -0.000335      NaN  0.001732 -0.037825   \n",
       "IsSCLC                           NaN       NaN      NaN       NaN       NaN   \n",
       "T_stage                     1.000000  0.038302      NaN  0.000462  0.188236   \n",
       "N_stage                     0.038302  1.000000      NaN -0.013137  0.014754   \n",
       "M_stage                          NaN       NaN      NaN       NaN       NaN   \n",
       "PA                          0.000462 -0.013137      NaN  1.000000  0.059095   \n",
       "Locatie                     0.188236  0.014754      NaN  0.059095  1.000000   \n",
       "FEV                         0.072450  0.208070      NaN -0.043210  0.018026   \n",
       "CumultativeTotalTumorDose  -0.060214 -0.186541      NaN  0.153027  0.005628   \n",
       "meanlungdose                0.040501  0.288704      NaN  0.048402 -0.128097   \n",
       "lungv20                    -0.034471  0.244433      NaN -0.011514 -0.146837   \n",
       "CumOTT                      0.005002 -0.002299      NaN  0.126559  0.079759   \n",
       "OverallBaselineDysp        -0.085191 -0.143632      NaN  0.007367 -0.048253   \n",
       "OverallPostRTDyspFullScore -0.101269 -0.135270      NaN  0.073753 -0.059175   \n",
       "DyspGT2                    -0.044456 -0.155977      NaN  0.021377  0.019870   \n",
       "DeltaDyspGe1                0.004086 -0.025439      NaN  0.043008 -0.031788   \n",
       "TreatmentType                    NaN       NaN      NaN       NaN       NaN   \n",
       "TwoYearSurvival            -0.009541  0.137334      NaN  0.024870 -0.039418   \n",
       "\n",
       "                                 FEV  CumultativeTotalTumorDose  meanlungdose  \\\n",
       "yearrt                     -0.099301                   0.024296     -0.093961   \n",
       "med                         0.027104                  -0.282365      0.452758   \n",
       "maxeso                     -0.080982                  -0.029768      0.256328   \n",
       "gender                     -0.148245                  -0.009368     -0.059605   \n",
       "intake_who                 -0.165784                  -0.098427     -0.082891   \n",
       "age                        -0.003546                  -0.019162     -0.012839   \n",
       "chemo                       0.271034                  -0.103707      0.166079   \n",
       "ott                         0.084749                   0.613298      0.025968   \n",
       "chemo3g                     0.285565                  -0.136605      0.163836   \n",
       "gtv1                             NaN                  -0.999307           NaN   \n",
       "tumorload                   0.075595                  -0.265619      0.173426   \n",
       "toxeso                      0.066401                   0.014101      0.128101   \n",
       "toxesohigh2                 0.055168                   0.007435      0.142954   \n",
       "pretoxeso                   0.066374                  -0.010079      0.035395   \n",
       "dose per fraction           0.023314                   0.326087      0.096442   \n",
       "fractions                  -0.012090                   0.427112     -0.262449   \n",
       "total dose                  0.019684                   0.696988     -0.219716   \n",
       "second dose per fracion     0.009552                   0.042710      0.160675   \n",
       "second fractions           -0.070514                   0.080343     -0.193699   \n",
       "second total dose          -0.046832                   0.289739     -0.172379   \n",
       "BED                         0.031338                   0.587917     -0.067666   \n",
       "Modality                   -0.024562                   0.076521     -0.087149   \n",
       "PacksPerDay                -0.082960                   0.089941      0.112930   \n",
       "SmokingStatus              -0.073774                   0.038605     -0.079628   \n",
       "IsSCLC                           NaN                        NaN           NaN   \n",
       "T_stage                     0.072450                  -0.060214      0.040501   \n",
       "N_stage                     0.208070                  -0.186541      0.288704   \n",
       "M_stage                          NaN                        NaN           NaN   \n",
       "PA                         -0.043210                   0.153027      0.048402   \n",
       "Locatie                     0.018026                   0.005628     -0.128097   \n",
       "FEV                         1.000000                  -0.040035      0.143628   \n",
       "CumultativeTotalTumorDose  -0.040035                   1.000000     -0.009455   \n",
       "meanlungdose                0.143628                  -0.009455      1.000000   \n",
       "lungv20                     0.102651                  -0.173725      0.588647   \n",
       "CumOTT                      0.084749                   0.613251      0.025968   \n",
       "OverallBaselineDysp        -0.339637                  -0.029617     -0.005571   \n",
       "OverallPostRTDyspFullScore -0.248436                  -0.058246     -0.006812   \n",
       "DyspGT2                    -0.071121                  -0.062178      0.037993   \n",
       "DeltaDyspGe1                0.048454                   0.041829      0.023137   \n",
       "TreatmentType                    NaN                        NaN           NaN   \n",
       "TwoYearSurvival            -0.106958                  -0.147027      0.097729   \n",
       "\n",
       "                             lungv20    CumOTT  OverallBaselineDysp  \\\n",
       "yearrt                     -0.078641 -0.073638             0.025096   \n",
       "med                         0.541446 -0.323505             0.110745   \n",
       "maxeso                      0.452165 -0.258884             0.160408   \n",
       "gender                     -0.004486 -0.035608            -0.002582   \n",
       "intake_who                 -0.000247 -0.052659             0.435516   \n",
       "age                         0.183543 -0.176510             0.158830   \n",
       "chemo                      -0.045534  0.213209            -0.302601   \n",
       "ott                        -0.314085  0.999986            -0.106849   \n",
       "chemo3g                    -0.138129  0.267231            -0.333993   \n",
       "gtv1                             NaN -0.744798                  NaN   \n",
       "tumorload                   0.120387 -0.133568             0.041443   \n",
       "toxeso                      0.021831  0.193106            -0.096965   \n",
       "toxesohigh2                -0.009286  0.086709            -0.041804   \n",
       "pretoxeso                  -0.151055  0.169078            -0.126220   \n",
       "dose per fraction           0.081345  0.035295            -0.010107   \n",
       "fractions                  -0.223045  0.207995             0.027011   \n",
       "total dose                  0.023769  0.191954             0.068380   \n",
       "second dose per fracion     0.207630 -0.374661             0.095823   \n",
       "second fractions           -0.518723  0.172864             0.060088   \n",
       "second total dose          -0.520877  0.268432             0.071221   \n",
       "BED                        -0.129587  0.151153             0.013879   \n",
       "Modality                   -0.127979 -0.074642             0.005434   \n",
       "PacksPerDay                -0.019987  0.201871             0.027688   \n",
       "SmokingStatus              -0.033291  0.060999            -0.026956   \n",
       "IsSCLC                           NaN       NaN                  NaN   \n",
       "T_stage                    -0.034471  0.005002            -0.085191   \n",
       "N_stage                     0.244433 -0.002299            -0.143632   \n",
       "M_stage                          NaN       NaN                  NaN   \n",
       "PA                         -0.011514  0.126559             0.007367   \n",
       "Locatie                    -0.146837  0.079759            -0.048253   \n",
       "FEV                         0.102651  0.084749            -0.339637   \n",
       "CumultativeTotalTumorDose  -0.173725  0.613251            -0.029617   \n",
       "meanlungdose                0.588647  0.025968            -0.005571   \n",
       "lungv20                     1.000000 -0.314085             0.110387   \n",
       "CumOTT                     -0.314085  1.000000            -0.106849   \n",
       "OverallBaselineDysp         0.110387 -0.106849             1.000000   \n",
       "OverallPostRTDyspFullScore  0.018637 -0.094880             0.607698   \n",
       "DyspGT2                     0.046527 -0.046685             0.323300   \n",
       "DeltaDyspGe1               -0.076196  0.043190            -0.336464   \n",
       "TreatmentType                    NaN       NaN                  NaN   \n",
       "TwoYearSurvival             0.196407 -0.179871             0.036435   \n",
       "\n",
       "                            OverallPostRTDyspFullScore   DyspGT2  \\\n",
       "yearrt                                        0.083471 -0.000678   \n",
       "med                                           0.043273  0.016402   \n",
       "maxeso                                        0.032826  0.016594   \n",
       "gender                                        0.034739 -0.016519   \n",
       "intake_who                                    0.336889  0.232220   \n",
       "age                                           0.155274  0.112600   \n",
       "chemo                                        -0.229349 -0.119252   \n",
       "ott                                          -0.095122 -0.046729   \n",
       "chemo3g                                      -0.239390 -0.134257   \n",
       "gtv1                                          0.089552       NaN   \n",
       "tumorload                                     0.059287  0.016452   \n",
       "toxeso                                        0.036825 -0.027473   \n",
       "toxesohigh2                                   0.058098  0.018407   \n",
       "pretoxeso                                    -0.054245 -0.057827   \n",
       "dose per fraction                            -0.013886 -0.036952   \n",
       "fractions                                     0.023499  0.025406   \n",
       "total dose                                    0.008642  0.014174   \n",
       "second dose per fracion                       0.059423 -0.048498   \n",
       "second fractions                              0.030720  0.035408   \n",
       "second total dose                             0.039333  0.044419   \n",
       "BED                                           0.013348 -0.017351   \n",
       "Modality                                      0.071616 -0.022424   \n",
       "PacksPerDay                                   0.130907  0.100587   \n",
       "SmokingStatus                                -0.048821 -0.051778   \n",
       "IsSCLC                                             NaN       NaN   \n",
       "T_stage                                      -0.101269 -0.044456   \n",
       "N_stage                                      -0.135270 -0.155977   \n",
       "M_stage                                            NaN       NaN   \n",
       "PA                                            0.073753  0.021377   \n",
       "Locatie                                      -0.059175  0.019870   \n",
       "FEV                                          -0.248436 -0.071121   \n",
       "CumultativeTotalTumorDose                    -0.058246 -0.062178   \n",
       "meanlungdose                                 -0.006812  0.037993   \n",
       "lungv20                                       0.018637  0.046527   \n",
       "CumOTT                                       -0.094880 -0.046685   \n",
       "OverallBaselineDysp                           0.607698  0.323300   \n",
       "OverallPostRTDyspFullScore                    1.000000  0.611347   \n",
       "DyspGT2                                       0.611347  1.000000   \n",
       "DeltaDyspGe1                                  0.377371  0.216909   \n",
       "TreatmentType                                      NaN       NaN   \n",
       "TwoYearSurvival                               0.127668  0.098367   \n",
       "\n",
       "                            DeltaDyspGe1  TreatmentType  TwoYearSurvival  \n",
       "yearrt                         -0.061878            NaN         0.198887  \n",
       "med                            -0.090430            NaN         0.124601  \n",
       "maxeso                         -0.163323            NaN         0.104804  \n",
       "gender                          0.062249            NaN         0.066701  \n",
       "intake_who                      0.005699            NaN         0.102559  \n",
       "age                            -0.001902            NaN         0.067338  \n",
       "chemo                           0.075513            NaN        -0.053787  \n",
       "ott                             0.043190            NaN        -0.180136  \n",
       "chemo3g                         0.072189            NaN        -0.044269  \n",
       "gtv1                                 NaN            NaN              NaN  \n",
       "tumorload                      -0.026728            NaN         0.177023  \n",
       "toxeso                          0.062604            NaN         0.093582  \n",
       "toxesohigh2                     0.062647            NaN         0.073368  \n",
       "pretoxeso                       0.012224            NaN        -0.032043  \n",
       "dose per fraction              -0.008059            NaN        -0.050494  \n",
       "fractions                       0.059023            NaN        -0.091325  \n",
       "total dose                     -0.004475            NaN        -0.034500  \n",
       "second dose per fracion        -0.026668            NaN         0.022480  \n",
       "second fractions               -0.015920            NaN        -0.047052  \n",
       "second total dose              -0.012150            NaN        -0.098626  \n",
       "BED                             0.040853            NaN        -0.049029  \n",
       "Modality                       -0.046445            NaN         0.062833  \n",
       "PacksPerDay                    -0.007705            NaN         0.119660  \n",
       "SmokingStatus                  -0.037518            NaN        -0.037060  \n",
       "IsSCLC                               NaN            NaN              NaN  \n",
       "T_stage                         0.004086            NaN        -0.009541  \n",
       "N_stage                        -0.025439            NaN         0.137334  \n",
       "M_stage                              NaN            NaN              NaN  \n",
       "PA                              0.043008            NaN         0.024870  \n",
       "Locatie                        -0.031788            NaN        -0.039418  \n",
       "FEV                             0.048454            NaN        -0.106958  \n",
       "CumultativeTotalTumorDose       0.041829            NaN        -0.147027  \n",
       "meanlungdose                    0.023137            NaN         0.097729  \n",
       "lungv20                        -0.076196            NaN         0.196407  \n",
       "CumOTT                          0.043190            NaN        -0.179871  \n",
       "OverallBaselineDysp            -0.336464            NaN         0.036435  \n",
       "OverallPostRTDyspFullScore      0.377371            NaN         0.127668  \n",
       "DyspGT2                         0.216909            NaN         0.098367  \n",
       "DeltaDyspGe1                    1.000000            NaN         0.067666  \n",
       "TreatmentType                        NaN            NaN              NaN  \n",
       "TwoYearSurvival                 0.067666            NaN         1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat = df.corr()\n",
    "print(corrmat['TwoYearSurvival'])\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "corrmat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strongest covariance with outcome is -0.199, -0.177 for yearrt and tumorload. Yearrt is Year of RT, which means the year of receiving radiation therapy (RT). I would imagine that the higher the year, the more advanced the technology, and the higher then 2-year survival. However, the correlation is negative. Despite being the strongest relationship of the group, -0.199 is not very strong. We should keep in mind that patients are still undergoing standard treatment protocols, some of which were established in 2005. Advancements in medical technology may not be employed here, and the decrease in survival through the years may be attributed to something else such as change in staff."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models\n",
    "\n",
    "The evaluation measure I have chosen is a combination between precision and recall. The most common cross-validation score is a measure of accuracy. However, simple accuracy is not the best measure when predicting human lives, since the cost of a wrong prediction is literally a matter of life and death. A prediction of life when the outcome is death would prevent that person and their familiy from being able to adequately prepare themselves for the future, and this should be avoided at all costs.<br>\n",
    "\n",
    "For this reason, I chose to look at the combination of precision and recall in a custom f-score. Precision is the number of true positives over the number of true positives plus false postives. This means we are considering the number of accurately predicted deaths out of all predicted deaths. Recall is the number of true positives over the number of true positives plus false negatives. This means that we are considering the number of accurately predicted deaths out of all total deaths.\n",
    "\n",
    "Essentially, precision measures the ability to identify real deaths against false-alarm deaths. The people who slip through the cracks end up living longer than expected. Recall measures the ability to predict death correctly against predicting life incorrectly. The people who slip through the cracks are the ones who die unexpectedly and without a chance to prepare. Since this consequence is more severe, I will choose a beta value that places more weight on recall than precision.<br>\n",
    "\n",
    "Precision measures expected deaths vs. unexpected survival. The people who slip through the cracks end up living longer than expected.\n",
    "Recall measures expected deaths vs. unexpected deaths. The people who slip through the cracks are the ones who die unexpectedly and without a chance to prepare.\n",
    "\n",
    "\n",
    "However, when recall is favored too strongly, the models with the highest scores tend to aggressively predict death and lose out on predicting positives well.\n",
    "\n",
    "\n",
    "TP: people who we said died and died\n",
    "FP: people who we said died but lived\n",
    "Precision: TP / TP + FP (number of real deaths out of all predicted deaths)\n",
    "Recall: TP / TP + FN (number of predicted deaths out of all real deaths)\n",
    "\n",
    "\"precision -- the ability to identify positives as positives\n",
    "recall -- the ability to not to identify negatives as positives\"\n",
    "\n",
    "\n",
    "I have used cross-validation with 5 folds because it is computationally cheap, but creates enough diversity amongst models to protect against overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   yearrt        med     maxeso  intake_who  age     chemo  ott   chemo3g  \\\n",
      "0  2010.0  17.034600  44.898900         2.0   67  1.000000   21  2.000000   \n",
      "1  2014.0  20.334135  49.199991         1.0   69  0.736142   36  1.354767   \n",
      "2  2010.0  20.334135  49.199991         1.0   82  0.736142   24  1.354767   \n",
      "3  2013.0  17.229800  48.921700         1.0   77  1.000000   36  2.000000   \n",
      "4  2013.0  20.334135  49.199991         2.0   83  0.736142   28  1.354767   \n",
      "\n",
      "    tumorload  toxeso  toxesohigh2  pretoxeso  SmokingStatus  IsSCLC  T_stage  \\\n",
      "0   52.505500     2.0          0.0        2.0       1.252155       0      0.0   \n",
      "1  114.555789     2.0          0.0        2.0       1.000000       0      3.0   \n",
      "2  114.555789     1.0          0.0        0.0       1.000000       0      1.0   \n",
      "3   42.274500     1.0          0.0        1.0       1.000000       0      1.0   \n",
      "4  114.555789     0.0          0.0        0.0       1.000000       0      1.0   \n",
      "\n",
      "   N_stage  M_stage        FEV  CumultativeTotalTumorDose  meanlungdose  \\\n",
      "0      2.0      0.0  97.000000                      45.00     15.417800   \n",
      "1      2.0      0.0  61.000000                      67.00     16.680025   \n",
      "2      3.0      0.0  76.697907                      52.25     16.680025   \n",
      "3      3.0      0.0  91.000000                      69.00     25.042800   \n",
      "4      2.0      0.0  76.697907                      72.00     16.680025   \n",
      "\n",
      "     lungv20  CumOTT  OverallBaselineDysp  OverallPostRTDyspFullScore  \\\n",
      "0  33.848500      21                  0.0                           0   \n",
      "1  22.260337      36                  1.0                           1   \n",
      "2  22.260337      24                  0.0                           1   \n",
      "3  11.988800      36                  1.0                           1   \n",
      "4  22.260337      28                  2.0                           2   \n",
      "\n",
      "   DyspGT2  TwoYearSurvival  gender_0  gender_1  Modality_0.0  Modality_1.0  \\\n",
      "0        0                1         1         0             1             0   \n",
      "1        0                1         1         0             0             0   \n",
      "2        0                1         0         1             0             1   \n",
      "3        0                1         0         1             0             0   \n",
      "4        0                1         0         1             0             0   \n",
      "\n",
      "   Modality_2.0  PA_0.0  PA_1.0  Locatie_0.0  Locatie_1.0  Locatie_2.0  \\\n",
      "0             0       1       0            0            1            0   \n",
      "1             1       0       1            1            0            0   \n",
      "2             0       0       1            1            0            0   \n",
      "3             1       0       1            1            0            0   \n",
      "4             1       0       1            0            0            1   \n",
      "\n",
      "   Locatie_3.0  DeltaDyspGe1_0.0  DeltaDyspGe1_1.0  \n",
      "0            0                 1                 0  \n",
      "1            0                 1                 0  \n",
      "2            0                 0                 1  \n",
      "3            0                 1                 0  \n",
      "4            0                 1                 0  \n"
     ]
    }
   ],
   "source": [
    "cat = ['gender','Modality','PA','Locatie','DeltaDyspGe1']\n",
    "df_cat = pd.get_dummies(df, columns = cat)\n",
    "df_cat = df_cat.fillna(df_cat.mean())\n",
    "\n",
    "X = df_cat.loc[:, ~(df_cat.columns).isin(['TwoYearSurvival'])]\n",
    "Y = df_cat['TwoYearSurvival']\n",
    "\n",
    "print(df_cat.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "ftwo_scorer = make_scorer(fbeta_score, beta=2)\n",
    "\n",
    "def recall_score(model, X, Y):\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    scores = cross_validate(model, X, Y, cv = 5, scoring = ftwo_scorer)\n",
    "    \n",
    "    train_ = scores['train_score'].mean()\n",
    "    test_ = scores['test_score'].mean()\n",
    "    accuracy = cross_val_score(model, X, Y, cv=5).mean()\n",
    "    print(f'Training Score: {train_}')\n",
    "    print(f'Testing Score: {test_}')\n",
    "    print(f'Cross-Val Accuracy: {accuracy}\\n')\n",
    "    \n",
    "    pred_y = model.predict(X)\n",
    "    cm = pd.crosstab(Y, pred_y)\n",
    "    print(cm)\n",
    "    \n",
    "    if cm.shape != (2,2):\n",
    "        if cm.columns.values[0] == 1:\n",
    "            true_neg_p = 0\n",
    "            true_pos_p = 1\n",
    "        else:\n",
    "            true_neg_p = 1\n",
    "            true_pos_p = 0\n",
    "    else:    \n",
    "        true_neg_p = cm[0][0]/(cm[0][0] + cm[1][0])\n",
    "        true_pos_p = cm[1][1]/(cm[1][1] + cm[0][1])\n",
    "        \n",
    "    print(f'Negative Accuracy: {true_neg_p}')\n",
    "    print(f'Positive Accuracy: {true_pos_p}')\n",
    "\n",
    "        \n",
    "    score = (.4*test_) + (.6*accuracy)\n",
    "    \"\"\"\n",
    "    recall at 2/3 of 40 = 27\n",
    "    precision at 1/3 of 40 = 13\n",
    "    \n",
    "    neg acc at 1/2 of 60 = 30\n",
    "    recall at 1/2 of 60 = 30\n",
    "    \n",
    "    recall at 57\n",
    "    \"\"\"\n",
    "    \n",
    "    print(f'Final Score: {score}\\n')\n",
    "    \n",
    "    results.append({'Final Score':score, 'Training Score':train_, 'Testing Score':test_, 'Cross-Val Accuracy':accuracy,\n",
    "    'Negative Acc})\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lasso Regression\n",
    "\n",
    "Since there are many features (41 to be exact) I will first perform lasso regression with L1 regularization to do an initial round of feature reduction. To account for missing data, I will fill all NaN values with averages for their respective columns. There are only 559 observations, so it is not practical to drop all observations with NaN values. The category GTV1 has only 3 observations, so if we dropped all NaN values we would only be left with 3 values. For lasso regression specifically, I care to see which features were dropped (coefficients reduced to 0). The model returns my coefficients as an array of 1 array, so I need to isolate the first element of that array to map the values to their respective features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "C = 0.001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "C = 0.01\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8360690363180201\n",
      "Testing Score: 0.8062959110205767\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                43  177\n",
      "1                37  302\n",
      "Negative Accuracy: 0.19545454545454546\n",
      "Positive Accuracy: 0.8908554572271387\n",
      "Cross-Val Accuracy: 0.5903796653796654\n",
      "\n",
      "Combined Score: 0.6767461636360299\n",
      "\n",
      "C = 0.1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8078366021474874\n",
      "Testing Score: 0.7598135794447948\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                81  139\n",
      "1                56  283\n",
      "Negative Accuracy: 0.36818181818181817\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6010939510939511\n",
      "\n",
      "Combined Score: 0.6645818024342887\n",
      "\n",
      "C = 0.3\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.813060895048958\n",
      "Testing Score: 0.7530011956519214\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                53  286\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.8436578171091446\n",
      "Cross-Val Accuracy: 0.6082689832689832\n",
      "\n",
      "Combined Score: 0.6661618682221584\n",
      "\n",
      "C = 0.5\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8128856403555569\n",
      "Testing Score: 0.754571873317648\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                55  284\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.8377581120943953\n",
      "Cross-Val Accuracy: 0.6101029601029602\n",
      "\n",
      "Combined Score: 0.6678905253888353\n",
      "\n",
      "C = 1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8131514092106444\n",
      "Testing Score: 0.748505226959104\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 51  288\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.8495575221238938\n",
      "Cross-Val Accuracy: 0.6083011583011583\n",
      "\n",
      "Combined Score: 0.6643827857643365\n",
      "\n",
      "C = 100\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.807140685863672\n",
      "Testing Score: 0.6947480112797711\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 59  280\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8259587020648967\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6289030655157695\n",
      "\n",
      "C = 1000\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8079785962655569\n",
      "Testing Score: 0.6992881456904032\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 58  281\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8289085545722714\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6296476907085937\n",
      "\n",
      "C = 100000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8084597189600071\n",
      "Testing Score: 0.7020033210184483\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 59  280\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8259587020648967\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6318051894112403\n",
      "\n",
      "C = 10000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8079785962655569\n",
      "Testing Score: 0.7020033210184483\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 58  281\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8289085545722714\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6318051894112403\n",
      "\n",
      "C = 1000000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8079785962655569\n",
      "Testing Score: 0.7020033210184483\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                111  109\n",
      "1                 58  281\n",
      "Negative Accuracy: 0.5045454545454545\n",
      "Positive Accuracy: 0.8289085545722714\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6318051894112403\n",
      "\n",
      "{'score': 0.71790673824974616, 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def run_logistic(X, Y, pen):\n",
    "    runs = []\n",
    "    \n",
    "    def log_res(alpha, pen):\n",
    "        lr = LogisticRegression(C = alpha, penalty = pen)\n",
    "        fit = lr.fit(X, Y)\n",
    "\n",
    "        print(f'C = {alpha}\\n')\n",
    "\n",
    "        fit.coef_\n",
    "        coeff = fit.coef_[0]\n",
    "\n",
    "        #for i in range(len(coeff)):\n",
    "            #print(X.columns.values[i], coeff[i])\n",
    "        #print(fit.intercept_)\n",
    "        print('\\n')\n",
    "\n",
    "        score = recall_score(lr, X, Y)\n",
    "    \n",
    "        runs.append({'score': score, 'alpha': alpha})\n",
    "        # e.g. result['alpha']=alpha\n",
    "    \n",
    "    alpha_nums = [0.0001, 0.0001, 0.001, 0.01, 0.1, 0.3, 0.5, 1, 100, 1000, 1e5, 1e7, 1e9]\n",
    "\n",
    "    for alpha in alpha_nums:\n",
    "        log_res(alpha, pen)\n",
    "        \n",
    "    runs.sort(key = lambda run: run['score'])\n",
    "    print(runs[-1])\n",
    "            \n",
    "run_logistic(X,Y, 'l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When the regularization coefficient is too low, the model eliminates features very aggressively and ends up predicting death for every patient. This gives the model good positive accuracy, but horrible negative accuracy. The most commonly used feature is year of treatment, with tumorload next. I wouldn't have expected the year of treatment to be more important than direct medical indicators, but it was also one of the features that revealed strong covariance with the outcome in the correlation matrix. The next features that get included are age and overall treatment time, which have a positive and negative correlation with the outcome.<br>\n",
    "\n",
    "When regularization is not used (C=1000), we see a smaller gap between negative and positive accuracy. It seems that regardless of the beta value valuing precision or recall, the closest we can get is 49% negative accuracy and 82% positive accuracy. Balanced with a testing F1-score of 68.6%, this model is sufficient but not impressive. This model also has a training score of 78%, which means it is overfitting.<br>\n",
    "FINAL SCORE: 62.3%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8284200837955581\n",
      "Testing Score: 0.7990604586765903\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                36  303\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.8938053097345132\n",
      "Cross-Val Accuracy: 0.5975868725868726\n",
      "\n",
      "Combined Score: 0.6781763070227598\n",
      "\n",
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8284200837955581\n",
      "Testing Score: 0.7990604586765903\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                36  303\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.8938053097345132\n",
      "Cross-Val Accuracy: 0.5975868725868726\n",
      "\n",
      "Combined Score: 0.6781763070227598\n",
      "\n",
      "C = 0.001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7966298296933262\n",
      "Testing Score: 0.7601576789751657\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                50  289\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.8525073746312685\n",
      "Cross-Val Accuracy: 0.6012065637065638\n",
      "\n",
      "Combined Score: 0.6647870098140045\n",
      "\n",
      "C = 0.01\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8038550339631698\n",
      "Testing Score: 0.7552384878465398\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                83  137\n",
      "1                61  278\n",
      "Negative Accuracy: 0.37727272727272726\n",
      "Positive Accuracy: 0.8200589970501475\n",
      "Cross-Val Accuracy: 0.6136100386100386\n",
      "\n",
      "Combined Score: 0.6702614183046391\n",
      "\n",
      "C = 0.1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8006019411894876\n",
      "Testing Score: 0.728324566006198\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                57  282\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.6171814671814672\n",
      "\n",
      "Combined Score: 0.6616387067113595\n",
      "\n",
      "C = 0.3\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7970262689569162\n",
      "Testing Score: 0.7210713717090771\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                100  120\n",
      "1                 57  282\n",
      "Negative Accuracy: 0.45454545454545453\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.610006435006435\n",
      "\n",
      "Combined Score: 0.6544324096874918\n",
      "\n",
      "C = 0.5\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7985341882157234\n",
      "Testing Score: 0.7164318691351936\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                102  118\n",
      "1                 58  281\n",
      "Negative Accuracy: 0.4636363636363636\n",
      "Positive Accuracy: 0.8289085545722714\n",
      "Cross-Val Accuracy: 0.6136261261261261\n",
      "\n",
      "Combined Score: 0.6547484233297531\n",
      "\n",
      "C = 1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7997850398596343\n",
      "Testing Score: 0.7217426091806436\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 59  280\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8259587020648967\n",
      "Cross-Val Accuracy: 0.61003861003861\n",
      "\n",
      "Combined Score: 0.6547202096954234\n",
      "\n",
      "C = 100\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7913677070040369\n",
      "Testing Score: 0.6944392915962693\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 61  278\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8200589970501475\n",
      "Cross-Val Accuracy: 0.6028957528957529\n",
      "\n",
      "Combined Score: 0.6395131683759594\n",
      "\n",
      "C = 1000\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7934378577071641\n",
      "Testing Score: 0.6973457503307368\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 61  278\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.8200589970501475\n",
      "Cross-Val Accuracy: 0.6028957528957528\n",
      "\n",
      "Combined Score: 0.6406757518697463\n",
      "\n",
      "C = 100000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7951124433613795\n",
      "Testing Score: 0.7039826277292007\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 61  278\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8200589970501475\n",
      "Cross-Val Accuracy: 0.6028957528957529\n",
      "\n",
      "Combined Score: 0.6433305028291321\n",
      "\n",
      "C = 10000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7940117656367471\n",
      "Testing Score: 0.6982972095709187\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 59  280\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.8259587020648967\n",
      "Cross-Val Accuracy: 0.6064671814671814\n",
      "\n",
      "Combined Score: 0.6431991927086763\n",
      "\n",
      "C = 1000000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7932989538667684\n",
      "Testing Score: 0.687096493093288\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 61  278\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.8200589970501475\n",
      "Cross-Val Accuracy: 0.6046814671814672\n",
      "\n",
      "Combined Score: 0.6376474775461956\n",
      "\n",
      "{'score': 0.67817630702275977, 'alpha': 0.0001}\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X,Y, 'l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Using ridge regression, we were able to obtain very similar results to lasso regression. Again, the models did better with **very weak** regularization, which means very large parameter estimates are not penalized and make the model prone to overfitting. With a negative accuracy of 48%, positive accuracy of 82%, and testing score of 67%, this model is slightly worse than the lasso model but not significantly different.<br>\n",
    "FINAL SCORE: 62.8%\n",
    "NOTE: lambda is smaller here, regularization very strong (prevents overfitting)\n",
    "\n",
    "Note: \"Logistic regression good for time and memory requirement. It is not particularly affected by mild cases of multi-collinearity. Severe cases of multi-collinearity can be handled by implementing logistic regression with L2 regularization, although if a parsimonious model is needed, L2 regularization is not the best choice because it keeps all the features in the model.\"\n",
    "\n",
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 4\n",
      "Training Score: 0.8650901029844258\n",
      "Testing Score: 0.8299724127807308\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                8  212\n",
      "1                0  339\n",
      "Negative Accuracy: 0.03636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5921492921492922\n",
      "\n",
      "Combined Score: 0.6872785404018676\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 5\n",
      "Training Score: 0.8650901029844258\n",
      "Testing Score: 0.8299724127807308\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                8  212\n",
      "1                0  339\n",
      "Negative Accuracy: 0.03636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5921492921492922\n",
      "\n",
      "Combined Score: 0.6872785404018676\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 6\n",
      "Training Score: 0.8650901029844258\n",
      "Testing Score: 0.8299724127807308\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                8  212\n",
      "1                0  339\n",
      "Negative Accuracy: 0.03636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5921492921492922\n",
      "\n",
      "Combined Score: 0.6872785404018676\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 7\n",
      "Training Score: 0.8650901029844258\n",
      "Testing Score: 0.8299724127807308\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                8  212\n",
      "1                0  339\n",
      "Negative Accuracy: 0.03636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5921492921492922\n",
      "\n",
      "Combined Score: 0.6872785404018676\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 4\n",
      "Training Score: 0.7959816254412366\n",
      "Testing Score: 0.7403647879629296\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                3  217\n",
      "1                0  339\n",
      "Negative Accuracy: 0.013636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5617760617760619\n",
      "\n",
      "Combined Score: 0.633211552250809\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 5\n",
      "Training Score: 0.7959816254412366\n",
      "Testing Score: 0.7403647879629296\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                3  217\n",
      "1                0  339\n",
      "Negative Accuracy: 0.013636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5617760617760619\n",
      "\n",
      "Combined Score: 0.633211552250809\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 6\n",
      "Training Score: 0.7959816254412366\n",
      "Testing Score: 0.7403647879629296\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                3  217\n",
      "1                0  339\n",
      "Negative Accuracy: 0.013636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.5617760617760619\n",
      "\n",
      "Combined Score: 0.633211552250809\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 7\n",
      "Training Score: 0.8284902147396245\n",
      "Testing Score: 0.7613684143502485\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                3  217\n",
      "1                0  339\n",
      "Negative Accuracy: 0.013636363636363636\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.563561776061776\n",
      "\n",
      "Combined Score: 0.6426844313771651\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 4\n",
      "Training Score: 0.8091302501299411\n",
      "Testing Score: 0.7377035754471994\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                26  313\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5886904761904761\n",
      "\n",
      "Combined Score: 0.6482957158931655\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 5\n",
      "Training Score: 0.8091302501299411\n",
      "Testing Score: 0.7377035754471994\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                26  313\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5886904761904761\n",
      "\n",
      "Combined Score: 0.6482957158931655\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 6\n",
      "Training Score: 0.8091302501299411\n",
      "Testing Score: 0.7377035754471994\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                26  313\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5886904761904761\n",
      "\n",
      "Combined Score: 0.6482957158931655\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 7\n",
      "Training Score: 0.8096055390042858\n",
      "Testing Score: 0.7381315177450162\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                26  313\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5904761904761904\n",
      "\n",
      "Combined Score: 0.6495383213837207\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 4\n",
      "Training Score: 0.8266971431160635\n",
      "Testing Score: 0.8391084653964563\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                7  213\n",
      "1                2  337\n",
      "Negative Accuracy: 0.031818181818181815\n",
      "Positive Accuracy: 0.9941002949852508\n",
      "Cross-Val Accuracy: 0.5958011583011583\n",
      "\n",
      "Combined Score: 0.6931240811392776\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 5\n",
      "Training Score: 0.8266971431160635\n",
      "Testing Score: 0.8391084653964563\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                7  213\n",
      "1                2  337\n",
      "Negative Accuracy: 0.031818181818181815\n",
      "Positive Accuracy: 0.9941002949852508\n",
      "Cross-Val Accuracy: 0.5958011583011583\n",
      "\n",
      "Combined Score: 0.6931240811392776\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 6\n",
      "Training Score: 0.8266971431160635\n",
      "Testing Score: 0.8391084653964563\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                7  213\n",
      "1                2  337\n",
      "Negative Accuracy: 0.031818181818181815\n",
      "Positive Accuracy: 0.9941002949852508\n",
      "Cross-Val Accuracy: 0.5958011583011583\n",
      "\n",
      "Combined Score: 0.6931240811392776\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 7\n",
      "Training Score: 0.8110204200956096\n",
      "Testing Score: 0.8199198689052283\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                7  213\n",
      "1                2  337\n",
      "Negative Accuracy: 0.031818181818181815\n",
      "Positive Accuracy: 0.9941002949852508\n",
      "Cross-Val Accuracy: 0.5975868725868725\n",
      "\n",
      "Combined Score: 0.6865200711142148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 4\n",
      "Training Score: 0.8008782037604071\n",
      "Testing Score: 0.7163320977872633\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                79  260\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.7669616519174042\n",
      "Cross-Val Accuracy: 0.5457207207207208\n",
      "\n",
      "Combined Score: 0.6139652715473377\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 5\n",
      "Training Score: 0.8008782037604071\n",
      "Testing Score: 0.7163320977872633\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                79  260\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.7669616519174042\n",
      "Cross-Val Accuracy: 0.5457207207207208\n",
      "\n",
      "Combined Score: 0.6139652715473377\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 6\n",
      "Training Score: 0.8008782037604071\n",
      "Testing Score: 0.7163320977872633\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                79  260\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.7669616519174042\n",
      "Cross-Val Accuracy: 0.5457207207207208\n",
      "\n",
      "Combined Score: 0.6139652715473377\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 7\n",
      "Training Score: 0.8008782037604071\n",
      "Testing Score: 0.7163320977872633\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                7  213\n",
      "1                2  337\n",
      "Negative Accuracy: 0.031818181818181815\n",
      "Positive Accuracy: 0.9941002949852508\n",
      "Cross-Val Accuracy: 0.5457207207207208\n",
      "\n",
      "Combined Score: 0.6139652715473377\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 4\n",
      "Training Score: 0.8312508876960667\n",
      "Testing Score: 0.796665762516173\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                69  151\n",
      "1                49  290\n",
      "Negative Accuracy: 0.31363636363636366\n",
      "Positive Accuracy: 0.855457227138643\n",
      "Cross-Val Accuracy: 0.5866956241956242\n",
      "\n",
      "Combined Score: 0.6706836795238438\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 5\n",
      "Training Score: 0.830316247157365\n",
      "Testing Score: 0.8009127781268249\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                69  151\n",
      "1                49  290\n",
      "Negative Accuracy: 0.31363636363636366\n",
      "Positive Accuracy: 0.855457227138643\n",
      "Cross-Val Accuracy: 0.5884813384813385\n",
      "\n",
      "Combined Score: 0.673453914339533\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 6\n",
      "Training Score: 0.830316247157365\n",
      "Testing Score: 0.8009127781268249\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                69  151\n",
      "1                49  290\n",
      "Negative Accuracy: 0.31363636363636366\n",
      "Positive Accuracy: 0.855457227138643\n",
      "Cross-Val Accuracy: 0.5884813384813385\n",
      "\n",
      "Combined Score: 0.673453914339533\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 7\n",
      "Training Score: 0.825615733919878\n",
      "Testing Score: 0.7724261378523198\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                69  151\n",
      "1                49  290\n",
      "Negative Accuracy: 0.31363636363636366\n",
      "Positive Accuracy: 0.855457227138643\n",
      "Cross-Val Accuracy: 0.5867277992277993\n",
      "\n",
      "Combined Score: 0.6610071346776075\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 4\n",
      "Training Score: 0.7825169373708953\n",
      "Testing Score: 0.7740529047395919\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                62  158\n",
      "1                35  304\n",
      "Negative Accuracy: 0.2818181818181818\n",
      "Positive Accuracy: 0.8967551622418879\n",
      "Cross-Val Accuracy: 0.5724742599742599\n",
      "\n",
      "Combined Score: 0.6531057178803927\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 5\n",
      "Training Score: 0.7825169373708953\n",
      "Testing Score: 0.7740529047395919\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                62  158\n",
      "1                35  304\n",
      "Negative Accuracy: 0.2818181818181818\n",
      "Positive Accuracy: 0.8967551622418879\n",
      "Cross-Val Accuracy: 0.5724742599742599\n",
      "\n",
      "Combined Score: 0.6531057178803927\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 6\n",
      "Training Score: 0.7825169373708953\n",
      "Testing Score: 0.7740529047395919\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                62  158\n",
      "1                35  304\n",
      "Negative Accuracy: 0.2818181818181818\n",
      "Positive Accuracy: 0.8967551622418879\n",
      "Cross-Val Accuracy: 0.5724742599742599\n",
      "\n",
      "Combined Score: 0.6531057178803927\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 7\n",
      "Training Score: 0.781846910621732\n",
      "Testing Score: 0.776663870797033\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                62  158\n",
      "1                35  304\n",
      "Negative Accuracy: 0.2818181818181818\n",
      "Positive Accuracy: 0.8967551622418879\n",
      "Cross-Val Accuracy: 0.5760456885456886\n",
      "\n",
      "Combined Score: 0.6562929614462263\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 4\n",
      "Training Score: 0.7321671733768871\n",
      "Testing Score: 0.5987560783507979\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                61  159\n",
      "1                33  306\n",
      "Negative Accuracy: 0.2772727272727273\n",
      "Positive Accuracy: 0.9026548672566371\n",
      "Cross-Val Accuracy: 0.5261904761904762\n",
      "\n",
      "Combined Score: 0.555216717054605\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 5\n",
      "Training Score: 0.7376641437012681\n",
      "Testing Score: 0.6023095900564835\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                61  159\n",
      "1                33  306\n",
      "Negative Accuracy: 0.2772727272727273\n",
      "Positive Accuracy: 0.9026548672566371\n",
      "Cross-Val Accuracy: 0.5261904761904762\n",
      "\n",
      "Combined Score: 0.5566381217368792\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 6\n",
      "Training Score: 0.7376641437012681\n",
      "Testing Score: 0.6023095900564835\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                61  159\n",
      "1                33  306\n",
      "Negative Accuracy: 0.2772727272727273\n",
      "Positive Accuracy: 0.9026548672566371\n",
      "Cross-Val Accuracy: 0.5261904761904762\n",
      "\n",
      "Combined Score: 0.5566381217368792\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 7\n",
      "Training Score: 0.7915083504278044\n",
      "Testing Score: 0.674217065752092\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                87  133\n",
      "1                66  273\n",
      "Negative Accuracy: 0.39545454545454545\n",
      "Positive Accuracy: 0.8053097345132744\n",
      "Cross-Val Accuracy: 0.5494047619047618\n",
      "\n",
      "Combined Score: 0.5993296834436939\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 4\n",
      "Training Score: 0.7731873519669221\n",
      "Testing Score: 0.6079135832081525\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                166   54\n",
      "1                140  199\n",
      "Negative Accuracy: 0.7545454545454545\n",
      "Positive Accuracy: 0.5870206489675516\n",
      "Cross-Val Accuracy: 0.4868243243243243\n",
      "\n",
      "Combined Score: 0.5352600278778556\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 5\n",
      "Training Score: 0.7731873519669221\n",
      "Testing Score: 0.6079135832081525\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                166   54\n",
      "1                140  199\n",
      "Negative Accuracy: 0.7545454545454545\n",
      "Positive Accuracy: 0.5870206489675516\n",
      "Cross-Val Accuracy: 0.4868243243243243\n",
      "\n",
      "Combined Score: 0.5352600278778556\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 6\n",
      "Training Score: 0.7720461273043769\n",
      "Testing Score: 0.6051487750052778\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                83  137\n",
      "1                65  274\n",
      "Negative Accuracy: 0.37727272727272726\n",
      "Positive Accuracy: 0.8082595870206489\n",
      "Cross-Val Accuracy: 0.48503861003861\n",
      "\n",
      "Combined Score: 0.5330826760252771\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 7\n",
      "Training Score: 0.7720461273043769\n",
      "Testing Score: 0.6051487750052778\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                75  145\n",
      "1                36  303\n",
      "Negative Accuracy: 0.3409090909090909\n",
      "Positive Accuracy: 0.8938053097345132\n",
      "Cross-Val Accuracy: 0.48503861003861\n",
      "\n",
      "Combined Score: 0.5330826760252771\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 4\n",
      "Training Score: 0.8457743318464402\n",
      "Testing Score: 0.7963711045267818\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                13  326\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5957046332046332\n",
      "\n",
      "Combined Score: 0.6759712217334926\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 5\n",
      "Training Score: 0.8333688440073969\n",
      "Testing Score: 0.7831537055938161\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                13  326\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5957850707850708\n",
      "\n",
      "Combined Score: 0.6707325247085689\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 6\n",
      "Training Score: 0.8333688440073969\n",
      "Testing Score: 0.7831537055938161\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                13  326\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5957850707850708\n",
      "\n",
      "Combined Score: 0.6707325247085689\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 7\n",
      "Training Score: 0.8385570628024736\n",
      "Testing Score: 0.7917926374889525\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                13  326\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.6011743886743887\n",
      "\n",
      "Combined Score: 0.6774216882002142\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 4\n",
      "Training Score: 0.8303512573351199\n",
      "Testing Score: 0.7770377547716392\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                126   94\n",
      "1                 76  263\n",
      "Negative Accuracy: 0.5727272727272728\n",
      "Positive Accuracy: 0.775811209439528\n",
      "Cross-Val Accuracy: 0.5689028314028313\n",
      "\n",
      "Combined Score: 0.6521568007503544\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 5\n",
      "Training Score: 0.8303512573351199\n",
      "Testing Score: 0.7770377547716392\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                126   94\n",
      "1                 76  263\n",
      "Negative Accuracy: 0.5727272727272728\n",
      "Positive Accuracy: 0.775811209439528\n",
      "Cross-Val Accuracy: 0.5689028314028313\n",
      "\n",
      "Combined Score: 0.6521568007503544\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 6\n",
      "Training Score: 0.8303512573351199\n",
      "Testing Score: 0.7770377547716392\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                126   94\n",
      "1                 76  263\n",
      "Negative Accuracy: 0.5727272727272728\n",
      "Positive Accuracy: 0.775811209439528\n",
      "Cross-Val Accuracy: 0.5689028314028313\n",
      "\n",
      "Combined Score: 0.6521568007503544\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 7\n",
      "Training Score: 0.8359905466079365\n",
      "Testing Score: 0.7894081923811471\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                126   94\n",
      "1                 76  263\n",
      "Negative Accuracy: 0.5727272727272728\n",
      "Positive Accuracy: 0.775811209439528\n",
      "Cross-Val Accuracy: 0.5760456885456886\n",
      "\n",
      "Combined Score: 0.6613906900798721\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 4\n",
      "Training Score: 0.7496902164906276\n",
      "Testing Score: 0.5215658619212993\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                27  193\n",
      "1                 3  336\n",
      "Negative Accuracy: 0.12272727272727273\n",
      "Positive Accuracy: 0.9911504424778761\n",
      "Cross-Val Accuracy: 0.49029922779922785\n",
      "\n",
      "Combined Score: 0.5028058814480565\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 5\n",
      "Training Score: 0.7210605863208082\n",
      "Testing Score: 0.4970870677081963\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                27  193\n",
      "1                 3  336\n",
      "Negative Accuracy: 0.12272727272727273\n",
      "Positive Accuracy: 0.9911504424778761\n",
      "Cross-Val Accuracy: 0.4939028314028315\n",
      "\n",
      "Combined Score: 0.4951765259249774\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 6\n",
      "Training Score: 0.7210605863208082\n",
      "Testing Score: 0.4970870677081963\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                27  193\n",
      "1                 3  336\n",
      "Negative Accuracy: 0.12272727272727273\n",
      "Positive Accuracy: 0.9911504424778761\n",
      "Cross-Val Accuracy: 0.4939028314028315\n",
      "\n",
      "Combined Score: 0.4951765259249774\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 7\n",
      "Training Score: 0.760737100605256\n",
      "Testing Score: 0.5574819740533188\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                53  167\n",
      "1                14  325\n",
      "Negative Accuracy: 0.2409090909090909\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5117760617760618\n",
      "\n",
      "Combined Score: 0.5300584266869646\n",
      "\n",
      "{'score': 0.69312408113927759, 'Max Depth': 3, 'Random State': 1, 'Max Feature': 7, 'Min Samples Split': 6}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from IPython.display import Image, display\n",
    "import pydotplus\n",
    "import graphviz\n",
    "\n",
    "def run_tree(X,Y):\n",
    "    runs = []\n",
    "\n",
    "    def decision_tree (depth_max, random, feature_max, min_split):\n",
    "        decision_tree = tree.DecisionTreeClassifier(\n",
    "            criterion = 'entropy',\n",
    "            max_depth = depth_max,\n",
    "            random_state = random,\n",
    "            max_features = feature_max,\n",
    "            min_samples_split = min_split\n",
    "        )\n",
    "        decision_tree.fit(X, Y)\n",
    "\n",
    "        dot_data = tree.export_graphviz(\n",
    "            decision_tree, out_file=None,\n",
    "            feature_names=X.columns.values,\n",
    "            class_names=['die','live'],\n",
    "            filled=True\n",
    "        )\n",
    "        graph = pydotplus.graph_from_dot_data(dot_data)\n",
    "        graphimage = Image(graph.create_png())\n",
    "        #display(graphimage)\n",
    "\n",
    "        print(f'Max Depth: {depth_max}, Random State = {random}, Max Feature = {feature_max}, Min Samples Split = {min_split}')\n",
    "        score = recall_score(decision_tree, X, Y)\n",
    "        runs.append({'score':score, 'Max Depth':depth_max, 'Random State':random, 'Max Feature':feature_max, 'Min Samples Split':min_split})\n",
    "\n",
    "    depth_maxs = [3,4,5]\n",
    "    randoms = [1]\n",
    "    feature_maxs = [4,5,6,7]\n",
    "    min_splits = [4,5,6,7]\n",
    "\n",
    "    for depth_max in depth_maxs:\n",
    "        for random in randoms:\n",
    "            for feature_max in feature_maxs:\n",
    "                for min_split in min_splits:\n",
    "                    decision_tree (depth_max, random, feature_max, min_split)\n",
    "                    \n",
    "    runs.sort(key = lambda run: run['score'])\n",
    "    print(runs[-1])\n",
    "    \n",
    "run_tree(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest cross-val score achieved through a decision tree is 69.3%. Max Depth = 5, Random State = 1, Max Features = 6, Min Samples Split = 7. This is slightly better than the scores achieved through logistic regression using ridge and lasso methods. The difference between the training and testing F1 score is only 4%, which means overfitting is not an issue here. Negative accuracy is at 57.3%, which is much higher than the values we were seeing with logistic regression. Positive accuracy is at 77.6%, which is fairly decent for this critical measure.\n",
    "FINAL SCORE: 69.3%\n",
    "\n",
    "\n",
    "# Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8774634737692532\n",
      "Testing Score: 0.7983775177102121\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                16  323\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5867760617760618\n",
      "\n",
      "Combined Score: 0.6714166441497219\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8899569566391653\n",
      "Testing Score: 0.8193176394613818\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                40  180\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.18181818181818182\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5957368082368083\n",
      "\n",
      "Combined Score: 0.6851691407266377\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8876078614436084\n",
      "Testing Score: 0.815901243469954\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                42  178\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.19090909090909092\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6795072155346997\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8757630980645139\n",
      "Testing Score: 0.7983775177102121\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                16  323\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5867760617760618\n",
      "\n",
      "Combined Score: 0.6714166441497219\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8907555338830224\n",
      "Testing Score: 0.8264369518658855\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                39  181\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.17727272727272728\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.601093951093951\n",
      "\n",
      "Combined Score: 0.6912311514027248\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8876900920373366\n",
      "Testing Score: 0.8160600599407823\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                42  178\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.19090909090909092\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.679570742123031\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8758820877041137\n",
      "Testing Score: 0.8025168863820408\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                41  179\n",
      "1                15  324\n",
      "Negative Accuracy: 0.18636363636363637\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5885617760617761\n",
      "\n",
      "Combined Score: 0.674143820189882\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8896026817313725\n",
      "Testing Score: 0.8250879611570232\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                39  181\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.17727272727272728\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5957207207207207\n",
      "\n",
      "Combined Score: 0.6874676168952417\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8878087884831636\n",
      "Testing Score: 0.8200554637201016\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                42  178\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.19090909090909092\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6822403322061874\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8743777906823864\n",
      "Testing Score: 0.8064188827522767\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                41  179\n",
      "1                15  324\n",
      "Negative Accuracy: 0.18636363636363637\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5903474903474903\n",
      "\n",
      "Combined Score: 0.6767760473094049\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8910998672877503\n",
      "Testing Score: 0.8226655429236986\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                39  181\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.17727272727272728\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6854272210304834\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8880239699217946\n",
      "Testing Score: 0.820741591340201\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                41  179\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.18636363636363637\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6835862118256557\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8737648331880349\n",
      "Testing Score: 0.8080586487954946\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                53  167\n",
      "1                18  321\n",
      "Negative Accuracy: 0.2409090909090909\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6699416062363446\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8922082285119728\n",
      "Testing Score: 0.8163020168205583\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                55  165\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.25\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6764532391606557\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8881461899345044\n",
      "Testing Score: 0.806611155239857\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                46  174\n",
      "1                 7  332\n",
      "Negative Accuracy: 0.20909090909090908\n",
      "Positive Accuracy: 0.9793510324483776\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6715054659569467\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8734047788775527\n",
      "Testing Score: 0.807643408757613\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6687040816497634\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8910947003323674\n",
      "Testing Score: 0.8177289222096944\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                53  167\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.2409090909090909\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6802382870305959\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8851558347582879\n",
      "Testing Score: 0.8109340178027091\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                47  173\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.21363636363636362\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6743060395535161\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8740934841117124\n",
      "Testing Score: 0.8116451349924594\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6703047721437019\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8910956082515312\n",
      "Testing Score: 0.8173355064164107\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                50  170\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.22727272727272727\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5867921492921493\n",
      "\n",
      "Combined Score: 0.6790094921418539\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8872162158814165\n",
      "Testing Score: 0.8105327336935598\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                46  174\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.20909090909090908\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6730740973384278\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8728767278125096\n",
      "Testing Score: 0.8162029248086297\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5796653796653797\n",
      "\n",
      "Combined Score: 0.6742803977226797\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8903410096433048\n",
      "Testing Score: 0.8097659559727539\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                50  170\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.22727272727272727\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6716959576786768\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8875074576996488\n",
      "Testing Score: 0.8038716422226496\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                46  174\n",
      "1                 6  333\n",
      "Negative Accuracy: 0.20909090909090908\n",
      "Positive Accuracy: 0.9823008849557522\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6682668036072066\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8758099781396591\n",
      "Testing Score: 0.8050382005993327\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                52  168\n",
      "1                18  321\n",
      "Negative Accuracy: 0.23636363636363636\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5814671814671815\n",
      "\n",
      "Combined Score: 0.670895589120042\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8898259156185018\n",
      "Testing Score: 0.8098775607429444\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                59  161\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2681818181818182\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6803120281581816\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8882917248237995\n",
      "Testing Score: 0.8101189397331211\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                58  162\n",
      "1                10  329\n",
      "Negative Accuracy: 0.2636363636363636\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6804085797542523\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8748918805693078\n",
      "Testing Score: 0.809537654339773\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                52  168\n",
      "1                18  321\n",
      "Negative Accuracy: 0.23636363636363636\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6748382277590752\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8891479495168069\n",
      "Testing Score: 0.8116735053135973\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                59  161\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2681818181818182\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6810304059864428\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8858282451728874\n",
      "Testing Score: 0.8095124302138805\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                58  162\n",
      "1                10  329\n",
      "Negative Accuracy: 0.2636363636363636\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6790945473751275\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8748918805693078\n",
      "Testing Score: 0.809537654339773\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                19  320\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6748382277590752\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8888315147053355\n",
      "Testing Score: 0.8116735053135973\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                60  160\n",
      "1                13  326\n",
      "Negative Accuracy: 0.2727272727272727\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6810304059864428\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8861473957703929\n",
      "Testing Score: 0.8069609966591871\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                59  161\n",
      "1                10  329\n",
      "Negative Accuracy: 0.2681818181818182\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6770025453818216\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8719871896757893\n",
      "Testing Score: 0.8030110898196312\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                19  320\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5814671814671815\n",
      "\n",
      "Combined Score: 0.6700847448081614\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8916063338616814\n",
      "Testing Score: 0.8124994895489135\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                58  162\n",
      "1                14  325\n",
      "Negative Accuracy: 0.2636363636363636\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.597506435006435\n",
      "\n",
      "Combined Score: 0.6835036568234263\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8863590714711561\n",
      "Testing Score: 0.8094899960359532\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                58  162\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.2636363636363636\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6790855737039565\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8780404438893926\n",
      "Testing Score: 0.8086683844673572\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                25  314\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.585070785070785\n",
      "\n",
      "Combined Score: 0.6745098248294139\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8898371526916492\n",
      "Testing Score: 0.8139599529229049\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                22  317\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.677668923254104\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8872387975278409\n",
      "Testing Score: 0.8089590316325891\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                15  324\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6778017593711824\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.876525605161054\n",
      "Testing Score: 0.7966832538193935\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                70  150\n",
      "1                20  319\n",
      "Negative Accuracy: 0.3181818181818182\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5761422136422137\n",
      "\n",
      "Combined Score: 0.6643586297130857\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8897322945250016\n",
      "Testing Score: 0.8139599529229049\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                62  158\n",
      "1                18  321\n",
      "Negative Accuracy: 0.2818181818181818\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.677668923254104\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8872234119028505\n",
      "Testing Score: 0.8065066229301804\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                14  325\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6757493673187902\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8763244049296505\n",
      "Testing Score: 0.7988889275782588\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                70  150\n",
      "1                20  319\n",
      "Negative Accuracy: 0.3181818181818182\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5779279279279279\n",
      "\n",
      "Combined Score: 0.6663123277880603\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8891764810253491\n",
      "Testing Score: 0.8139599529229049\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                61  159\n",
      "1                18  321\n",
      "Negative Accuracy: 0.2772727272727273\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.677668923254104\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8872221540233334\n",
      "Testing Score: 0.8046245271254326\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                15  324\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6749965289968911\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8764430672697081\n",
      "Testing Score: 0.7970743152171729\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                70  150\n",
      "1                20  319\n",
      "Negative Accuracy: 0.3181818181818182\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5779440154440155\n",
      "\n",
      "Combined Score: 0.6655961353532784\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8884913648829039\n",
      "Testing Score: 0.8139599529229049\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                20  319\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.677668923254104\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8876662333019218\n",
      "Testing Score: 0.8075067456916136\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                63  157\n",
      "1                17  322\n",
      "Negative Accuracy: 0.2863636363636364\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6782922735662207\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8826421023734378\n",
      "Testing Score: 0.7663596233875924\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                66  154\n",
      "1                16  323\n",
      "Negative Accuracy: 0.3\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5671492921492921\n",
      "\n",
      "Combined Score: 0.6468334246446122\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8965197627388125\n",
      "Testing Score: 0.7860679286859653\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                66  154\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.3\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6643596039068186\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9010550544599845\n",
      "Testing Score: 0.7835635859630236\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                71  149\n",
      "1                11  328\n",
      "Negative Accuracy: 0.32272727272727275\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5796492921492921\n",
      "\n",
      "Combined Score: 0.6612150096747846\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8797395720842237\n",
      "Testing Score: 0.7598785359006494\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                17  322\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5653635778635778\n",
      "\n",
      "Combined Score: 0.6431695610784065\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8982057098243856\n",
      "Testing Score: 0.7914439308767415\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6697242904974148\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8985080940565222\n",
      "Testing Score: 0.7907853679443371\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                68  152\n",
      "1                10  329\n",
      "Negative Accuracy: 0.3090909090909091\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6673180081815959\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8799809452041238\n",
      "Testing Score: 0.7687088541644842\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                17  322\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5707207207207208\n",
      "\n",
      "Combined Score: 0.6499159740982261\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9018304900278894\n",
      "Testing Score: 0.7957684049375919\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6725255086931835\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9019405900166196\n",
      "Testing Score: 0.7896190393194432\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                11  328\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5796492921492921\n",
      "\n",
      "Combined Score: 0.6636371910173525\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8793084528454187\n",
      "Testing Score: 0.770669975995844\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                17  322\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5689350064350065\n",
      "\n",
      "Combined Score: 0.6496289942593415\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9009580400375976\n",
      "Testing Score: 0.8002635239145931\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                10  329\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6753949848554126\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8987455620549566\n",
      "Testing Score: 0.7964204742889555\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                68  152\n",
      "1                10  329\n",
      "Negative Accuracy: 0.3090909090909091\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6685006221480146\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8761348357176324\n",
      "Testing Score: 0.7670303993927277\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                82  138\n",
      "1                16  323\n",
      "Negative Accuracy: 0.37272727272727274\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.581483268983269\n",
      "\n",
      "Combined Score: 0.6557021211470524\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9029373921238601\n",
      "Testing Score: 0.779664531481537\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                13  326\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5725064350064349\n",
      "\n",
      "Combined Score: 0.6553696735964758\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9055762792367823\n",
      "Testing Score: 0.7742410628729937\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                78  142\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.35454545454545455\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6564145718673442\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.877186339435814\n",
      "Testing Score: 0.7693237380637244\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                69  151\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.31363636363636366\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5743564993564994\n",
      "\n",
      "Combined Score: 0.6523433948393894\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.905160476346681\n",
      "Testing Score: 0.7784132405640228\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                78  142\n",
      "1                11  328\n",
      "Negative Accuracy: 0.35454545454545455\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5742760617760618\n",
      "\n",
      "Combined Score: 0.6559309332912462\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9043132531432789\n",
      "Testing Score: 0.7738956759720168\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                77  143\n",
      "1                 9  330\n",
      "Negative Accuracy: 0.35\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6552049885355249\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8799855017423752\n",
      "Testing Score: 0.7759847585013789\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                75  145\n",
      "1                13  326\n",
      "Negative Accuracy: 0.3409090909090909\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5707850707850708\n",
      "\n",
      "Combined Score: 0.652864945871594\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9012195971227651\n",
      "Testing Score: 0.7741057717018165\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                12  327\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5653635778635778\n",
      "\n",
      "Combined Score: 0.6488604553988733\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9029524425255646\n",
      "Testing Score: 0.7763777833511155\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                75  145\n",
      "1                10  329\n",
      "Negative Accuracy: 0.3409090909090909\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.657269260058593\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8800675255110848\n",
      "Testing Score: 0.7749394509831438\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                74  146\n",
      "1                14  325\n",
      "Negative Accuracy: 0.33636363636363636\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5671653796653796\n",
      "\n",
      "Combined Score: 0.6502750081924853\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9004684611918389\n",
      "Testing Score: 0.7786862256815474\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                79  141\n",
      "1                13  326\n",
      "Negative Accuracy: 0.35909090909090907\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5689350064350065\n",
      "\n",
      "Combined Score: 0.6528354941336229\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9025412863231044\n",
      "Testing Score: 0.7709425018676063\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                75  145\n",
      "1                10  329\n",
      "Negative Accuracy: 0.3409090909090909\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5707207207207208\n",
      "\n",
      "Combined Score: 0.6508094331794749\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.877342663535823\n",
      "Testing Score: 0.784379578847967\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                86  134\n",
      "1                17  322\n",
      "Negative Accuracy: 0.39090909090909093\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5886261261261261\n",
      "\n",
      "Combined Score: 0.6669275072148625\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9036799700844711\n",
      "Testing Score: 0.7803527747399388\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                13  326\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6577878280426936\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9038886322492614\n",
      "Testing Score: 0.7887195790833968\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                81  139\n",
      "1                13  326\n",
      "Negative Accuracy: 0.36818181818181817\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5867921492921493\n",
      "\n",
      "Combined Score: 0.6675631212086484\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8806604732387104\n",
      "Testing Score: 0.7919599881394934\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                86  134\n",
      "1                17  322\n",
      "Negative Accuracy: 0.39090909090909093\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5957850707850708\n",
      "\n",
      "Combined Score: 0.6742550377268399\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9030413838180662\n",
      "Testing Score: 0.7830344222644113\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                14  325\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6599319156239113\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9033246746023961\n",
      "Testing Score: 0.7895494222253422\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                14  325\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6700379156082836\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.879503162500025\n",
      "Testing Score: 0.779374118276694\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                83  137\n",
      "1                16  323\n",
      "Negative Accuracy: 0.37727272727272726\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5886422136422137\n",
      "\n",
      "Combined Score: 0.6649349754960059\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9016101815365056\n",
      "Testing Score: 0.7834263099509828\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                14  325\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6600886706985398\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.901368836368758\n",
      "Testing Score: 0.7919638993488259\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                13  326\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6720751350291057\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8731807162884957\n",
      "Testing Score: 0.7863417579766587\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                80  140\n",
      "1                16  323\n",
      "Negative Accuracy: 0.36363636363636365\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5940315315315315\n",
      "\n",
      "Combined Score: 0.6709556221095825\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8971930011626306\n",
      "Testing Score: 0.7887318136371462\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                78  142\n",
      "1                15  324\n",
      "Negative Accuracy: 0.35454545454545455\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.665425157887291\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8982203885375059\n",
      "Testing Score: 0.7880554736060214\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                83  137\n",
      "1                14  325\n",
      "Negative Accuracy: 0.37727272727272726\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6662260504462696\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8800889013192513\n",
      "Testing Score: 0.7910906385916517\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                23  316\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.5940154440154439\n",
      "\n",
      "Combined Score: 0.672845521845927\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9029389023046013\n",
      "Testing Score: 0.7875349564502734\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                14  325\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6649464150125418\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9061802532838975\n",
      "Testing Score: 0.7861401111391891\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                15  324\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6654599054595367\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8797966566312839\n",
      "Testing Score: 0.789679523683606\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                93  127\n",
      "1                22  317\n",
      "Negative Accuracy: 0.42272727272727273\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5939993564993566\n",
      "\n",
      "Combined Score: 0.6722714233730565\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9033028166196146\n",
      "Testing Score: 0.7876141037970024\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                14  325\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6606923596655192\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9027684377069489\n",
      "Testing Score: 0.7809712379799186\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                16  323\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6601780704815428\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8796773696010038\n",
      "Testing Score: 0.7877745082941549\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                93  127\n",
      "1                22  317\n",
      "Negative Accuracy: 0.42272727272727273\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5939832689832689\n",
      "\n",
      "Combined Score: 0.6714997647076233\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9044135877388004\n",
      "Testing Score: 0.7876148249554925\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                15  324\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6606926481289153\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9013228366899207\n",
      "Testing Score: 0.7803758375860503\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                17  322\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6588684817525668\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8765181117412201\n",
      "Testing Score: 0.7652595716723007\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                22  317\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5725546975546976\n",
      "\n",
      "Combined Score: 0.6496366472017389\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9017638432383638\n",
      "Testing Score: 0.7842349258390419\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                16  323\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5796653796653797\n",
      "\n",
      "Combined Score: 0.6614931981348445\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8974442708082266\n",
      "Testing Score: 0.7810584370356256\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                90  130\n",
      "1                17  322\n",
      "Negative Accuracy: 0.4090909090909091\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5796653796653797\n",
      "\n",
      "Combined Score: 0.6602226026134781\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8981375096190931\n",
      "Testing Score: 0.7372443604802321\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                20  319\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5708494208494208\n",
      "\n",
      "Combined Score: 0.6374073967017453\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9147326658425294\n",
      "Testing Score: 0.7682699582034416\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                11  328\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5689350064350065\n",
      "\n",
      "Combined Score: 0.6486689871423805\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.916644662634346\n",
      "Testing Score: 0.7882041008149823\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                  8  331\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6705712156155682\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8862550062873087\n",
      "Testing Score: 0.747170099285351\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                18  321\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5744047619047619\n",
      "\n",
      "Combined Score: 0.6435108968569976\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.915993862310074\n",
      "Testing Score: 0.76657820697403\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                11  328\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5742921492921493\n",
      "\n",
      "Combined Score: 0.6512065723649016\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9151497947414791\n",
      "Testing Score: 0.7739015918452232\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6605644977419503\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8862046669590018\n",
      "Testing Score: 0.7343532349302108\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                12  327\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5708333333333333\n",
      "\n",
      "Combined Score: 0.6362412939720843\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9117395502872073\n",
      "Testing Score: 0.770029590212664\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                12  327\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6547299828032124\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9134106427083497\n",
      "Testing Score: 0.7784781785562533\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                 7  332\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.9793510324483776\n",
      "Cross-Val Accuracy: 0.5867921492921493\n",
      "\n",
      "Combined Score: 0.6634665609977909\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8951211155552775\n",
      "Testing Score: 0.7303982925619215\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                12  327\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5565315315315316\n",
      "\n",
      "Combined Score: 0.6260782359436876\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9123407692430991\n",
      "Testing Score: 0.7807008425891184\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                11  328\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5867921492921493\n",
      "\n",
      "Combined Score: 0.664355626610937\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9114828008285274\n",
      "Testing Score: 0.7771458756943372\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.664005068424453\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8792686703692398\n",
      "Testing Score: 0.7317377036464762\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                14  325\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5833172458172458\n",
      "\n",
      "Combined Score: 0.6426854289489379\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9213192204944969\n",
      "Testing Score: 0.7556856642000409\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5725064350064349\n",
      "\n",
      "Combined Score: 0.6457781266838774\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9241398439374929\n",
      "Testing Score: 0.7788146484588888\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                107  113\n",
      "1                 10  329\n",
      "Negative Accuracy: 0.4863636363636364\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6678868632445594\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8838097518771721\n",
      "Testing Score: 0.7334227421146053\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                100  120\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.45454545454545453\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5832850707850709\n",
      "\n",
      "Combined Score: 0.6433401393168847\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9197808106656545\n",
      "Testing Score: 0.7653086924934545\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 17  322\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6517701951441\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9198968197457595\n",
      "Testing Score: 0.7763135451792771\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                108  112\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.4909090909090909\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5939350064350065\n",
      "\n",
      "Combined Score: 0.6668864219327147\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8856675526964592\n",
      "Testing Score: 0.7432478010864243\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                12  327\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5797136422136423\n",
      "\n",
      "Combined Score: 0.6451273057627551\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9169212791700632\n",
      "Testing Score: 0.7675068798398095\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 18  321\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5796492921492923\n",
      "\n",
      "Combined Score: 0.6547923272254992\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9173124383274948\n",
      "Testing Score: 0.7828227326951689\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                107  113\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.4863636363636364\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.6028635778635778\n",
      "\n",
      "Combined Score: 0.6748472397962142\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.879401961156893\n",
      "Testing Score: 0.7557150300541537\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                12  327\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5904118404118404\n",
      "\n",
      "Combined Score: 0.6565331162687658\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.916723543602141\n",
      "Testing Score: 0.7773127952413577\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                112  108\n",
      "1                 19  320\n",
      "Negative Accuracy: 0.509090909090909\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6640718362432612\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9144968193337875\n",
      "Testing Score: 0.7785073245677532\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5957207207207207\n",
      "\n",
      "Combined Score: 0.6688353622595337\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8939197656672866\n",
      "Testing Score: 0.7680424500512041\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                108  112\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.4909090909090909\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5922940797940799\n",
      "\n",
      "Combined Score: 0.6625934278969295\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9233908450838856\n",
      "Testing Score: 0.762386329758397\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                108  112\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.4909090909090909\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.657039473988301\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9223438771231256\n",
      "Testing Score: 0.7636273559167795\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6532405176562871\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8893972499361024\n",
      "Testing Score: 0.7519397820660986\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                14  325\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5726190476190476\n",
      "\n",
      "Combined Score: 0.644347341397868\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.921658926453139\n",
      "Testing Score: 0.773212680139123\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                111  109\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.5045454545454545\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5886100386100386\n",
      "\n",
      "Combined Score: 0.6624510952216724\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9240483127024373\n",
      "Testing Score: 0.7684578240069735\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6573155620352218\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8836372674428696\n",
      "Testing Score: 0.7609316426534027\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                98  122\n",
      "1                15  324\n",
      "Negative Accuracy: 0.44545454545454544\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5761422136422136\n",
      "\n",
      "Combined Score: 0.6500579852466892\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9212601235834347\n",
      "Testing Score: 0.7659100264670534\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                108  112\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.4909090909090909\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.658458605181416\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.920406811544245\n",
      "Testing Score: 0.7577447921561151\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                113  107\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.5136363636363637\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.65195892072345\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8910898224401229\n",
      "Testing Score: 0.7474678757262526\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                16  323\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5742921492921493\n",
      "\n",
      "Combined Score: 0.6435624398657906\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9165997453042793\n",
      "Testing Score: 0.7617190037351218\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6557107675172147\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9166759000727037\n",
      "Testing Score: 0.7576831440729644\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6508628329187611\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8961206377477179\n",
      "Testing Score: 0.7783344004473683\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 29  310\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.9144542772861357\n",
      "Cross-Val Accuracy: 0.5939832689832689\n",
      "\n",
      "Combined Score: 0.6677237215689087\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9191670900040222\n",
      "Testing Score: 0.774306810841961\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                120  100\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.5454545454545454\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6596551567692168\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9211725977672248\n",
      "Testing Score: 0.7767301683537301\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                122   98\n",
      "1                  9  330\n",
      "Negative Accuracy: 0.5545454545454546\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5921653796653796\n",
      "\n",
      "Combined Score: 0.6659912951407199\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8951873468004841\n",
      "Testing Score: 0.7639153307967126\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 25  314\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5832528957528957\n",
      "\n",
      "Combined Score: 0.6555178697704225\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9184636501557906\n",
      "Testing Score: 0.7597164893311612\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                112  108\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.509090909090909\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5707368082368083\n",
      "\n",
      "Combined Score: 0.6463286806745494\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9253913827952818\n",
      "Testing Score: 0.7753214188655795\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                117  103\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.5318181818181819\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.6622135096311739\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.885708184933546\n",
      "Testing Score: 0.7643103390394003\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 27  312\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.9203539823008849\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6567279966196211\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9162570115559058\n",
      "Testing Score: 0.762885332500655\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                119  101\n",
      "1                 13  326\n",
      "Negative Accuracy: 0.5409090909090909\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5689350064350065\n",
      "\n",
      "Combined Score: 0.6465151368612659\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.923459535121004\n",
      "Testing Score: 0.7737476882677015\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                117  103\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.5318181818181819\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6626554459634513\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.892181634821483\n",
      "Testing Score: 0.7519507517121399\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                107  113\n",
      "1                 26  313\n",
      "Negative Accuracy: 0.4863636363636364\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5796010296010295\n",
      "\n",
      "Combined Score: 0.6485409184454737\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9164393762458444\n",
      "Testing Score: 0.7587087898453939\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5671653796653796\n",
      "\n",
      "Combined Score: 0.6437827437373853\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9211270932404731\n",
      "Testing Score: 0.7566835088846878\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                  9  330\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5742921492921493\n",
      "\n",
      "Combined Score: 0.6472486931291648\n",
      "\n",
      "{'score': 0.69123115140272484, 'Max Depth': 3, 'Random State': 1, 'Max Feature': 4, 'Min Samples Split': 5, 'Number of Trees': 50}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "def run_forest(X,Y):\n",
    "    runs = []\n",
    "\n",
    "    def random_forest(depth_max, feature_max, min_split, n, random):\n",
    "\n",
    "        #X_dummies = pd.get_dummies(X)\n",
    "        rfc = ensemble.RandomForestClassifier(\n",
    "            max_depth = depth_max,\n",
    "            max_features = feature_max,\n",
    "            min_samples_split = min_split,\n",
    "            n_estimators = n,\n",
    "            random_state = random\n",
    "            )\n",
    "\n",
    "        rfc.fit(X,Y)\n",
    "\n",
    "        print(f'Max Depth: {depth_max}, Max Feature = {feature_max}, Number of Trees = {n}, Random State = {random}, Min Samples Split: {min_split}')\n",
    "\n",
    "        score = recall_score (rfc, X, Y)\n",
    "        runs.append({'score':score, 'Max Depth':depth_max, 'Random State':random, 'Max Feature':feature_max, 'Min Samples Split':min_split, 'Number of Trees':n})\n",
    "\n",
    "    depth_maxs = [3,4,5]\n",
    "    randoms = [1]\n",
    "    feature_maxs = [4,5,6,7]\n",
    "    min_splits = [4,5,6,7]\n",
    "    ns = [10, 50, 100]\n",
    "\n",
    "    for depth_max in depth_maxs:\n",
    "        for feature_max in feature_maxs:\n",
    "            for min_split in min_splits:\n",
    "                for n in ns:\n",
    "                    for random in randoms:\n",
    "                        random_forest (depth_max, feature_max, min_split, n, random)\n",
    "                        \n",
    "    runs.sort(key = lambda run: run['score'])\n",
    "    print(runs[-1])\n",
    "\n",
    "run_forest(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The highest score using random forest is 69.1%. This was achieved using max_depth = 3, random_state = 1, max_features = 4, min_samples_split = 5. The score generally goes down as we use more features, and up as we increase the number of trees in the forest. The score is slightly higher than that of the best singular decision tree, which was 0.6456, but this is not a significant difference. It is important to note that this dataset has not optimized been optimized for the few categorical features, for which we may need to get dummies. Let's continue running through the models, then try them all again with dummy features added.\n",
    "FINAL SCORE: 65%\n",
    "\n",
    "\n",
    "# Support Vector Machines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear\n",
      "C = 1e-07\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.0001\n",
      "Training Score: 0.8855802166895286\n",
      "Testing Score: 0.8829657284870864\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6046492921492922\n",
      "\n",
      "Combined Score: 0.7159758666844098\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.001\n",
      "Training Score: 0.8600617611336464\n",
      "Testing Score: 0.8167229019324835\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                29  191\n",
      "1                15  324\n",
      "Negative Accuracy: 0.1318181818181818\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5992921492921492\n",
      "\n",
      "Combined Score: 0.686264450348283\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.01\n",
      "Training Score: 0.8006009772165299\n",
      "Testing Score: 0.7523930262327878\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                98  122\n",
      "1                57  282\n",
      "Negative Accuracy: 0.44545454545454544\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.6368082368082367\n",
      "\n",
      "Combined Score: 0.6830421525780572\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.1\n",
      "Training Score: 0.8093965972726395\n",
      "Testing Score: 0.7306977834174698\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                113  107\n",
      "1                 64  275\n",
      "Negative Accuracy: 0.5136363636363637\n",
      "Positive Accuracy: 0.8112094395280236\n",
      "Cross-Val Accuracy: 0.6422458172458173\n",
      "\n",
      "Combined Score: 0.6776266037144782\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.3\n",
      "Training Score: 0.8092800444816621\n",
      "Testing Score: 0.7139371326649762\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 65  274\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.8082595870206489\n",
      "Cross-Val Accuracy: 0.6333494208494208\n",
      "\n",
      "Combined Score: 0.6655845055756429\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.5\n",
      "Training Score: 0.8094129098041384\n",
      "Testing Score: 0.6954014695676244\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 64  275\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.8112094395280236\n",
      "Cross-Val Accuracy: 0.615460102960103\n",
      "\n",
      "Combined Score: 0.6474366496031116\n",
      "\n",
      "Kernel: linear\n",
      "C = 1\n",
      "Training Score: 0.8062746025570396\n",
      "Testing Score: 0.6857703858725016\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                103  117\n",
      "1                 57  282\n",
      "Negative Accuracy: 0.4681818181818182\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.5957207207207207\n",
      "\n",
      "Combined Score: 0.631740586781433\n",
      "\n",
      "Kernel: linear\n",
      "C = 100\n",
      "Training Score: 0.7787350238811321\n",
      "Testing Score: 0.6524775042624873\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 71  268\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.7905604719764012\n",
      "Cross-Val Accuracy: 0.5921332046332047\n",
      "\n",
      "Combined Score: 0.6162709244849178\n",
      "\n",
      "Kernel: linear\n",
      "C = 1000\n",
      "Training Score: 0.7748055265100625\n",
      "Testing Score: 0.667864305223448\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 76  263\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.775811209439528\n",
      "Cross-Val Accuracy: 0.5939189189189189\n",
      "\n",
      "Combined Score: 0.6234970734407306\n",
      "\n",
      "Kernel: linear\n",
      "C = 100000.0\n",
      "Training Score: 0.7685552358117178\n",
      "Testing Score: 0.6916292506864009\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 86  253\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.7463126843657817\n",
      "Cross-Val Accuracy: 0.6243725868725869\n",
      "\n",
      "Combined Score: 0.6512752523981125\n",
      "\n",
      "Kernel: rbf\n",
      "C = 1e-07\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.0001\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.001\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.01\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.1\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.3\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.5\n",
      "Training Score: 0.8898842782645578\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                11  209\n",
      "1                 0  339\n",
      "Negative Accuracy: 0.05\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 1\n",
      "Training Score: 0.9989682037637249\n",
      "Testing Score: 0.8783452418272102\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                218    2\n",
      "1                  0  339\n",
      "Negative Accuracy: 0.990909090909091\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6064350064350065\n",
      "\n",
      "Combined Score: 0.7151991005918881\n",
      "\n",
      "Kernel: rbf\n",
      "C = 100\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8741428437440698\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                220    0\n",
      "1                  0  339\n",
      "Negative Accuracy: 1.0\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6100064350064349\n",
      "\n",
      "Combined Score: 0.7156609985014889\n",
      "\n",
      "Kernel: rbf\n",
      "C = 1000\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8741428437440698\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                220    0\n",
      "1                  0  339\n",
      "Negative Accuracy: 1.0\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6100064350064349\n",
      "\n",
      "Combined Score: 0.7156609985014889\n",
      "\n",
      "Kernel: rbf\n",
      "C = 100000.0\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8741428437440698\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                220    0\n",
      "1                  0  339\n",
      "Negative Accuracy: 1.0\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6100064350064349\n",
      "\n",
      "Combined Score: 0.7156609985014889\n",
      "\n",
      "{'score': 0.71790673824974616, 'alpha': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "def run_svc(X,Y):\n",
    "\n",
    "    runs = []\n",
    "    def svc(alpha, kern):\n",
    "        svc = SVC(C=alpha, kernel=kern)\n",
    "        svc.fit(X,Y)\n",
    "        print(f'Kernel: {kern}')\n",
    "        print(f'C = {alpha}')\n",
    "\n",
    "        score = recall_score(svc, X, Y)\n",
    "        \n",
    "        runs.append({'score': score, 'alpha': alpha, 'kernel': kern})\n",
    "\n",
    "    kernels = ['linear', 'rbf']\n",
    "    alpha_nums = [1e-7, 1e-4, 1e-3, 1e-2, 0.1, 0.3, 0.5, 1, 100, 1000, 1e5]\n",
    "\n",
    "    for kern in kernels:\n",
    "        for alpha in alpha_nums:\n",
    "            svc(alpha, kern)\n",
    "            \n",
    "    runs.sort(key = lambda run: run['score'])\n",
    "    print(runs[-1])\n",
    "            \n",
    "run_svc(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best SVM model uses a lambda 0.3 to achieve a combined score of 71.8%. So far, this is the best score. This score is made up of 51% negative accuracy (the highest value so far), 81% positive accuracy, testing score of 71!, and training score of 77%. Overfitting is present but not strong."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Boosting Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.996610710064811\n",
      "Testing Score: 0.6633871335805566\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                213    7\n",
      "1                  4  335\n",
      "Negative Accuracy: 0.9681818181818181\n",
      "Positive Accuracy: 0.9882005899705014\n",
      "Cross-Val Accuracy: 0.53497425997426\n",
      "\n",
      "Combined Score: 0.5863394094167786\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAETCAYAAABeATFVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSSeWJEmtSSeWJEmt+S+jQCkOfW9KzwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11d073f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Index(['TreatmentType', 'M_stage', 'IsSCLC', 'gtv1', 'DyspGT2',\n",
       "       'second dose per fracion', 'toxesohigh2', 'chemo3g', 'chemo', 'gender',\n",
       "       'second total dose', 'second fractions', 'SmokingStatus',\n",
       "       'DeltaDyspGe1', 'PA', 'dose per fraction', 'Modality', 'Locatie',\n",
       "       'toxeso', 'T_stage', 'intake_who', 'OverallPostRTDyspFullScore',\n",
       "       'PacksPerDay', 'OverallBaselineDysp', 'pretoxeso', 'total dose',\n",
       "       'N_stage', 'CumOTT', 'BED', 'fractions', 'ott', 'yearrt',\n",
       "       'CumultativeTotalTumorDose', 'meanlungdose', 'lungv20', 'med', 'age',\n",
       "       'tumorload', 'maxeso', 'FEV'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import ensemble\n",
    "\n",
    "params = {'n_estimators': 500,\n",
    "          'max_depth': 2,\n",
    "          'loss': 'deviance',\n",
    "          'subsample': 0.5\n",
    "         }\n",
    "def run_boosting (params):\n",
    "    clf = ensemble.GradientBoostingClassifier(**params)\n",
    "    clf.fit(X, Y)\n",
    "\n",
    "    score = recall_score(clf, X, Y)\n",
    "\n",
    "    feature_importance = clf.feature_importances_\n",
    "    feature_importance = 100.0 * (feature_importance / feature_importance.max())\n",
    "    sorted_idx = np.argsort(feature_importance)\n",
    "    pos = np.arange(sorted_idx.shape[0]) + .5\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.barh(pos, feature_importance[sorted_idx], align='center')\n",
    "    plt.yticks(pos, X.columns[sorted_idx])\n",
    "    plt.xlabel('Relative Importance')\n",
    "    plt.title('Variable Importance')\n",
    "    plt.show()\n",
    "\n",
    "    sorted_col = X.columns[sorted_idx]\n",
    "    return sorted_col\n",
    "    \n",
    "run_boosting(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9947030624921824\n",
      "Testing Score: 0.6589937535130675\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                210   10\n",
      "1                  4  335\n",
      "Negative Accuracy: 0.9545454545454546\n",
      "Positive Accuracy: 0.9882005899705014\n",
      "Cross-Val Accuracy: 0.5475386100386099\n",
      "\n",
      "Combined Score: 0.592120667428393\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATEAAAETCAYAAABeATFVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x11e72dc18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['gender', 'chemo', 'PA', 'toxeso', 'DeltaDyspGe1',\n",
      "       'OverallPostRTDyspFullScore', 'Modality', 'SmokingStatus',\n",
      "       'dose per fraction', 'pretoxeso', 'T_stage', 'PacksPerDay',\n",
      "       'OverallBaselineDysp', 'Locatie', 'intake_who', 'total dose', 'N_stage',\n",
      "       'BED', 'CumOTT', 'fractions', 'ott', 'yearrt',\n",
      "       'CumultativeTotalTumorDose', 'meanlungdose', 'lungv20', 'maxeso', 'age',\n",
      "       'med', 'tumorload', 'FEV'],\n",
      "      dtype='object')\n",
      "   gender     chemo   PA  toxeso  DeltaDyspGe1  OverallPostRTDyspFullScore  \\\n",
      "0       0  1.000000  0.0     2.0           0.0                           0   \n",
      "1       0  0.736142  1.0     2.0           0.0                           1   \n",
      "2       1  0.736142  1.0     1.0           1.0                           1   \n",
      "3       1  1.000000  1.0     1.0           0.0                           1   \n",
      "4       1  0.736142  1.0     0.0           0.0                           2   \n",
      "\n",
      "   Modality  SmokingStatus  dose per fraction  pretoxeso  T_stage  \\\n",
      "0       0.0       1.252155           2.088385        2.0      0.0   \n",
      "1       2.0       1.000000           1.500000        2.0      3.0   \n",
      "2       1.0       1.000000           2.088385        0.0      1.0   \n",
      "3       2.0       1.000000           2.000000        1.0      1.0   \n",
      "4       2.0       1.000000           1.800000        0.0      1.0   \n",
      "\n",
      "   PacksPerDay  OverallBaselineDysp  Locatie  intake_who  total dose  N_stage  \\\n",
      "0     0.727778                  0.0      1.0         2.0   54.670172      2.0   \n",
      "1     0.727778                  1.0      0.0         1.0   45.000000      2.0   \n",
      "2     0.727778                  0.0      0.0         1.0   54.670172      3.0   \n",
      "3     0.727778                  1.0      0.0         1.0   33.000000      3.0   \n",
      "4     0.727778                  2.0      2.0         2.0   72.000000      2.0   \n",
      "\n",
      "         BED  CumOTT  fractions  ott  yearrt  CumultativeTotalTumorDose  \\\n",
      "0  70.386818      21  28.802575   21  2010.0                      45.00   \n",
      "1  78.150000      36  30.000000   36  2014.0                      67.00   \n",
      "2  70.386818      24  28.802575   24  2010.0                      52.25   \n",
      "3  52.800000      36  22.000000   36  2013.0                      69.00   \n",
      "4  84.960000      28  40.000000   28  2013.0                      72.00   \n",
      "\n",
      "   meanlungdose    lungv20     maxeso  age        med   tumorload        FEV  \n",
      "0     15.417800  33.848500  44.898900   67  17.034600   52.505500  97.000000  \n",
      "1     16.680025  22.260337  49.199991   69  20.334135  114.555789  61.000000  \n",
      "2     16.680025  22.260337  49.199991   82  20.334135  114.555789  76.697907  \n",
      "3     25.042800  11.988800  48.921700   77  17.229800   42.274500  91.000000  \n",
      "4     16.680025  22.260337  49.199991   83  20.334135  114.555789  76.697907  \n"
     ]
    }
   ],
   "source": [
    "sorted_col = run_boosting(params)\n",
    "reduced_col = sorted_col[10:]\n",
    "\n",
    "print(reduced_col)\n",
    "\n",
    "X_10 = df[reduced_col]\n",
    "print(X_10.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   gender     chemo   PA  toxeso  DeltaDyspGe1  OverallPostRTDyspFullScore  \\\n",
      "0       0  1.000000  0.0     2.0           0.0                           0   \n",
      "1       0  0.736142  1.0     2.0           0.0                           1   \n",
      "2       1  0.736142  1.0     1.0           1.0                           1   \n",
      "3       1  1.000000  1.0     1.0           0.0                           1   \n",
      "4       1  0.736142  1.0     0.0           0.0                           2   \n",
      "\n",
      "   Modality  SmokingStatus  dose per fraction  pretoxeso  T_stage  \\\n",
      "0       0.0       1.252155           2.088385        2.0      0.0   \n",
      "1       2.0       1.000000           1.500000        2.0      3.0   \n",
      "2       1.0       1.000000           2.088385        0.0      1.0   \n",
      "3       2.0       1.000000           2.000000        1.0      1.0   \n",
      "4       2.0       1.000000           1.800000        0.0      1.0   \n",
      "\n",
      "   PacksPerDay  OverallBaselineDysp  Locatie  intake_who  total dose  N_stage  \\\n",
      "0     0.727778                  0.0      1.0         2.0   54.670172      2.0   \n",
      "1     0.727778                  1.0      0.0         1.0   45.000000      2.0   \n",
      "2     0.727778                  0.0      0.0         1.0   54.670172      3.0   \n",
      "3     0.727778                  1.0      0.0         1.0   33.000000      3.0   \n",
      "4     0.727778                  2.0      2.0         2.0   72.000000      2.0   \n",
      "\n",
      "         BED  CumOTT  fractions  ott  yearrt  CumultativeTotalTumorDose  \\\n",
      "0  70.386818      21  28.802575   21  2010.0                      45.00   \n",
      "1  78.150000      36  30.000000   36  2014.0                      67.00   \n",
      "2  70.386818      24  28.802575   24  2010.0                      52.25   \n",
      "3  52.800000      36  22.000000   36  2013.0                      69.00   \n",
      "4  84.960000      28  40.000000   28  2013.0                      72.00   \n",
      "\n",
      "   meanlungdose    lungv20     maxeso  age        med   tumorload        FEV  \n",
      "0     15.417800  33.848500  44.898900   67  17.034600   52.505500  97.000000  \n",
      "1     16.680025  22.260337  49.199991   69  20.334135  114.555789  61.000000  \n",
      "2     16.680025  22.260337  49.199991   82  20.334135  114.555789  76.697907  \n",
      "3     25.042800  11.988800  48.921700   77  17.229800   42.274500  91.000000  \n",
      "4     16.680025  22.260337  49.199991   83  20.334135  114.555789  76.697907  \n",
      "   yearrt        med     maxeso  gender  intake_who  age     chemo  ott  \\\n",
      "0  2010.0  17.034600  44.898900       0         2.0   67  1.000000   21   \n",
      "1  2014.0  20.334135  49.199991       0         1.0   69  0.736142   36   \n",
      "2  2010.0  20.334135  49.199991       1         1.0   82  0.736142   24   \n",
      "3  2013.0  17.229800  48.921700       1         1.0   77  1.000000   36   \n",
      "4  2013.0  20.334135  49.199991       1         2.0   83  0.736142   28   \n",
      "\n",
      "    chemo3g   gtv1   tumorload  toxeso  toxesohigh2  pretoxeso  \\\n",
      "0  2.000000  31.95   52.505500     2.0          0.0        2.0   \n",
      "1  1.354767  31.95  114.555789     2.0          0.0        2.0   \n",
      "2  1.354767  31.95  114.555789     1.0          0.0        0.0   \n",
      "3  2.000000  31.95   42.274500     1.0          0.0        1.0   \n",
      "4  1.354767  31.95  114.555789     0.0          0.0        0.0   \n",
      "\n",
      "   dose per fraction  fractions  total dose  second dose per fracion  \\\n",
      "0           2.088385  28.802575   54.670172                 2.274306   \n",
      "1           1.500000  30.000000   45.000000                 2.000000   \n",
      "2           2.088385  28.802575   54.670172                 2.274306   \n",
      "3           2.000000  22.000000   33.000000                 2.274306   \n",
      "4           1.800000  40.000000   72.000000                 2.274306   \n",
      "\n",
      "   second fractions  second total dose        BED  Modality  PacksPerDay  \\\n",
      "0         10.175676          20.364865  70.386818       0.0     0.727778   \n",
      "1         11.000000          22.000000  78.150000       2.0     0.727778   \n",
      "2         10.175676          20.364865  70.386818       1.0     0.727778   \n",
      "3         10.175676          20.364865  52.800000       2.0     0.727778   \n",
      "4         10.175676          20.364865  84.960000       2.0     0.727778   \n",
      "\n",
      "   SmokingStatus  IsSCLC  T_stage  N_stage  M_stage   PA  Locatie        FEV  \\\n",
      "0       1.252155       0      0.0      2.0      0.0  0.0      1.0  97.000000   \n",
      "1       1.000000       0      3.0      2.0      0.0  1.0      0.0  61.000000   \n",
      "2       1.000000       0      1.0      3.0      0.0  1.0      0.0  76.697907   \n",
      "3       1.000000       0      1.0      3.0      0.0  1.0      0.0  91.000000   \n",
      "4       1.000000       0      1.0      2.0      0.0  1.0      2.0  76.697907   \n",
      "\n",
      "   CumultativeTotalTumorDose  meanlungdose    lungv20  CumOTT  \\\n",
      "0                      45.00     15.417800  33.848500      21   \n",
      "1                      67.00     16.680025  22.260337      36   \n",
      "2                      52.25     16.680025  22.260337      24   \n",
      "3                      69.00     25.042800  11.988800      36   \n",
      "4                      72.00     16.680025  22.260337      28   \n",
      "\n",
      "   OverallBaselineDysp  OverallPostRTDyspFullScore  DyspGT2  DeltaDyspGe1  \\\n",
      "0                  0.0                           0        0           0.0   \n",
      "1                  1.0                           1        0           0.0   \n",
      "2                  0.0                           1        0           1.0   \n",
      "3                  1.0                           1        0           0.0   \n",
      "4                  2.0                           2        0           0.0   \n",
      "\n",
      "   TreatmentType  \n",
      "0            2.0  \n",
      "1            2.0  \n",
      "2            2.0  \n",
      "3            2.0  \n",
      "4            2.0  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>gender</th>\n",
       "      <th>chemo</th>\n",
       "      <th>PA</th>\n",
       "      <th>toxeso</th>\n",
       "      <th>DeltaDyspGe1</th>\n",
       "      <th>OverallPostRTDyspFullScore</th>\n",
       "      <th>Modality</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>dose per fraction</th>\n",
       "      <th>pretoxeso</th>\n",
       "      <th>T_stage</th>\n",
       "      <th>PacksPerDay</th>\n",
       "      <th>OverallBaselineDysp</th>\n",
       "      <th>Locatie</th>\n",
       "      <th>intake_who</th>\n",
       "      <th>total dose</th>\n",
       "      <th>N_stage</th>\n",
       "      <th>BED</th>\n",
       "      <th>CumOTT</th>\n",
       "      <th>fractions</th>\n",
       "      <th>ott</th>\n",
       "      <th>yearrt</th>\n",
       "      <th>CumultativeTotalTumorDose</th>\n",
       "      <th>meanlungdose</th>\n",
       "      <th>lungv20</th>\n",
       "      <th>maxeso</th>\n",
       "      <th>age</th>\n",
       "      <th>med</th>\n",
       "      <th>tumorload</th>\n",
       "      <th>FEV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.252155</td>\n",
       "      <td>2.088385</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.670172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.386818</td>\n",
       "      <td>21</td>\n",
       "      <td>28.802575</td>\n",
       "      <td>21</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>15.417800</td>\n",
       "      <td>33.848500</td>\n",
       "      <td>44.898900</td>\n",
       "      <td>67</td>\n",
       "      <td>17.034600</td>\n",
       "      <td>52.505500</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.736142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>36</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>16.680025</td>\n",
       "      <td>22.260337</td>\n",
       "      <td>49.199991</td>\n",
       "      <td>69</td>\n",
       "      <td>20.334135</td>\n",
       "      <td>114.555789</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.088385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.670172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.386818</td>\n",
       "      <td>24</td>\n",
       "      <td>28.802575</td>\n",
       "      <td>24</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>52.25</td>\n",
       "      <td>16.680025</td>\n",
       "      <td>22.260337</td>\n",
       "      <td>49.199991</td>\n",
       "      <td>82</td>\n",
       "      <td>20.334135</td>\n",
       "      <td>114.555789</td>\n",
       "      <td>76.697907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.800000</td>\n",
       "      <td>36</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>69.00</td>\n",
       "      <td>25.042800</td>\n",
       "      <td>11.988800</td>\n",
       "      <td>48.921700</td>\n",
       "      <td>77</td>\n",
       "      <td>17.229800</td>\n",
       "      <td>42.274500</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.736142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.960000</td>\n",
       "      <td>28</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>16.680025</td>\n",
       "      <td>22.260337</td>\n",
       "      <td>49.199991</td>\n",
       "      <td>83</td>\n",
       "      <td>20.334135</td>\n",
       "      <td>114.555789</td>\n",
       "      <td>76.697907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index  gender     chemo   PA  toxeso  DeltaDyspGe1  \\\n",
       "0      0       0  1.000000  0.0     2.0           0.0   \n",
       "1      1       0  0.736142  1.0     2.0           0.0   \n",
       "2      2       1  0.736142  1.0     1.0           1.0   \n",
       "3      3       1  1.000000  1.0     1.0           0.0   \n",
       "4      4       1  0.736142  1.0     0.0           0.0   \n",
       "\n",
       "   OverallPostRTDyspFullScore  Modality  SmokingStatus  dose per fraction  \\\n",
       "0                           0       0.0       1.252155           2.088385   \n",
       "1                           1       2.0       1.000000           1.500000   \n",
       "2                           1       1.0       1.000000           2.088385   \n",
       "3                           1       2.0       1.000000           2.000000   \n",
       "4                           2       2.0       1.000000           1.800000   \n",
       "\n",
       "   pretoxeso  T_stage  PacksPerDay  OverallBaselineDysp  Locatie  intake_who  \\\n",
       "0        2.0      0.0     0.727778                  0.0      1.0         2.0   \n",
       "1        2.0      3.0     0.727778                  1.0      0.0         1.0   \n",
       "2        0.0      1.0     0.727778                  0.0      0.0         1.0   \n",
       "3        1.0      1.0     0.727778                  1.0      0.0         1.0   \n",
       "4        0.0      1.0     0.727778                  2.0      2.0         2.0   \n",
       "\n",
       "   total dose  N_stage        BED  CumOTT  fractions  ott  yearrt  \\\n",
       "0   54.670172      2.0  70.386818      21  28.802575   21  2010.0   \n",
       "1   45.000000      2.0  78.150000      36  30.000000   36  2014.0   \n",
       "2   54.670172      3.0  70.386818      24  28.802575   24  2010.0   \n",
       "3   33.000000      3.0  52.800000      36  22.000000   36  2013.0   \n",
       "4   72.000000      2.0  84.960000      28  40.000000   28  2013.0   \n",
       "\n",
       "   CumultativeTotalTumorDose  meanlungdose    lungv20     maxeso  age  \\\n",
       "0                      45.00     15.417800  33.848500  44.898900   67   \n",
       "1                      67.00     16.680025  22.260337  49.199991   69   \n",
       "2                      52.25     16.680025  22.260337  49.199991   82   \n",
       "3                      69.00     25.042800  11.988800  48.921700   77   \n",
       "4                      72.00     16.680025  22.260337  49.199991   83   \n",
       "\n",
       "         med   tumorload        FEV  \n",
       "0  17.034600   52.505500  97.000000  \n",
       "1  20.334135  114.555789  61.000000  \n",
       "2  20.334135  114.555789  76.697907  \n",
       "3  17.229800   42.274500  91.000000  \n",
       "4  20.334135  114.555789  76.697907  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(X_10.head())\n",
    "print(X.head())\n",
    "X_10.reset_index().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "C = 0.001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "C = 0.01\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8327554417299691\n",
      "Testing Score: 0.8061064618803844\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                43  177\n",
      "1                37  302\n",
      "Negative Accuracy: 0.19545454545454546\n",
      "Positive Accuracy: 0.8908554572271387\n",
      "Cross-Val Accuracy: 0.602992277992278\n",
      "\n",
      "Combined Score: 0.6842379515475205\n",
      "\n",
      "C = 0.1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8008247543173512\n",
      "Testing Score: 0.7551448590157704\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                83  137\n",
      "1                57  282\n",
      "Negative Accuracy: 0.37727272727272726\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.6136583011583012\n",
      "\n",
      "Combined Score: 0.6702529243012889\n",
      "\n",
      "C = 0.3\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8038947352897399\n",
      "Testing Score: 0.7218676941329585\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                58  281\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.8289085545722714\n",
      "Cross-Val Accuracy: 0.6082528957528958\n",
      "\n",
      "Combined Score: 0.6536988151049208\n",
      "\n",
      "C = 0.5\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8031864822653162\n",
      "Testing Score: 0.71761751143145\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                56  283\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6171975546975548\n",
      "\n",
      "Combined Score: 0.6573655373911129\n",
      "\n",
      "C = 1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7973899698015924\n",
      "Testing Score: 0.7161586636305267\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                56  283\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6189671814671814\n",
      "\n",
      "Combined Score: 0.6578437743325196\n",
      "\n",
      "C = 100\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7978300020155709\n",
      "Testing Score: 0.7085808302588124\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6136261261261261\n",
      "\n",
      "Combined Score: 0.6516080077792006\n",
      "\n",
      "C = 1000\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.79771426835594\n",
      "Testing Score: 0.7085808302588124\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6172297297297298\n",
      "\n",
      "Combined Score: 0.6537701699413628\n",
      "\n",
      "C = 100000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.79771426835594\n",
      "Testing Score: 0.7118882391822672\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6136261261261261\n",
      "\n",
      "Combined Score: 0.6529309713485825\n",
      "\n",
      "C = 10000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.79771426835594\n",
      "Testing Score: 0.7085808302588124\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6136261261261261\n",
      "\n",
      "Combined Score: 0.6516080077792006\n",
      "\n",
      "C = 1000000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7983141648483756\n",
      "Testing Score: 0.7114379731159552\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6172297297297298\n",
      "\n",
      "Combined Score: 0.65491302708422\n",
      "\n",
      "{'score': 0.71790673824974616, 'alpha': 0.001}\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_10, Y, 'l1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is 62.4, alpha = 1e7. Compare to baseline at 62.3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8272967116881624\n",
      "Testing Score: 0.7967135827147558\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                36  303\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.8938053097345132\n",
      "Cross-Val Accuracy: 0.5958011583011584\n",
      "\n",
      "Combined Score: 0.6761661280665974\n",
      "\n",
      "C = 0.0001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.8272967116881624\n",
      "Testing Score: 0.7990604586765903\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                36  303\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.8938053097345132\n",
      "Cross-Val Accuracy: 0.5940154440154439\n",
      "\n",
      "Combined Score: 0.6760334498799025\n",
      "\n",
      "C = 0.001\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7978955513323458\n",
      "Testing Score: 0.7616816267464271\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                51  288\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.8495575221238938\n",
      "Cross-Val Accuracy: 0.5994047619047619\n",
      "\n",
      "Combined Score: 0.664315507841428\n",
      "\n",
      "C = 0.01\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.799805075337186\n",
      "Testing Score: 0.7568844956700969\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                84  136\n",
      "1                61  278\n",
      "Negative Accuracy: 0.38181818181818183\n",
      "Positive Accuracy: 0.8200589970501475\n",
      "Cross-Val Accuracy: 0.627927927927928\n",
      "\n",
      "Combined Score: 0.6795105550247955\n",
      "\n",
      "C = 0.1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7998663087402986\n",
      "Testing Score: 0.7252147264568907\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                59  280\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.8259587020648967\n",
      "Cross-Val Accuracy: 0.6153796653796654\n",
      "\n",
      "Combined Score: 0.6593136898105555\n",
      "\n",
      "C = 0.3\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7927228699805579\n",
      "Testing Score: 0.722064582110856\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                100  120\n",
      "1                 57  282\n",
      "Negative Accuracy: 0.45454545454545453\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.617181467181467\n",
      "\n",
      "Combined Score: 0.6591347131532226\n",
      "\n",
      "C = 0.5\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7936502384329513\n",
      "Testing Score: 0.7158203051599893\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                101  119\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4590909090909091\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6136100386100386\n",
      "\n",
      "Combined Score: 0.6544941452300188\n",
      "\n",
      "C = 1\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7936537486237192\n",
      "Testing Score: 0.708548945065641\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                101  119\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4590909090909091\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6172136422136422\n",
      "\n",
      "Combined Score: 0.6537477633544417\n",
      "\n",
      "C = 100\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7985780591918495\n",
      "Testing Score: 0.7116975356411975\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6172458172458173\n",
      "\n",
      "Combined Score: 0.6550265046039694\n",
      "\n",
      "C = 1000\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7988830981020452\n",
      "Testing Score: 0.7117818828211832\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                103  117\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4681818181818182\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6172297297297298\n",
      "\n",
      "Combined Score: 0.6550505909663111\n",
      "\n",
      "C = 100000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7968556540559016\n",
      "Testing Score: 0.7173664757302065\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 57  282\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.6172458172458172\n",
      "\n",
      "Combined Score: 0.657294080639573\n",
      "\n",
      "C = 10000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7983166055668404\n",
      "Testing Score: 0.7141522404879673\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 56  283\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.8348082595870207\n",
      "Cross-Val Accuracy: 0.6208172458172458\n",
      "\n",
      "Combined Score: 0.6581512436855343\n",
      "\n",
      "C = 1000000000.0\n",
      "\n",
      "\n",
      "\n",
      "Training Score: 0.7961255213698418\n",
      "Testing Score: 0.7114250724996524\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                101  119\n",
      "1                 58  281\n",
      "Negative Accuracy: 0.4590909090909091\n",
      "Positive Accuracy: 0.8289085545722714\n",
      "Cross-Val Accuracy: 0.6154440154440154\n",
      "\n",
      "Combined Score: 0.6538364382662702\n",
      "\n",
      "{'score': 0.67951055502479552, 'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "run_logistic(X_10, Y, 'l2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Score is 63.2, alpha = 0.1. Compare to baseline at 62.8."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 4\n",
      "Training Score: 0.8475896312598243\n",
      "Testing Score: 0.8093975527083259\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                25  314\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6704771678014771\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 5\n",
      "Training Score: 0.8475896312598243\n",
      "Testing Score: 0.8093975527083259\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                25  314\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6704771678014771\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 6\n",
      "Training Score: 0.8475896312598243\n",
      "Testing Score: 0.8093975527083259\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                25  314\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6704771678014771\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 4, Min Samples Split = 7\n",
      "Training Score: 0.8475896312598243\n",
      "Testing Score: 0.8093975527083259\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                48  172\n",
      "1                25  314\n",
      "Negative Accuracy: 0.21818181818181817\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6704771678014771\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 4\n",
      "Training Score: 0.8214062932189213\n",
      "Testing Score: 0.7123399536809067\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                89  131\n",
      "1                68  271\n",
      "Negative Accuracy: 0.40454545454545454\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5493082368082367\n",
      "\n",
      "Combined Score: 0.6145209235573047\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 5\n",
      "Training Score: 0.8214062932189213\n",
      "Testing Score: 0.7123399536809067\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                89  131\n",
      "1                68  271\n",
      "Negative Accuracy: 0.40454545454545454\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5493082368082367\n",
      "\n",
      "Combined Score: 0.6145209235573047\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 6\n",
      "Training Score: 0.8214062932189213\n",
      "Testing Score: 0.7123399536809067\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                89  131\n",
      "1                68  271\n",
      "Negative Accuracy: 0.40454545454545454\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5493082368082367\n",
      "\n",
      "Combined Score: 0.6145209235573047\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 5, Min Samples Split = 7\n",
      "Training Score: 0.8214062932189213\n",
      "Testing Score: 0.7123399536809067\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                89  131\n",
      "1                68  271\n",
      "Negative Accuracy: 0.40454545454545454\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5493082368082367\n",
      "\n",
      "Combined Score: 0.6145209235573047\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 4\n",
      "Training Score: 0.8582421249691106\n",
      "Testing Score: 0.7895488634597758\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                77  143\n",
      "1                68  271\n",
      "Negative Accuracy: 0.35\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5600064350064351\n",
      "\n",
      "Combined Score: 0.6518234063877714\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 5\n",
      "Training Score: 0.8582421249691106\n",
      "Testing Score: 0.7895488634597758\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                77  143\n",
      "1                68  271\n",
      "Negative Accuracy: 0.35\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5600064350064351\n",
      "\n",
      "Combined Score: 0.6518234063877714\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 6\n",
      "Training Score: 0.8582421249691106\n",
      "Testing Score: 0.7895488634597758\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                77  143\n",
      "1                68  271\n",
      "Negative Accuracy: 0.35\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5600064350064351\n",
      "\n",
      "Combined Score: 0.6518234063877714\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 6, Min Samples Split = 7\n",
      "Training Score: 0.8582421249691106\n",
      "Testing Score: 0.7895488634597758\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                77  143\n",
      "1                68  271\n",
      "Negative Accuracy: 0.35\n",
      "Positive Accuracy: 0.799410029498525\n",
      "Cross-Val Accuracy: 0.5600064350064351\n",
      "\n",
      "Combined Score: 0.6518234063877714\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 4\n",
      "Training Score: 0.79562767680628\n",
      "Testing Score: 0.7088491975227287\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                11  209\n",
      "1                 1  338\n",
      "Negative Accuracy: 0.05\n",
      "Positive Accuracy: 0.9970501474926253\n",
      "Cross-Val Accuracy: 0.550997425997426\n",
      "\n",
      "Combined Score: 0.6141381346075471\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 5\n",
      "Training Score: 0.79562767680628\n",
      "Testing Score: 0.7088491975227287\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                11  209\n",
      "1                 1  338\n",
      "Negative Accuracy: 0.05\n",
      "Positive Accuracy: 0.9970501474926253\n",
      "Cross-Val Accuracy: 0.550997425997426\n",
      "\n",
      "Combined Score: 0.6141381346075471\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 6\n",
      "Training Score: 0.79562767680628\n",
      "Testing Score: 0.7088491975227287\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                11  209\n",
      "1                 1  338\n",
      "Negative Accuracy: 0.05\n",
      "Positive Accuracy: 0.9970501474926253\n",
      "Cross-Val Accuracy: 0.550997425997426\n",
      "\n",
      "Combined Score: 0.6141381346075471\n",
      "\n",
      "Max Depth: 3, Random State = 1, Max Feature = 7, Min Samples Split = 7\n",
      "Training Score: 0.79562767680628\n",
      "Testing Score: 0.7088491975227287\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                11  209\n",
      "1                 1  338\n",
      "Negative Accuracy: 0.05\n",
      "Positive Accuracy: 0.9970501474926253\n",
      "Cross-Val Accuracy: 0.550997425997426\n",
      "\n",
      "Combined Score: 0.6141381346075471\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 4\n",
      "Training Score: 0.8717329129045343\n",
      "Testing Score: 0.8191713405093488\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                42  178\n",
      "1                13  326\n",
      "Negative Accuracy: 0.19090909090909092\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6829581114933148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 5\n",
      "Training Score: 0.8714957031612984\n",
      "Testing Score: 0.8191713405093488\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                30  190\n",
      "1                12  327\n",
      "Negative Accuracy: 0.13636363636363635\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6829581114933148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 6\n",
      "Training Score: 0.8714957031612984\n",
      "Testing Score: 0.8191713405093488\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                30  190\n",
      "1                12  327\n",
      "Negative Accuracy: 0.13636363636363635\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6829581114933148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 4, Min Samples Split = 7\n",
      "Training Score: 0.8714957031612984\n",
      "Testing Score: 0.8191713405093488\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                30  190\n",
      "1                12  327\n",
      "Negative Accuracy: 0.13636363636363635\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5921492921492921\n",
      "\n",
      "Combined Score: 0.6829581114933148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 4\n",
      "Training Score: 0.8167411905229869\n",
      "Testing Score: 0.7361656999721046\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                60  160\n",
      "1                28  311\n",
      "Negative Accuracy: 0.2727272727272727\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5689671814671814\n",
      "\n",
      "Combined Score: 0.6358465888691507\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 5\n",
      "Training Score: 0.8167411905229869\n",
      "Testing Score: 0.7361656999721046\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                60  160\n",
      "1                28  311\n",
      "Negative Accuracy: 0.2727272727272727\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5689671814671814\n",
      "\n",
      "Combined Score: 0.6358465888691507\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 6\n",
      "Training Score: 0.8167411905229869\n",
      "Testing Score: 0.7361656999721046\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                60  160\n",
      "1                28  311\n",
      "Negative Accuracy: 0.2727272727272727\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5689671814671814\n",
      "\n",
      "Combined Score: 0.6358465888691507\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 5, Min Samples Split = 7\n",
      "Training Score: 0.8167411905229869\n",
      "Testing Score: 0.7361656999721046\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                60  160\n",
      "1                28  311\n",
      "Negative Accuracy: 0.2727272727272727\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5689671814671814\n",
      "\n",
      "Combined Score: 0.6358465888691507\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 4\n",
      "Training Score: 0.776097194131986\n",
      "Testing Score: 0.6761664624149486\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                69  270\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.7964601769911505\n",
      "Cross-Val Accuracy: 0.5368404118404119\n",
      "\n",
      "Combined Score: 0.5925708320702265\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 5\n",
      "Training Score: 0.7750260609468846\n",
      "Testing Score: 0.6699818994994171\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                69  270\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.7964601769911505\n",
      "Cross-Val Accuracy: 0.5260456885456886\n",
      "\n",
      "Combined Score: 0.5836201729271799\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 6\n",
      "Training Score: 0.7750260609468846\n",
      "Testing Score: 0.6699818994994171\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                69  270\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.7964601769911505\n",
      "Cross-Val Accuracy: 0.5260456885456886\n",
      "\n",
      "Combined Score: 0.5836201729271799\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 6, Min Samples Split = 7\n",
      "Training Score: 0.773388668996736\n",
      "Testing Score: 0.6699818994994171\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                69  270\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.7964601769911505\n",
      "Cross-Val Accuracy: 0.5260456885456886\n",
      "\n",
      "Combined Score: 0.5836201729271799\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 4\n",
      "Training Score: 0.8399737160060201\n",
      "Testing Score: 0.7435854468943345\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                56  164\n",
      "1                29  310\n",
      "Negative Accuracy: 0.2545454545454545\n",
      "Positive Accuracy: 0.9144542772861357\n",
      "Cross-Val Accuracy: 0.5726351351351351\n",
      "\n",
      "Combined Score: 0.6410152598388148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 5\n",
      "Training Score: 0.8399737160060201\n",
      "Testing Score: 0.7435854468943345\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                51  288\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.8495575221238938\n",
      "Cross-Val Accuracy: 0.5726351351351351\n",
      "\n",
      "Combined Score: 0.6410152598388148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 6\n",
      "Training Score: 0.8399737160060201\n",
      "Testing Score: 0.7435854468943345\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                51  288\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.8495575221238938\n",
      "Cross-Val Accuracy: 0.5726351351351351\n",
      "\n",
      "Combined Score: 0.6410152598388148\n",
      "\n",
      "Max Depth: 4, Random State = 1, Max Feature = 7, Min Samples Split = 7\n",
      "Training Score: 0.8399737160060201\n",
      "Testing Score: 0.7435854468943345\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                92  128\n",
      "1                51  288\n",
      "Negative Accuracy: 0.41818181818181815\n",
      "Positive Accuracy: 0.8495575221238938\n",
      "Cross-Val Accuracy: 0.5726351351351351\n",
      "\n",
      "Combined Score: 0.6410152598388148\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 4\n",
      "Training Score: 0.8472208824364909\n",
      "Testing Score: 0.782039737098908\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                37  183\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.16818181818181818\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5903153153153153\n",
      "\n",
      "Combined Score: 0.6670050840287524\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 5\n",
      "Training Score: 0.8481327662800352\n",
      "Testing Score: 0.7815953574092451\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                37  183\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.16818181818181818\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5885135135135136\n",
      "\n",
      "Combined Score: 0.6657462510718062\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 6\n",
      "Training Score: 0.8465028960466812\n",
      "Testing Score: 0.7741996656224728\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                37  183\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.16818181818181818\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5885135135135136\n",
      "\n",
      "Combined Score: 0.6627879743570972\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 4, Min Samples Split = 7\n",
      "Training Score: 0.8465028960466812\n",
      "Testing Score: 0.7741996656224728\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                37  183\n",
      "1                 8  331\n",
      "Negative Accuracy: 0.16818181818181818\n",
      "Positive Accuracy: 0.976401179941003\n",
      "Cross-Val Accuracy: 0.5885135135135136\n",
      "\n",
      "Combined Score: 0.6627879743570972\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 4\n",
      "Training Score: 0.745027045041604\n",
      "Testing Score: 0.5420735804644502\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                31  308\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9085545722713865\n",
      "Cross-Val Accuracy: 0.5277670527670528\n",
      "\n",
      "Combined Score: 0.5334896638460118\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 5\n",
      "Training Score: 0.745027045041604\n",
      "Testing Score: 0.5420735804644502\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                31  308\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9085545722713865\n",
      "Cross-Val Accuracy: 0.5277670527670528\n",
      "\n",
      "Combined Score: 0.5334896638460118\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 6\n",
      "Training Score: 0.745027045041604\n",
      "Testing Score: 0.5420735804644502\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                31  308\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9085545722713865\n",
      "Cross-Val Accuracy: 0.5277670527670528\n",
      "\n",
      "Combined Score: 0.5334896638460118\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 5, Min Samples Split = 7\n",
      "Training Score: 0.7434718238385138\n",
      "Testing Score: 0.5420735804644502\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                64  156\n",
      "1                31  308\n",
      "Negative Accuracy: 0.2909090909090909\n",
      "Positive Accuracy: 0.9085545722713865\n",
      "Cross-Val Accuracy: 0.5277670527670528\n",
      "\n",
      "Combined Score: 0.5334896638460118\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 4\n",
      "Training Score: 0.8425629442578353\n",
      "Testing Score: 0.7590379780752436\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 73  266\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.7846607669616519\n",
      "Cross-Val Accuracy: 0.5815797940797941\n",
      "\n",
      "Combined Score: 0.6525630676779739\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 5\n",
      "Training Score: 0.8590128360303873\n",
      "Testing Score: 0.768594628321549\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 73  266\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.7846607669616519\n",
      "Cross-Val Accuracy: 0.5617599742599741\n",
      "\n",
      "Combined Score: 0.6444938358846041\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 6\n",
      "Training Score: 0.8590128360303873\n",
      "Testing Score: 0.768594628321549\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 73  266\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.7846607669616519\n",
      "Cross-Val Accuracy: 0.5617599742599741\n",
      "\n",
      "Combined Score: 0.6444938358846041\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 6, Min Samples Split = 7\n",
      "Training Score: 0.8441476013749398\n",
      "Testing Score: 0.7532644633979562\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 73  266\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.7846607669616519\n",
      "Cross-Val Accuracy: 0.5599903474903475\n",
      "\n",
      "Combined Score: 0.637299993853391\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 4\n",
      "Training Score: 0.8051457545015005\n",
      "Testing Score: 0.6941228871496066\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                57  163\n",
      "1                22  317\n",
      "Negative Accuracy: 0.2590909090909091\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5563867438867438\n",
      "\n",
      "Combined Score: 0.6114812011918889\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 5\n",
      "Training Score: 0.8271338446706619\n",
      "Testing Score: 0.7218044571815522\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                51  169\n",
      "1                22  317\n",
      "Negative Accuracy: 0.2318181818181818\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5599581724581724\n",
      "\n",
      "Combined Score: 0.6246966863475243\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 6\n",
      "Training Score: 0.8271338446706619\n",
      "Testing Score: 0.7218044571815522\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                51  169\n",
      "1                22  317\n",
      "Negative Accuracy: 0.2318181818181818\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5599581724581724\n",
      "\n",
      "Combined Score: 0.6246966863475243\n",
      "\n",
      "Max Depth: 5, Random State = 1, Max Feature = 7, Min Samples Split = 7\n",
      "Training Score: 0.8271338446706619\n",
      "Testing Score: 0.7218044571815522\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                51  169\n",
      "1                22  317\n",
      "Negative Accuracy: 0.2318181818181818\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5599581724581724\n",
      "\n",
      "Combined Score: 0.6246966863475243\n",
      "\n",
      "{'score': 0.68295811149331476, 'Max Depth': 4, 'Random State': 1, 'Max Feature': 4, 'Min Samples Split': 7}\n"
     ]
    }
   ],
   "source": [
    "run_tree(X_10, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8706574619046943\n",
      "Testing Score: 0.8010116036683442\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                23  316\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6692656453283417\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.889944515211497\n",
      "Testing Score: 0.8135372886718377\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                56  164\n",
      "1                14  325\n",
      "Negative Accuracy: 0.2545454545454545\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6764187764725962\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8903058487471673\n",
      "Testing Score: 0.8098173323958691\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                10  329\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5867921492921494\n",
      "\n",
      "Combined Score: 0.6760022225336373\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8695389853951692\n",
      "Testing Score: 0.7993456613244357\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                22  317\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6696706969622068\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8908856299656778\n",
      "Testing Score: 0.8103149695506895\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                59  161\n",
      "1                14  325\n",
      "Negative Accuracy: 0.2681818181818182\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.671915563109851\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8905387169692673\n",
      "Testing Score: 0.8044382556285493\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                55  165\n",
      "1                10  329\n",
      "Negative Accuracy: 0.25\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6706363061124236\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8694192980409797\n",
      "Testing Score: 0.8017110151160045\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                22  317\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6716882670502629\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8915568775880909\n",
      "Testing Score: 0.8125940011859939\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                59  161\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2681818181818182\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6738986043354014\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8909884073791605\n",
      "Testing Score: 0.8090672791499411\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                56  164\n",
      "1                11  328\n",
      "Negative Accuracy: 0.2545454545454545\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6746307726638374\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8671273172412197\n",
      "Testing Score: 0.802613434530959\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                25  314\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6742017444687542\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8894382435387834\n",
      "Testing Score: 0.8122049627334332\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                54  166\n",
      "1                11  328\n",
      "Negative Accuracy: 0.24545454545454545\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6726715603829485\n",
      "\n",
      "Max Depth: 3, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8905038889309754\n",
      "Testing Score: 0.8019615656518593\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                53  167\n",
      "1                10  329\n",
      "Negative Accuracy: 0.2409090909090909\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5796492921492921\n",
      "\n",
      "Combined Score: 0.6685742015503189\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8712160523500128\n",
      "Testing Score: 0.7938266534372035\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6674630938073138\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8849669946595542\n",
      "Testing Score: 0.8009789951600297\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                61  159\n",
      "1                21  318\n",
      "Negative Accuracy: 0.2772727272727273\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6735479687203825\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8873649131623029\n",
      "Testing Score: 0.7941490137104831\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                59  161\n",
      "1                14  325\n",
      "Negative Accuracy: 0.2681818181818182\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5850225225225225\n",
      "\n",
      "Combined Score: 0.6686731189977068\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8745337074849623\n",
      "Testing Score: 0.7933976304054408\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6662200560231801\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.884938476901892\n",
      "Testing Score: 0.8009789951600297\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                58  162\n",
      "1                20  319\n",
      "Negative Accuracy: 0.2636363636363636\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6735479687203825\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.887235902401256\n",
      "Testing Score: 0.7992452659660223\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                61  159\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2772727272727273\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5903796653796654\n",
      "\n",
      "Combined Score: 0.6739259056142082\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8771735472252381\n",
      "Testing Score: 0.7975773587231001\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6678919473502439\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8869695289860722\n",
      "Testing Score: 0.8010498211732852\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                58  162\n",
      "1                20  319\n",
      "Negative Accuracy: 0.2636363636363636\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6735762991256847\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8862162699090443\n",
      "Testing Score: 0.7973115643085638\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                62  158\n",
      "1                16  323\n",
      "Negative Accuracy: 0.2818181818181818\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5903796653796654\n",
      "\n",
      "Combined Score: 0.6731524249512246\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8752498423936483\n",
      "Testing Score: 0.8007536345021157\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                44  176\n",
      "1                15  324\n",
      "Negative Accuracy: 0.2\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5867921492921493\n",
      "\n",
      "Combined Score: 0.6723767433761358\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8869676962769887\n",
      "Testing Score: 0.8018943413895292\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                55  165\n",
      "1                20  319\n",
      "Negative Accuracy: 0.25\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5921653796653796\n",
      "\n",
      "Combined Score: 0.6760569643550395\n",
      "\n",
      "Max Depth: 3, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8851651930879776\n",
      "Testing Score: 0.7997045692660386\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                60  160\n",
      "1                16  323\n",
      "Negative Accuracy: 0.2727272727272727\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5921653796653796\n",
      "\n",
      "Combined Score: 0.6751810555056432\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8669890738904213\n",
      "Testing Score: 0.7880937078122928\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                63  157\n",
      "1                17  322\n",
      "Negative Accuracy: 0.2863636363636364\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6651699155573496\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8861214375517124\n",
      "Testing Score: 0.7810848639357015\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                68  152\n",
      "1                20  319\n",
      "Negative Accuracy: 0.3090909090909091\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5707207207207208\n",
      "\n",
      "Combined Score: 0.654866378006713\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8855178023607342\n",
      "Testing Score: 0.7860181842297367\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                66  154\n",
      "1                19  320\n",
      "Negative Accuracy: 0.3\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6600539918386128\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.86666221203938\n",
      "Testing Score: 0.7870917491140549\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                63  157\n",
      "1                17  322\n",
      "Negative Accuracy: 0.2863636363636364\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.6669312942402166\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8880747712277859\n",
      "Testing Score: 0.769599185776177\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                21  318\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5671653796653796\n",
      "\n",
      "Combined Score: 0.6481389021096986\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8869882753831518\n",
      "Testing Score: 0.7893511883527855\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                66  154\n",
      "1                19  320\n",
      "Negative Accuracy: 0.3\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.581451093951094\n",
      "\n",
      "Combined Score: 0.6646111317117706\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8658599173545234\n",
      "Testing Score: 0.7866305077983641\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                63  157\n",
      "1                17  322\n",
      "Negative Accuracy: 0.2863636363636364\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6656753691425117\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8873794976986842\n",
      "Testing Score: 0.7702831627603516\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                21  318\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5707368082368083\n",
      "\n",
      "Combined Score: 0.6505553500462256\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8878180699009416\n",
      "Testing Score: 0.7866516381824811\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                18  321\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5796653796653797\n",
      "\n",
      "Combined Score: 0.6624598830722203\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8602695961031461\n",
      "Testing Score: 0.7853822631424114\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                63  157\n",
      "1                17  322\n",
      "Negative Accuracy: 0.2863636363636364\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5868404118404118\n",
      "\n",
      "Combined Score: 0.6662571523612117\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8867705024463308\n",
      "Testing Score: 0.77376255572163\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                21  318\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5689350064350065\n",
      "\n",
      "Combined Score: 0.6508660261496559\n",
      "\n",
      "Max Depth: 3, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8883583830684897\n",
      "Testing Score: 0.7820062086629612\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                65  155\n",
      "1                19  320\n",
      "Negative Accuracy: 0.29545454545454547\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5778635778635779\n",
      "\n",
      "Combined Score: 0.6595206301833312\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8690366597248251\n",
      "Testing Score: 0.8036502113769327\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                72  148\n",
      "1                26  313\n",
      "Negative Accuracy: 0.32727272727272727\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.670321088411777\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8771800728359833\n",
      "Testing Score: 0.7887164510327451\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                68  152\n",
      "1                26  313\n",
      "Negative Accuracy: 0.3090909090909091\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.666490441416959\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8793836910162447\n",
      "Testing Score: 0.780800593738195\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                25  314\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6601098127848533\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8677554122813149\n",
      "Testing Score: 0.8091839431466671\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                72  148\n",
      "1                26  313\n",
      "Negative Accuracy: 0.32727272727272727\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5886261261261261\n",
      "\n",
      "Combined Score: 0.6768492529343425\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.879242479384039\n",
      "Testing Score: 0.7857169957455539\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                68  152\n",
      "1                26  313\n",
      "Negative Accuracy: 0.3090909090909091\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6620763735877968\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8804502572839319\n",
      "Testing Score: 0.786000652167932\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                23  316\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.5832368082368082\n",
      "\n",
      "Combined Score: 0.6643423458092578\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8724433660032478\n",
      "Testing Score: 0.8118506098133336\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                82  138\n",
      "1                34  305\n",
      "Negative Accuracy: 0.37272727272727274\n",
      "Positive Accuracy: 0.8997050147492626\n",
      "Cross-Val Accuracy: 0.5921975546975548\n",
      "\n",
      "Combined Score: 0.6800587767438663\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8787965446832734\n",
      "Testing Score: 0.7879534640197581\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                67  153\n",
      "1                26  313\n",
      "Negative Accuracy: 0.30454545454545456\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6640423894689071\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8801982207247541\n",
      "Testing Score: 0.7850695194472603\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                66  154\n",
      "1                27  312\n",
      "Negative Accuracy: 0.3\n",
      "Positive Accuracy: 0.9203539823008849\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6618173830684795\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8713507868030647\n",
      "Testing Score: 0.809512039292945\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                82  138\n",
      "1                34  305\n",
      "Negative Accuracy: 0.37272727272727274\n",
      "Positive Accuracy: 0.8997050147492626\n",
      "Cross-Val Accuracy: 0.5904118404118404\n",
      "\n",
      "Combined Score: 0.6780519199642823\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8797324843093968\n",
      "Testing Score: 0.78848745570941\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                68  152\n",
      "1                26  313\n",
      "Negative Accuracy: 0.3090909090909091\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6653274147161965\n",
      "\n",
      "Max Depth: 3, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8789542135033201\n",
      "Testing Score: 0.793001351965851\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                66  154\n",
      "1                28  311\n",
      "Negative Accuracy: 0.3\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.6703472589330586\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8795857097472496\n",
      "Testing Score: 0.7763179956329582\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                87  133\n",
      "1                21  318\n",
      "Negative Accuracy: 0.39545454545454545\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5833333333333333\n",
      "\n",
      "Combined Score: 0.6605271982531833\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8983032014889922\n",
      "Testing Score: 0.794146272435745\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                88  132\n",
      "1                18  321\n",
      "Negative Accuracy: 0.4\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6718766556924447\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9020588109007125\n",
      "Testing Score: 0.7962501075710698\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                82  138\n",
      "1                14  325\n",
      "Negative Accuracy: 0.37272727272727274\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5939671814671814\n",
      "\n",
      "Combined Score: 0.6748803519087367\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8852371889634505\n",
      "Testing Score: 0.7788109277370436\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                90  130\n",
      "1                25  314\n",
      "Negative Accuracy: 0.4090909090909091\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5778957528957529\n",
      "\n",
      "Combined Score: 0.6582618228322692\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9014243596635563\n",
      "Testing Score: 0.7936461578718523\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                87  133\n",
      "1                19  320\n",
      "Negative Accuracy: 0.39545454545454545\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5885778635778636\n",
      "\n",
      "Combined Score: 0.670605181295459\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9018335845453691\n",
      "Testing Score: 0.788818485489181\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                13  326\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.667621988790267\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8836598790243139\n",
      "Testing Score: 0.7698759430824003\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                90  130\n",
      "1                25  314\n",
      "Negative Accuracy: 0.4090909090909091\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5725386100386101\n",
      "\n",
      "Combined Score: 0.6514735432561262\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8981051829101343\n",
      "Testing Score: 0.7916277435456525\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                88  132\n",
      "1                16  323\n",
      "Negative Accuracy: 0.4\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5867921492921493\n",
      "\n",
      "Combined Score: 0.6687263869935506\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9034084640579504\n",
      "Testing Score: 0.7885950287357361\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                89  131\n",
      "1                14  325\n",
      "Negative Accuracy: 0.40454545454545454\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6664611775174605\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8812379778516419\n",
      "Testing Score: 0.7732046389269775\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                76  144\n",
      "1                28  311\n",
      "Negative Accuracy: 0.34545454545454546\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5796975546975547\n",
      "\n",
      "Combined Score: 0.6571003883893238\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8991124457661007\n",
      "Testing Score: 0.7949662242844662\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                86  134\n",
      "1                18  321\n",
      "Negative Accuracy: 0.39090909090909093\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.6700810843083811\n",
      "\n",
      "Max Depth: 4, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9007994426076568\n",
      "Testing Score: 0.7902276051008866\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                17  322\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6671142080635206\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8799698504275841\n",
      "Testing Score: 0.7763355777451844\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                86  134\n",
      "1                28  311\n",
      "Negative Accuracy: 0.39090909090909093\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5814510939510938\n",
      "\n",
      "Combined Score: 0.65940488746873\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8969355964896166\n",
      "Testing Score: 0.7829971252612216\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                88  132\n",
      "1                19  320\n",
      "Negative Accuracy: 0.4\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5867921492921492\n",
      "\n",
      "Combined Score: 0.6652741396797781\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9003099463318579\n",
      "Testing Score: 0.7716681472604954\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                84  136\n",
      "1                20  319\n",
      "Negative Accuracy: 0.38181818181818183\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5796653796653797\n",
      "\n",
      "Combined Score: 0.656466486703426\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8779981008892805\n",
      "Testing Score: 0.772226089849101\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                31  308\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.9085545722713865\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.6609753780245825\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9006925062937368\n",
      "Testing Score: 0.780899445847806\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                90  130\n",
      "1                23  316\n",
      "Negative Accuracy: 0.4090909090909091\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.6633636393429834\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9014609685391243\n",
      "Testing Score: 0.7736551829128694\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                19  320\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6572516484547231\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8712131862354087\n",
      "Testing Score: 0.7771693010521978\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                84  136\n",
      "1                34  305\n",
      "Negative Accuracy: 0.38181818181818183\n",
      "Positive Accuracy: 0.8997050147492626\n",
      "Cross-Val Accuracy: 0.5903796653796654\n",
      "\n",
      "Combined Score: 0.6650955196486783\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9010914383948713\n",
      "Testing Score: 0.7830011840360123\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                88  132\n",
      "1                26  313\n",
      "Negative Accuracy: 0.4\n",
      "Positive Accuracy: 0.9233038348082596\n",
      "Cross-Val Accuracy: 0.585006435006435\n",
      "\n",
      "Combined Score: 0.664204334618266\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8997868648181451\n",
      "Testing Score: 0.7709079301656167\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                85  135\n",
      "1                21  318\n",
      "Negative Accuracy: 0.38636363636363635\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5760778635778636\n",
      "\n",
      "Combined Score: 0.6540098902129649\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8726956224938893\n",
      "Testing Score: 0.7834387565034968\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                86  134\n",
      "1                33  306\n",
      "Negative Accuracy: 0.39090909090909093\n",
      "Positive Accuracy: 0.9026548672566371\n",
      "Cross-Val Accuracy: 0.5939510939510939\n",
      "\n",
      "Combined Score: 0.669746158972055\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8970284523820787\n",
      "Testing Score: 0.7758183912364112\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                86  134\n",
      "1                22  317\n",
      "Negative Accuracy: 0.39090909090909093\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6591883603555684\n",
      "\n",
      "Max Depth: 4, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8976364579981235\n",
      "Testing Score: 0.773682433960355\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                83  137\n",
      "1                22  317\n",
      "Negative Accuracy: 0.37727272727272726\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6583339774451459\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.879685377025055\n",
      "Testing Score: 0.7666652245263983\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 28  311\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5904118404118405\n",
      "\n",
      "Combined Score: 0.6609131940576636\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8916969896750839\n",
      "Testing Score: 0.7498570949607958\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                19  320\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5743082368082368\n",
      "\n",
      "Combined Score: 0.6445277800692604\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8934681275194786\n",
      "Testing Score: 0.7687986684193729\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                18  321\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6606758380241198\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8774977748641692\n",
      "Testing Score: 0.7711152321502684\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 29  310\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.9144542772861357\n",
      "Cross-Val Accuracy: 0.5922136422136423\n",
      "\n",
      "Combined Score: 0.6637742781882927\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8944057349509261\n",
      "Testing Score: 0.7582797975826463\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                22  317\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5814671814671815\n",
      "\n",
      "Combined Score: 0.6521922279133674\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8942845618071285\n",
      "Testing Score: 0.7676752809434082\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                17  322\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5832528957528957\n",
      "\n",
      "Combined Score: 0.6570218498291007\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8729247426392867\n",
      "Testing Score: 0.7617440269081801\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 35  304\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.8967551622418879\n",
      "Cross-Val Accuracy: 0.5886422136422136\n",
      "\n",
      "Combined Score: 0.6578829389486003\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8941173869254827\n",
      "Testing Score: 0.7654170883964075\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                93  127\n",
      "1                19  320\n",
      "Negative Accuracy: 0.42272727272727273\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5832528957528957\n",
      "\n",
      "Combined Score: 0.6561185728103005\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8924630217542898\n",
      "Testing Score: 0.7722763305204607\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                17  322\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.6609954742931263\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8695516215044392\n",
      "Testing Score: 0.7600131997630158\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 35  304\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.8967551622418879\n",
      "Cross-Val Accuracy: 0.5886261261261261\n",
      "\n",
      "Combined Score: 0.6571809555808821\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8916399254396211\n",
      "Testing Score: 0.761023641289327\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                22  317\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5832528957528957\n",
      "\n",
      "Combined Score: 0.6543611939674683\n",
      "\n",
      "Max Depth: 4, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8918513107136807\n",
      "Testing Score: 0.7723990049778651\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                18  321\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.6610541965857406\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8793869341807914\n",
      "Testing Score: 0.7862641981569045\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                33  306\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.9026548672566371\n",
      "Cross-Val Accuracy: 0.5957046332046332\n",
      "\n",
      "Combined Score: 0.6719284591855417\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8991851470116901\n",
      "Testing Score: 0.7814958502862721\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                18  321\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5885939510939511\n",
      "\n",
      "Combined Score: 0.6657547107708794\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9014962667511057\n",
      "Testing Score: 0.7717916605608435\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                99  121\n",
      "1                17  322\n",
      "Negative Accuracy: 0.45\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.6608016063092794\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8807573558322443\n",
      "Testing Score: 0.7878828026177757\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                31  308\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.9085545722713865\n",
      "Cross-Val Accuracy: 0.6010778635778636\n",
      "\n",
      "Combined Score: 0.6757998391938285\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8981624670899816\n",
      "Testing Score: 0.7769759874396235\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                21  318\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.9380530973451328\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.6628849895704441\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9013882439653413\n",
      "Testing Score: 0.7697255047840665\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                19  320\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6589133679367927\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8821854317234459\n",
      "Testing Score: 0.7866098009210913\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                90  130\n",
      "1                24  315\n",
      "Negative Accuracy: 0.4090909090909091\n",
      "Positive Accuracy: 0.9292035398230089\n",
      "Cross-Val Accuracy: 0.590363577863578\n",
      "\n",
      "Combined Score: 0.6688620670865834\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8982833633061243\n",
      "Testing Score: 0.7760471573644071\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                94  126\n",
      "1                17  322\n",
      "Negative Accuracy: 0.42727272727272725\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5832528957528956\n",
      "\n",
      "Combined Score: 0.6603706003975003\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8956903113803533\n",
      "Testing Score: 0.7776283693846507\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                18  321\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.58503861003861\n",
      "\n",
      "Combined Score: 0.6620745137770263\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.879976829182082\n",
      "Testing Score: 0.7832302985693795\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                84  136\n",
      "1                27  312\n",
      "Negative Accuracy: 0.38181818181818183\n",
      "Positive Accuracy: 0.9203539823008849\n",
      "Cross-Val Accuracy: 0.5903635778635778\n",
      "\n",
      "Combined Score: 0.6675102661458985\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8947347802062848\n",
      "Testing Score: 0.7944313659642115\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                91  129\n",
      "1                20  319\n",
      "Negative Accuracy: 0.41363636363636364\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.6011100386100386\n",
      "\n",
      "Combined Score: 0.6784385695517079\n",
      "\n",
      "Max Depth: 4, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.895667425818878\n",
      "Testing Score: 0.7823282069479995\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                95  125\n",
      "1                22  317\n",
      "Negative Accuracy: 0.4318181818181818\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.6650258773737945\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8990421210199642\n",
      "Testing Score: 0.7325278465618222\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                107  113\n",
      "1                 27  312\n",
      "Negative Accuracy: 0.4863636363636364\n",
      "Positive Accuracy: 0.9203539823008849\n",
      "Cross-Val Accuracy: 0.5653635778635779\n",
      "\n",
      "Combined Score: 0.6322292853428757\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9253686149186088\n",
      "Testing Score: 0.7699748760346166\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                112  108\n",
      "1                 10  329\n",
      "Negative Accuracy: 0.509090909090909\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.581451093951094\n",
      "\n",
      "Combined Score: 0.656860606784503\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9294193406329294\n",
      "Testing Score: 0.7801559278182425\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                117  103\n",
      "1                  7  332\n",
      "Negative Accuracy: 0.5318181818181819\n",
      "Positive Accuracy: 0.9793510324483776\n",
      "Cross-Val Accuracy: 0.5939671814671814\n",
      "\n",
      "Combined Score: 0.6684426800076059\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8921900583818239\n",
      "Testing Score: 0.7375525122636518\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 23  316\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.5653635778635778\n",
      "\n",
      "Combined Score: 0.6342391516236074\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9230228019206607\n",
      "Testing Score: 0.7630184416012916\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                107  113\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.4863636363636364\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5868082368082368\n",
      "\n",
      "Combined Score: 0.6572923187254587\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9273684462289505\n",
      "Testing Score: 0.7691429748596207\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                  7  332\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9793510324483776\n",
      "Cross-Val Accuracy: 0.590395752895753\n",
      "\n",
      "Combined Score: 0.6618946416813001\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8914752464629704\n",
      "Testing Score: 0.7514982058637659\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                106  114\n",
      "1                 23  316\n",
      "Negative Accuracy: 0.4818181818181818\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.5832207207207207\n",
      "\n",
      "Combined Score: 0.6505317147779388\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9183143938735434\n",
      "Testing Score: 0.7814943211913136\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                113  107\n",
      "1                  9  330\n",
      "Negative Accuracy: 0.5136363636363637\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.5975225225225225\n",
      "\n",
      "Combined Score: 0.6711112419900389\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9226885717040437\n",
      "Testing Score: 0.7789334581103989\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                112  108\n",
      "1                  9  330\n",
      "Negative Accuracy: 0.509090909090909\n",
      "Positive Accuracy: 0.9734513274336283\n",
      "Cross-Val Accuracy: 0.59753861003861\n",
      "\n",
      "Combined Score: 0.6700965492673256\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8949330199237098\n",
      "Testing Score: 0.7484989281710515\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                102  118\n",
      "1                 20  319\n",
      "Negative Accuracy: 0.4636363636363636\n",
      "Positive Accuracy: 0.9410029498525073\n",
      "Cross-Val Accuracy: 0.5779440154440155\n",
      "\n",
      "Combined Score: 0.6461659805348299\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9181210091705599\n",
      "Testing Score: 0.7777435645121408\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                112  108\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.509090909090909\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5850225225225225\n",
      "\n",
      "Combined Score: 0.6621109393183698\n",
      "\n",
      "Max Depth: 5, Max Feature = 4, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9180449200184576\n",
      "Testing Score: 0.7840549712057643\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                107  113\n",
      "1                 10  329\n",
      "Negative Accuracy: 0.4863636363636364\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5939510939510939\n",
      "\n",
      "Combined Score: 0.6699926448529621\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8990339384051952\n",
      "Testing Score: 0.7468101842610564\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 22  317\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9351032448377581\n",
      "Cross-Val Accuracy: 0.5653796653796654\n",
      "\n",
      "Combined Score: 0.6379518729322218\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9248722859927583\n",
      "Testing Score: 0.7822692995885578\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.6046653796653796\n",
      "\n",
      "Combined Score: 0.6757069476346509\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9240534942981677\n",
      "Testing Score: 0.7750808275662123\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 13  326\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5939510939510939\n",
      "\n",
      "Combined Score: 0.6664029873971413\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8977046996190973\n",
      "Testing Score: 0.7356575071553415\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                108  112\n",
      "1                 28  311\n",
      "Negative Accuracy: 0.4909090909090909\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5617760617760619\n",
      "\n",
      "Combined Score: 0.6313286399277738\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9240246187476394\n",
      "Testing Score: 0.7730518911337055\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 17  322\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5921653796653796\n",
      "\n",
      "Combined Score: 0.6645199842527101\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9223082594005005\n",
      "Testing Score: 0.7766614604473678\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5903796653796654\n",
      "\n",
      "Combined Score: 0.6648923834067464\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8968047147721165\n",
      "Testing Score: 0.7431471470127595\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                108  112\n",
      "1                 19  320\n",
      "Negative Accuracy: 0.4909090909090909\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5742921492921493\n",
      "\n",
      "Combined Score: 0.6418341483803934\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9236799944468281\n",
      "Testing Score: 0.7628986469347458\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                114  106\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.5181818181818182\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5850225225225225\n",
      "\n",
      "Combined Score: 0.6561729722874119\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9208819379823534\n",
      "Testing Score: 0.764661792735132\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                112  108\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.509090909090909\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5850225225225225\n",
      "\n",
      "Combined Score: 0.6568782306075663\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8951309017924229\n",
      "Testing Score: 0.7377400365547034\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 18  321\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5707207207207208\n",
      "\n",
      "Combined Score: 0.6375284470543139\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9179025985669979\n",
      "Testing Score: 0.7528408516320017\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                110  110\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.5\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5760939510939511\n",
      "\n",
      "Combined Score: 0.6467927113091714\n",
      "\n",
      "Max Depth: 5, Max Feature = 5, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9205766980562864\n",
      "Testing Score: 0.7682651820251921\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                109  111\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.4954545454545455\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5832368082368082\n",
      "\n",
      "Combined Score: 0.6572481577521618\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8946716433212816\n",
      "Testing Score: 0.7634835287329189\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                128   92\n",
      "1                 30  309\n",
      "Negative Accuracy: 0.5818181818181818\n",
      "Positive Accuracy: 0.911504424778761\n",
      "Cross-Val Accuracy: 0.585070785070785\n",
      "\n",
      "Combined Score: 0.6564358825356386\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.923424773335709\n",
      "Testing Score: 0.7506080552214893\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                120  100\n",
      "1                 13  326\n",
      "Negative Accuracy: 0.5454545454545454\n",
      "Positive Accuracy: 0.9616519174041298\n",
      "Cross-Val Accuracy: 0.5796653796653797\n",
      "\n",
      "Combined Score: 0.6480424498878236\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9254095256301456\n",
      "Testing Score: 0.7462931799802339\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                115  105\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.5227272727272727\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.5707368082368082\n",
      "\n",
      "Combined Score: 0.6409593569341785\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8998126850744578\n",
      "Testing Score: 0.7446578500743085\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                128   92\n",
      "1                 29  310\n",
      "Negative Accuracy: 0.5818181818181818\n",
      "Positive Accuracy: 0.9144542772861357\n",
      "Cross-Val Accuracy: 0.5796814671814672\n",
      "\n",
      "Combined Score: 0.6456720203386037\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9224551746557029\n",
      "Testing Score: 0.745040894099618\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                119  101\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.5409090909090909\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5743082368082368\n",
      "\n",
      "Combined Score: 0.6426012997247894\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.925993290023226\n",
      "Testing Score: 0.74317476813836\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                117  103\n",
      "1                 11  328\n",
      "Negative Accuracy: 0.5318181818181819\n",
      "Positive Accuracy: 0.967551622418879\n",
      "Cross-Val Accuracy: 0.568951093951094\n",
      "\n",
      "Combined Score: 0.6386405636260004\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8968911006677572\n",
      "Testing Score: 0.749791499406788\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                130   90\n",
      "1                 27  312\n",
      "Negative Accuracy: 0.5909090909090909\n",
      "Positive Accuracy: 0.9203539823008849\n",
      "Cross-Val Accuracy: 0.5868404118404118\n",
      "\n",
      "Combined Score: 0.6520208468669624\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.919248396267415\n",
      "Testing Score: 0.7384360557055469\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                123   97\n",
      "1                 19  320\n",
      "Negative Accuracy: 0.5590909090909091\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5707207207207208\n",
      "\n",
      "Combined Score: 0.6378068547146512\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9242322958687108\n",
      "Testing Score: 0.7387949108245051\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                121   99\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.55\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5671653796653796\n",
      "\n",
      "Combined Score: 0.6358171921290299\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8995682633685715\n",
      "Testing Score: 0.7430182242704351\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                126   94\n",
      "1                 28  311\n",
      "Negative Accuracy: 0.5727272727272728\n",
      "Positive Accuracy: 0.9174041297935103\n",
      "Cross-Val Accuracy: 0.5761583011583011\n",
      "\n",
      "Combined Score: 0.6429022704031547\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9206086532414837\n",
      "Testing Score: 0.7454484584784342\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                123   97\n",
      "1                 15  324\n",
      "Negative Accuracy: 0.5590909090909091\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.5760939510939511\n",
      "\n",
      "Combined Score: 0.6438357540477444\n",
      "\n",
      "Max Depth: 5, Max Feature = 6, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9231843483525349\n",
      "Testing Score: 0.744302383003529\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                121   99\n",
      "1                 10  329\n",
      "Negative Accuracy: 0.55\n",
      "Positive Accuracy: 0.9705014749262537\n",
      "Cross-Val Accuracy: 0.5725225225225226\n",
      "\n",
      "Combined Score: 0.6412344667149251\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.8975028543663515\n",
      "Testing Score: 0.7408029747627982\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                119  101\n",
      "1                 25  314\n",
      "Negative Accuracy: 0.5409090909090909\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5832850707850709\n",
      "\n",
      "Combined Score: 0.6462922323761617\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9248032961136381\n",
      "Testing Score: 0.7562705445750688\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                125   95\n",
      "1                 19  320\n",
      "Negative Accuracy: 0.5681818181818182\n",
      "Positive Accuracy: 0.943952802359882\n",
      "Cross-Val Accuracy: 0.5868243243243243\n",
      "\n",
      "Combined Score: 0.6546028124246221\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 4\n",
      "Training Score: 0.9287116820440975\n",
      "Testing Score: 0.7498298243884902\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                122   98\n",
      "1                 12  327\n",
      "Negative Accuracy: 0.5545454545454546\n",
      "Positive Accuracy: 0.9646017699115044\n",
      "Cross-Val Accuracy: 0.5796492921492922\n",
      "\n",
      "Combined Score: 0.6477215050449714\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.8973442319068818\n",
      "Testing Score: 0.7447146528847778\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                120  100\n",
      "1                 25  314\n",
      "Negative Accuracy: 0.5454545454545454\n",
      "Positive Accuracy: 0.9262536873156342\n",
      "Cross-Val Accuracy: 0.5725386100386101\n",
      "\n",
      "Combined Score: 0.6414090271770772\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9234065971674825\n",
      "Testing Score: 0.7435518087000049\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                125   95\n",
      "1                 18  321\n",
      "Negative Accuracy: 0.5681818181818182\n",
      "Positive Accuracy: 0.9469026548672567\n",
      "Cross-Val Accuracy: 0.5743243243243243\n",
      "\n",
      "Combined Score: 0.6420153180745966\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 5\n",
      "Training Score: 0.9275652487824114\n",
      "Testing Score: 0.7477266616144101\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                125   95\n",
      "1                 14  325\n",
      "Negative Accuracy: 0.5681818181818182\n",
      "Positive Accuracy: 0.9587020648967551\n",
      "Cross-Val Accuracy: 0.5778957528957529\n",
      "\n",
      "Combined Score: 0.6458281163832158\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.8959954768979811\n",
      "Testing Score: 0.7596300699180355\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                126   94\n",
      "1                 23  316\n",
      "Negative Accuracy: 0.5727272727272728\n",
      "Positive Accuracy: 0.9321533923303835\n",
      "Cross-Val Accuracy: 0.5939671814671814\n",
      "\n",
      "Combined Score: 0.6602323368475231\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.924194095970573\n",
      "Testing Score: 0.7487351961253665\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                123   97\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.5590909090909091\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5743082368082368\n",
      "\n",
      "Combined Score: 0.6440790205350888\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 6\n",
      "Training Score: 0.9251724286727206\n",
      "Testing Score: 0.7498978068784468\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                119  101\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.5409090909090909\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6488201266123825\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 10, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.8922302562760253\n",
      "Testing Score: 0.7725066126893058\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                117  103\n",
      "1                 30  309\n",
      "Negative Accuracy: 0.5318181818181819\n",
      "Positive Accuracy: 0.911504424778761\n",
      "Cross-Val Accuracy: 0.6136422136422136\n",
      "\n",
      "Combined Score: 0.6771879732610505\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 50, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9225597828261011\n",
      "Testing Score: 0.7550300577682457\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                119  101\n",
      "1                 17  322\n",
      "Negative Accuracy: 0.5409090909090909\n",
      "Positive Accuracy: 0.9498525073746312\n",
      "Cross-Val Accuracy: 0.5742921492921493\n",
      "\n",
      "Combined Score: 0.6465873126825878\n",
      "\n",
      "Max Depth: 5, Max Feature = 7, Number of Trees = 100, Random State = 1, Min Samples Split: 7\n",
      "Training Score: 0.9213005372062548\n",
      "Testing Score: 0.750009448924717\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                118  102\n",
      "1                 16  323\n",
      "Negative Accuracy: 0.5363636363636364\n",
      "Positive Accuracy: 0.9528023598820059\n",
      "Cross-Val Accuracy: 0.5814350064350065\n",
      "\n",
      "Combined Score: 0.6488647834308907\n",
      "\n",
      "{'score': 0.68005877674386628, 'Max Depth': 3, 'Random State': 1, 'Max Feature': 7, 'Min Samples Split': 6, 'Number of Trees': 10}\n"
     ]
    }
   ],
   "source": [
    "run_forest(X_10, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kernel: linear\n",
      "C = 1e-07\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.0001\n",
      "Training Score: 0.8855802166895286\n",
      "Testing Score: 0.8829657284870864\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6046492921492922\n",
      "\n",
      "Combined Score: 0.7159758666844098\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.001\n",
      "Training Score: 0.8617069884578713\n",
      "Testing Score: 0.8196149395935863\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                30  190\n",
      "1                15  324\n",
      "Negative Accuracy: 0.13636363636363635\n",
      "Positive Accuracy: 0.9557522123893806\n",
      "Cross-Val Accuracy: 0.6028635778635778\n",
      "\n",
      "Combined Score: 0.6895641225555813\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.01\n",
      "Training Score: 0.8012945973349979\n",
      "Testing Score: 0.7584647017192155\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                55  284\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.8377581120943953\n",
      "Cross-Val Accuracy: 0.6421975546975546\n",
      "\n",
      "Combined Score: 0.688704413506219\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.1\n",
      "Training Score: 0.8027019970803402\n",
      "Testing Score: 0.7375392820835124\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                104  116\n",
      "1                 59  280\n",
      "Negative Accuracy: 0.4727272727272727\n",
      "Positive Accuracy: 0.8259587020648967\n",
      "Cross-Val Accuracy: 0.6476190476190475\n",
      "\n",
      "Combined Score: 0.6835871414048335\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.3\n",
      "Training Score: 0.8083579549430008\n",
      "Testing Score: 0.7154238702060736\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                100  120\n",
      "1                 54  285\n",
      "Negative Accuracy: 0.45454545454545453\n",
      "Positive Accuracy: 0.8407079646017699\n",
      "Cross-Val Accuracy: 0.6208172458172458\n",
      "\n",
      "Combined Score: 0.6586598955727769\n",
      "\n",
      "Kernel: linear\n",
      "C = 0.5\n",
      "Training Score: 0.8057804682465391\n",
      "Testing Score: 0.7118878804890599\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                105  115\n",
      "1                 57  282\n",
      "Negative Accuracy: 0.4772727272727273\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.6208655083655084\n",
      "\n",
      "Combined Score: 0.6572744572149289\n",
      "\n",
      "Kernel: linear\n",
      "C = 1\n",
      "Training Score: 0.8052258398037573\n",
      "Testing Score: 0.6945507361480643\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                101  119\n",
      "1                 57  282\n",
      "Negative Accuracy: 0.4590909090909091\n",
      "Positive Accuracy: 0.831858407079646\n",
      "Cross-Val Accuracy: 0.6101029601029601\n",
      "\n",
      "Combined Score: 0.6438820705210018\n",
      "\n",
      "Kernel: linear\n",
      "C = 100\n",
      "Training Score: 0.7719547915628069\n",
      "Testing Score: 0.6485687081369725\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                96  124\n",
      "1                65  274\n",
      "Negative Accuracy: 0.43636363636363634\n",
      "Positive Accuracy: 0.8082595870206489\n",
      "Cross-Val Accuracy: 0.5778957528957529\n",
      "\n",
      "Combined Score: 0.6061649349922408\n",
      "\n",
      "Kernel: linear\n",
      "C = 1000\n",
      "Training Score: 0.780847646664383\n",
      "Testing Score: 0.6862842471976418\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                97  123\n",
      "1                62  277\n",
      "Negative Accuracy: 0.4409090909090909\n",
      "Positive Accuracy: 0.8171091445427728\n",
      "Cross-Val Accuracy: 0.6047619047619046\n",
      "\n",
      "Combined Score: 0.6373708417361995\n",
      "\n",
      "Kernel: linear\n",
      "C = 100000.0\n",
      "Training Score: 0.7843497103989281\n",
      "Testing Score: 0.6873558470544626\n",
      "\n",
      "col_0             0    1\n",
      "TwoYearSurvival         \n",
      "0                93  127\n",
      "1                62  277\n",
      "Negative Accuracy: 0.42272727272727273\n",
      "Positive Accuracy: 0.8171091445427728\n",
      "Cross-Val Accuracy: 0.602992277992278\n",
      "\n",
      "Combined Score: 0.6367377056171518\n",
      "\n",
      "Kernel: rbf\n",
      "C = 1e-07\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.0001\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.001\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.01\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.1\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.3\n",
      "Training Score: 0.8851172980622687\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0              1\n",
      "TwoYearSurvival     \n",
      "0                220\n",
      "1                339\n",
      "Negative Accuracy: 0\n",
      "Positive Accuracy: 1\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 0.5\n",
      "Training Score: 0.8873195557830963\n",
      "Testing Score: 0.8851143359718557\n",
      "\n",
      "col_0            0    1\n",
      "TwoYearSurvival        \n",
      "0                5  215\n",
      "1                0  339\n",
      "Negative Accuracy: 0.022727272727272728\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6064350064350064\n",
      "\n",
      "Combined Score: 0.7179067382497462\n",
      "\n",
      "Kernel: rbf\n",
      "C = 1\n",
      "Training Score: 0.9989682037637249\n",
      "Testing Score: 0.8800423464430599\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                218    2\n",
      "1                  0  339\n",
      "Negative Accuracy: 0.990909090909091\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6064350064350065\n",
      "\n",
      "Combined Score: 0.7158779424382279\n",
      "\n",
      "Kernel: rbf\n",
      "C = 100\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8775485464981715\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                220    0\n",
      "1                  0  339\n",
      "Negative Accuracy: 1.0\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6100064350064349\n",
      "\n",
      "Combined Score: 0.7170232796031295\n",
      "\n",
      "Kernel: rbf\n",
      "C = 1000\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8775485464981715\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                220    0\n",
      "1                  0  339\n",
      "Negative Accuracy: 1.0\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6100064350064349\n",
      "\n",
      "Combined Score: 0.7170232796031295\n",
      "\n",
      "Kernel: rbf\n",
      "C = 100000.0\n",
      "Training Score: 1.0\n",
      "Testing Score: 0.8775485464981715\n",
      "\n",
      "col_0              0    1\n",
      "TwoYearSurvival          \n",
      "0                220    0\n",
      "1                  0  339\n",
      "Negative Accuracy: 1.0\n",
      "Positive Accuracy: 1.0\n",
      "Cross-Val Accuracy: 0.6100064350064349\n",
      "\n",
      "Combined Score: 0.7170232796031295\n",
      "\n",
      "{'score': 0.71790673824974616, 'alpha': 0.5, 'kernel': 'rbf'}\n"
     ]
    }
   ],
   "source": [
    "run_svc(X_10, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender</th>\n",
       "      <th>chemo</th>\n",
       "      <th>PA</th>\n",
       "      <th>toxeso</th>\n",
       "      <th>DeltaDyspGe1</th>\n",
       "      <th>OverallPostRTDyspFullScore</th>\n",
       "      <th>Modality</th>\n",
       "      <th>SmokingStatus</th>\n",
       "      <th>dose per fraction</th>\n",
       "      <th>pretoxeso</th>\n",
       "      <th>T_stage</th>\n",
       "      <th>PacksPerDay</th>\n",
       "      <th>OverallBaselineDysp</th>\n",
       "      <th>Locatie</th>\n",
       "      <th>intake_who</th>\n",
       "      <th>total dose</th>\n",
       "      <th>N_stage</th>\n",
       "      <th>BED</th>\n",
       "      <th>CumOTT</th>\n",
       "      <th>fractions</th>\n",
       "      <th>ott</th>\n",
       "      <th>yearrt</th>\n",
       "      <th>CumultativeTotalTumorDose</th>\n",
       "      <th>meanlungdose</th>\n",
       "      <th>lungv20</th>\n",
       "      <th>maxeso</th>\n",
       "      <th>age</th>\n",
       "      <th>med</th>\n",
       "      <th>tumorload</th>\n",
       "      <th>FEV</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.252155</td>\n",
       "      <td>2.088385</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>54.670172</td>\n",
       "      <td>2.0</td>\n",
       "      <td>70.386818</td>\n",
       "      <td>21</td>\n",
       "      <td>28.802575</td>\n",
       "      <td>21</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>45.00</td>\n",
       "      <td>15.417800</td>\n",
       "      <td>33.848500</td>\n",
       "      <td>44.898900</td>\n",
       "      <td>67</td>\n",
       "      <td>17.034600</td>\n",
       "      <td>52.505500</td>\n",
       "      <td>97.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.736142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>78.150000</td>\n",
       "      <td>36</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>67.00</td>\n",
       "      <td>16.680025</td>\n",
       "      <td>22.260337</td>\n",
       "      <td>49.199991</td>\n",
       "      <td>69</td>\n",
       "      <td>20.334135</td>\n",
       "      <td>114.555789</td>\n",
       "      <td>61.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0.736142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.088385</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54.670172</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.386818</td>\n",
       "      <td>24</td>\n",
       "      <td>28.802575</td>\n",
       "      <td>24</td>\n",
       "      <td>2010.0</td>\n",
       "      <td>52.25</td>\n",
       "      <td>16.680025</td>\n",
       "      <td>22.260337</td>\n",
       "      <td>49.199991</td>\n",
       "      <td>82</td>\n",
       "      <td>20.334135</td>\n",
       "      <td>114.555789</td>\n",
       "      <td>76.697907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>52.800000</td>\n",
       "      <td>36</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>36</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>69.00</td>\n",
       "      <td>25.042800</td>\n",
       "      <td>11.988800</td>\n",
       "      <td>48.921700</td>\n",
       "      <td>77</td>\n",
       "      <td>17.229800</td>\n",
       "      <td>42.274500</td>\n",
       "      <td>91.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0.736142</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.727778</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>84.960000</td>\n",
       "      <td>28</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>28</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>72.00</td>\n",
       "      <td>16.680025</td>\n",
       "      <td>22.260337</td>\n",
       "      <td>49.199991</td>\n",
       "      <td>83</td>\n",
       "      <td>20.334135</td>\n",
       "      <td>114.555789</td>\n",
       "      <td>76.697907</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender     chemo   PA  toxeso  DeltaDyspGe1  OverallPostRTDyspFullScore  \\\n",
       "0       0  1.000000  0.0     2.0           0.0                           0   \n",
       "1       0  0.736142  1.0     2.0           0.0                           1   \n",
       "2       1  0.736142  1.0     1.0           1.0                           1   \n",
       "3       1  1.000000  1.0     1.0           0.0                           1   \n",
       "4       1  0.736142  1.0     0.0           0.0                           2   \n",
       "\n",
       "   Modality  SmokingStatus  dose per fraction  pretoxeso  T_stage  \\\n",
       "0       0.0       1.252155           2.088385        2.0      0.0   \n",
       "1       2.0       1.000000           1.500000        2.0      3.0   \n",
       "2       1.0       1.000000           2.088385        0.0      1.0   \n",
       "3       2.0       1.000000           2.000000        1.0      1.0   \n",
       "4       2.0       1.000000           1.800000        0.0      1.0   \n",
       "\n",
       "   PacksPerDay  OverallBaselineDysp  Locatie  intake_who  total dose  N_stage  \\\n",
       "0     0.727778                  0.0      1.0         2.0   54.670172      2.0   \n",
       "1     0.727778                  1.0      0.0         1.0   45.000000      2.0   \n",
       "2     0.727778                  0.0      0.0         1.0   54.670172      3.0   \n",
       "3     0.727778                  1.0      0.0         1.0   33.000000      3.0   \n",
       "4     0.727778                  2.0      2.0         2.0   72.000000      2.0   \n",
       "\n",
       "         BED  CumOTT  fractions  ott  yearrt  CumultativeTotalTumorDose  \\\n",
       "0  70.386818      21  28.802575   21  2010.0                      45.00   \n",
       "1  78.150000      36  30.000000   36  2014.0                      67.00   \n",
       "2  70.386818      24  28.802575   24  2010.0                      52.25   \n",
       "3  52.800000      36  22.000000   36  2013.0                      69.00   \n",
       "4  84.960000      28  40.000000   28  2013.0                      72.00   \n",
       "\n",
       "   meanlungdose    lungv20     maxeso  age        med   tumorload        FEV  \n",
       "0     15.417800  33.848500  44.898900   67  17.034600   52.505500  97.000000  \n",
       "1     16.680025  22.260337  49.199991   69  20.334135  114.555789  61.000000  \n",
       "2     16.680025  22.260337  49.199991   82  20.334135  114.555789  76.697907  \n",
       "3     25.042800  11.988800  48.921700   77  17.229800   42.274500  91.000000  \n",
       "4     16.680025  22.260337  49.199991   83  20.334135  114.555789  76.697907  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_10.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['yearrt' 'med' 'maxeso' 'gender' 'intake_who' 'age' 'chemo' 'ott'\n",
      " 'chemo3g' 'gtv1' 'tumorload' 'toxeso' 'toxesohigh2' 'pretoxeso'\n",
      " 'dose per fraction' 'fractions' 'total dose' 'second dose per fracion'\n",
      " 'second fractions' 'second total dose' 'BED' 'Modality' 'PacksPerDay'\n",
      " 'SmokingStatus' 'IsSCLC' 'T_stage' 'N_stage' 'M_stage' 'PA' 'Locatie'\n",
      " 'FEV' 'CumultativeTotalTumorDose' 'meanlungdose' 'lungv20' 'CumOTT'\n",
      " 'OverallBaselineDysp' 'OverallPostRTDyspFullScore' 'DyspGT2'\n",
      " 'DeltaDyspGe1' 'TreatmentType']\n",
      "(559, 40)\n",
      "   yearrt        med     maxeso  gender  intake_who  age     chemo  ott  \\\n",
      "0  2010.0  17.034600  44.898900       0         2.0   67  1.000000   21   \n",
      "1  2014.0  20.334135  49.199991       0         1.0   69  0.736142   36   \n",
      "2  2010.0  20.334135  49.199991       1         1.0   82  0.736142   24   \n",
      "3  2013.0  17.229800  48.921700       1         1.0   77  1.000000   36   \n",
      "4  2013.0  20.334135  49.199991       1         2.0   83  0.736142   28   \n",
      "\n",
      "    chemo3g   gtv1   tumorload  toxeso  toxesohigh2  pretoxeso  \\\n",
      "0  2.000000  31.95   52.505500     2.0          0.0        2.0   \n",
      "1  1.354767  31.95  114.555789     2.0          0.0        2.0   \n",
      "2  1.354767  31.95  114.555789     1.0          0.0        0.0   \n",
      "3  2.000000  31.95   42.274500     1.0          0.0        1.0   \n",
      "4  1.354767  31.95  114.555789     0.0          0.0        0.0   \n",
      "\n",
      "   dose per fraction  fractions  total dose  second dose per fracion  \\\n",
      "0           2.088385  28.802575   54.670172                 2.274306   \n",
      "1           1.500000  30.000000   45.000000                 2.000000   \n",
      "2           2.088385  28.802575   54.670172                 2.274306   \n",
      "3           2.000000  22.000000   33.000000                 2.274306   \n",
      "4           1.800000  40.000000   72.000000                 2.274306   \n",
      "\n",
      "   second fractions  second total dose        BED  Modality  PacksPerDay  \\\n",
      "0         10.175676          20.364865  70.386818       0.0     0.727778   \n",
      "1         11.000000          22.000000  78.150000       2.0     0.727778   \n",
      "2         10.175676          20.364865  70.386818       1.0     0.727778   \n",
      "3         10.175676          20.364865  52.800000       2.0     0.727778   \n",
      "4         10.175676          20.364865  84.960000       2.0     0.727778   \n",
      "\n",
      "   SmokingStatus  IsSCLC  T_stage  N_stage  M_stage   PA  Locatie        FEV  \\\n",
      "0       1.252155       0      0.0      2.0      0.0  0.0      1.0  97.000000   \n",
      "1       1.000000       0      3.0      2.0      0.0  1.0      0.0  61.000000   \n",
      "2       1.000000       0      1.0      3.0      0.0  1.0      0.0  76.697907   \n",
      "3       1.000000       0      1.0      3.0      0.0  1.0      0.0  91.000000   \n",
      "4       1.000000       0      1.0      2.0      0.0  1.0      2.0  76.697907   \n",
      "\n",
      "   CumultativeTotalTumorDose  meanlungdose    lungv20  CumOTT  \\\n",
      "0                      45.00     15.417800  33.848500      21   \n",
      "1                      67.00     16.680025  22.260337      36   \n",
      "2                      52.25     16.680025  22.260337      24   \n",
      "3                      69.00     25.042800  11.988800      36   \n",
      "4                      72.00     16.680025  22.260337      28   \n",
      "\n",
      "   OverallBaselineDysp  OverallPostRTDyspFullScore  DyspGT2  DeltaDyspGe1  \\\n",
      "0                  0.0                           0        0           0.0   \n",
      "1                  1.0                           1        0           0.0   \n",
      "2                  0.0                           1        0           1.0   \n",
      "3                  1.0                           1        0           0.0   \n",
      "4                  2.0                           2        0           0.0   \n",
      "\n",
      "   TreatmentType  \n",
      "0            2.0  \n",
      "1            2.0  \n",
      "2            2.0  \n",
      "3            2.0  \n",
      "4            2.0  \n"
     ]
    }
   ],
   "source": [
    "print(X.columns.values)\n",
    "print(X.shape)\n",
    "print(X.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(X_dummies.columns.values)\n",
    "cat = ['gender','Modality','PA','Locatie','DeltaDyspGe1','TreatmentType']\n",
    "X_ = pd.get_dummies(X, columns = cat)\n",
    "print(X_.head())\n",
    "X_cat = pd.concat([X, X_], axis = 1)\n",
    "#print(X_cat.head())\n",
    "#print(X_cat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Analysis\n",
    "\n",
    "# SVM\n",
    "\n",
    "After running all the models, Support Vector Machine produced the best cross-val score of 67.3%. Support Vector machines are useful because they can handle a large feature space like this one with 41 features. They can also handle non-linear feature interactions, which is quite common in real world data, especially as you account for more features. By using a statistical technique called kernel smoothing, SVMs are able to reduce overfitting to nuanced datapoints and focus on the big picture.  SVMs are not ideal when the dataset has a vast number of observations, but that is not the case here as we only have 559 datapoints. SVMs are also good at handling missing data (**I averaged them here??**).\n",
    "\n",
    "\n",
    "\n",
    "Pros:\n",
    "Can handle large feature space\n",
    "Can handle non-linear feature interactions\n",
    "Do not rely on entire data -- ??\n",
    "primary advantage is flexibility\n",
    "great visual explanatory power (linear SVC) -- is this true in multidimensional space?\n",
    "great accuracy (kernel smoothing)\n",
    "clustering (SVClustering)\n",
    "ability to control specificity of training (SVR) -- ok what does this mean tho\n",
    "\n",
    "Cons:\n",
    "Not very efficient with large number of observations\n",
    "It can be tricky to find appropriate kernel sometimes -- i feel like there are only a few? linear, rbf...sklearn documentation listed gamma and one other but they didn't return anything\n",
    "\n",
    "\"Always start with logistic regression, if nothing then to use the performance as baseline\n",
    "See if decision trees (Random Forests) provide significant improvement. Even if you do not end up using the resultant model, you can use random forest results to remove noisy variables\n",
    "Go for SVM if you have large number of features and number of observations are not a limitation for available resources and time\"\n",
    "\n",
    "Glad I did this...but how does random forest allow me to cut out variables?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "\n",
    "Because of the computational simplicity of logistic regression, I tried this method first, using both ridge and lasso techniques as baseline scores. These models were comparable with SVM at 65.5%. Regularization was helpful for both ridge and lasso because nuances in the data were causing the models to overfit, as seen by the difference in training/testing scores.\n",
    "\n",
    "**Update, regularization was not helpful**\n",
    "\n",
    "In binary logistic regression, binary output data is converted to a probability distribution and transformed using the log function. The ideal scenario would see a linear relationship between the features and this new, transformed output data. If logistic regression is not performing well, it may be because the data did not fit a linear relationship. Linear relationships cannot be modeled when features have multicollinearity. Certain features get blown way out of proportion despite the model showing minimal error. This is when L2 regularization (or both?) help, as it supplements the tradtional error function with a penalty for extreme parameter estimates. In both ridge and lasso models, regularization was strong (1e-3 and 1e-4), which shows that the features were collinear. They may not have been a good fit for logistic regression, even with the power of regularization.\n",
    "\n",
    "Convenient probability scores for observations - why is this different?\n",
    "Efficient implementations available across tools - eh?\n",
    "Multi-collinearity is not really an issue and can be countered with L2 regularization to an extent\n",
    "Wide spread industry comfort for logistic regression solutions [ oh thats important too!]\n",
    "Logistic Regression Cons:\n",
    "\n",
    "Doesnt perform well when feature space is too large\n",
    "Doesnt handle large number of categorical features/variables well\n",
    "Relies on transformations for non-linear features\n",
    "Relies on entire data [ Not a very serious drawback Id say]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "\n",
    "As expected, the random forest performed better than the decision tree, but took much longer. Both a singular decision tree and a random forest were able to provide better cross-val scores for this dataset. This may be because the logistic models are searching for a single linear decision boundary within this non-linear feature space. Decision tree/random forest models do not rely on absolute linearity, rather they partition the space into smaller linear decision boundaries and combine them.\n",
    "\n",
    "dataset with x feature: sqrt(x) features are used for classifiers are x/3 features are used for regression\n",
    "should i have used bagging?\n",
    "\n",
    "\n",
    "This is nice when your data points aren't easily separated by a single hyperplane, but on the other hand, decisions trees are so flexible that they can be prone to overfitting. To combat this, you can try pruning. Logistic regression tends to be less susceptible (but not immune!) to overfitting.\n",
    "\n",
    "Lastly, another thing to consider is that decision trees can automatically take into account interactions between variables, e.g. xyxy if you have two independent features xx and yy. With logistic regression, you'll have to manually add those interaction terms yourself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "make a spreadsheet that compares best models<br>\n",
    "put categorical variables in beginning<br>\n",
    "next feature set cut out half<br>\n",
    "do PCA<br>\n",
    "get rid of features that don't have enough values (half-60%) \"to prevent us from adding our own interpretation of the data\" more reliable. then add dummies<br>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
